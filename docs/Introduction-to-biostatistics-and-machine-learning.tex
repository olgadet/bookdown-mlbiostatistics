% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Introduction to biostatistics and machine learning},
  pdfauthor={Olga Dethlefsen, Eva Freyhult, Bengt Sennblad, Payam Emami},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{Introduction to biostatistics and machine learning}
\author{Olga Dethlefsen, Eva Freyhult, Bengt Sennblad, Payam Emami}
\date{2020-11-19}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

This ``bookdown'' book contains teaching and learning materials prepared and used during ``Introduction to biostatistics and machine learning'' course organized by NBIS, National Bioinformatics Infrastructure Sweden. The course is open for PhD students, postdoctoral researcher and other employees in need of biostatistical skills within Swedish universities. The materials are geared towards life scientists wanting to be able to understand and use basic statistical and machine learning methods. It may also suits those already applying biostatistical methods but who have never gotten a chance to reflect on the basic statistical concepts, such as the commonly misinterpreted p-value.

More about the course \url{https://nbisweden.github.io/workshop-mlbiostatistics/}

\hypertarget{part-preliminary-mathematics}{%
\part{Preliminary Mathematics}\label{part-preliminary-mathematics}}

\hypertarget{mathematical-notations}{%
\chapter{Mathematical notations}\label{mathematical-notations}}

\textbf{Aims}

\begin{itemize}
\tightlist
\item
  to recapitulate the basic notations and conventions used in mathematics and statistics
\end{itemize}

\textbf{Learning outcomes}

\begin{itemize}
\tightlist
\item
  to recognize natural numbers, integrals and real numbers
\item
  to understand the differences between variables and constants
\item
  to use symbols, especially Sigma and product notations, to represent mathematical operations
\end{itemize}

\hypertarget{numbers}{%
\section{Numbers}\label{numbers}}

\begin{itemize}
\tightlist
\item
  \textbf{Natural numbers, N}: numbers such as 0, 1, 3, \ldots{}
\item
  \textbf{Integers, Z}: include negative numbers \ldots, -2, -1, 0, 1, 2
\item
  \textbf{Rational numbers}: numbers that can be expressed as a ratio two integers, i.e.~in a form \(\frac{a}{b}\), where \(a\) and \(b\) are integers, and \(b\neq0\)
\item
  \textbf{Real numbers, R}: include both rational and irrational numbers
\item
  \textbf{Reciprocal} of any number is found by diving 1 by the number, e.g.~reciprocal of 5 is \(\frac{1}{5}\)
\item
  \textbf{Absolute value} of a number can be viewed as its distance from zero, e.g.~the absolute value of 6 is 6, written as \(|6| = 6\) and absolute value of -5 is 5, written as \(|-5| = 5\)
\item
  \textbf{Factorial} of a non-negative integer number \(n\) is denoted by \(n!\) and it is a product of all positive integers less than or equal to \(n\), e.g.~\(4! = 4 \cdot 3\cdot 2 \cdot 1 = 24\)
\end{itemize}

\hypertarget{variables-constants-and-letters}{%
\section{Variables, constants and letters}\label{variables-constants-and-letters}}

Mathematics gives us a precise language to communicate different concepts and ideas. To be able to use it it is essential to learn symbols and understand how they are used to represent physical quantities as well as understand the rules and conventions that have been developed to manipulate them.

\begin{itemize}
\tightlist
\item
  \textbf{variables}: things that can vary, e.g.~temperature and time
\item
  \textbf{constants}: fixed and unchanging quantities used in certain calculations, e.g.~3.14159
\item
  in principle one could freely choose letters and symbols to represent variables and constants, but it is helpful and choose letters and symbols that have meaning in a particular context. Hence, we
\item
  \(x, y, z\), the end of the alphabet is reserved for variables
\item
  \(a, b, c\), the beginning of the alphabet is used to represent constants
\item
  \(\pi\), \(\omega\) and Greek letters below are used frequently used to represent common constant, e.g.~\(\pi = 3.14159\)
\end{itemize}

\begin{longtable}[]{@{}llllll@{}}
\caption{\label{tab:greek-table} Uppercase and lowercase letters of the Greek alphabet}\tabularnewline
\toprule
Letter & Upper case & Lower case & Letter & Upper case & Lower case\tabularnewline
\midrule
\endfirsthead
\toprule
Letter & Upper case & Lower case & Letter & Upper case & Lower case\tabularnewline
\midrule
\endhead
Alpha & A & \(\alpha\) & Nu & N & \(\nu\)\tabularnewline
Beta & B & \(\beta\) & Xi & \(\Xi\) & \(\xi\)\tabularnewline
Gamma & \(\Gamma\) & \(\gamma\) & Omicron & O & o\tabularnewline
Delta & \(\Delta\) & \(\delta\) & Pi & \(\Pi\) & \(\pi\)\tabularnewline
Epsilon & E & \(\epsilon\) & Rho & P & \(\rho\)\tabularnewline
Zeta & Z & \(\zeta\) & Sigma & \(\Sigma\) & \(\sigma\)\tabularnewline
Eta & H & \(\eta\) & Tau & T & \(\tau\)\tabularnewline
Theta & \(\Theta\) & \(\theta\) & Upsilon & Y & \(\upsilon\)\tabularnewline
Iota & i & \(\iota\) & Phi & \(\Phi\) & \(\phi\)\tabularnewline
Kappa & K & \(\kappa\) & Chi & \(\Gamma\) & \(\gamma\)\tabularnewline
Lambda & \(\Gamma\) & \(\gamma\) & Psi & \(\Psi\) & \(\psi\)\tabularnewline
Mu & M & \(\mu\) & Omega & \(\Omega\) & \(\omega\)\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{a-precise-language}{%
\section{A precise language}\label{a-precise-language}}

\begin{itemize}
\tightlist
\item
  Mathematics is a precise language meaning that a special attention has to be paid to the exact position of any symbol in relation to other.
\item
  Given two symbols \(x\) and \(y\), \(xy\) and \(x^y\) and \(x_y\) can mean different things
\item
  \(xy\) stands for multiplication, \(x^y\) for superscript and \(x_y\) for subscript
\end{itemize}

\hypertarget{using-symbols}{%
\section{Using symbols}\label{using-symbols}}

If the letters \(x\) and \(y\) represent two numbers, then:

\begin{itemize}
\tightlist
\item
  their \textbf{sum} is written as \(x + y\)
\item
  subtracting \(y\) from \(x\) is \(x - y\), known also as \textbf{difference}
\item
  to multiply \(x\) and \(y\) we written as \(x \cdot y\) or also with the multiplication signed omitted as \(xy\). The quantity is known as \textbf{product of x and y}
\item
  multiplication is \textbf{associative}, e.g.~when we multiply three numbers together, \(x \cdot y \cdot z\), the order of multiplication does not matter, so \(x \cdot y \cdot z\) is the same as \(z \cdot x \cdot y\) or \(y cdot z \cdot x\)
\item
  division is denoted by \(\frac{x}{y}\) and mans that \(x\) is divided by \(y\). In this expression \(x\), on the top, is called \textbf{numerator} and \(y\), on the bottom, is called \textbf{denominator}
\item
  division by 1 leaves any number unchanged, e.g.~\(\frac{x}{1}=x\) and division by 0 is not allowed
\end{itemize}

Equal sign

\begin{itemize}
\tightlist
\item
  the equal sign \(=\) is used in \textbf{equations}, e.g.~\(x - 5 = 0\) or \(5x = 1\)
\item
  the equal sign \(=\) can be also used in \textbf{formulae}. Physical quantities are related through a formula in many fields, e.g.~the formula \(A=\pi r^2\) relates circle area \(A\) to its radius \(r\) and the formula \(s = \frac{d}{t}\) defines speed as distance \(d\) divided by time \(t\)
\item
  the equal sign \(=\) is also used in identities, expressions true for all values of the variable, e.g.~\((x-1)(x-1) = (x^2-1)\)
\item
  opposite to the equal sign is ``is not equal to'' sign \(\neq\), e.g.~we can write \(1+2 \neq 4\)
\end{itemize}

\textbf{Sigma and Product notation}

\begin{itemize}
\tightlist
\item
  the \(\Sigma\) notation, read as \textbf{Sigma notation}, provides a convenient way of writing longs sums, e.g.~the sum of \(x_1 + x_2 + x_3 + ... + x_{20}\) is written as \(\displaystyle \sum_{i=1}^{i=20}x_i\)
\item
  the \(\Pi\) notation, read as \textbf{Product notation}, provides a convenient way of writing longs products, e.g.~\(x_1 \cdot x_2 \cdot x_3 \cdot ... \cdot x_{20}\) is written as \(\displaystyle \prod_{i=1}^{i=20}x_i\)
\end{itemize}

\hypertarget{inequalities}{%
\section{Inequalities}\label{inequalities}}

Given any two real numbers \(a\) and \(b\) there are three mutually exclusive possibilities:

\begin{itemize}
\tightlist
\item
  \(a > b\), meaning that \(a\) is greater than \(b\)
\item
  \(a < b\), meaning that \(a\) is less than \(b\)
\item
  \(a = b\), meaning that \(a\) is equal to \(b\)
\end{itemize}

Strict and weak

\begin{itemize}
\tightlist
\item
  inequality in \(a > b\) and \(a < b\) is \textbf{strict}
\item
  as oppose to \textbf{weak} inequality denoted as \(a \ge b\) or \(a \le b\)
\end{itemize}

Some useful relations are:

\begin{itemize}
\tightlist
\item
  if \(a > b\) and \(b > c\) then \(a > c\)
\item
  if \(a > b\) then \(a + c > b\) for any \(c\)
\item
  if \(a > b\) then \(ac > bc\) for any positive \(c\)
\item
  if \(a > b\) then \(ac < bc\) for any negative \(c\)
\end{itemize}

\hypertarget{indices-and-powers}{%
\section{Indices and powers}\label{indices-and-powers}}

\begin{itemize}
\tightlist
\item
  \textbf{Indices}, also known as \textbf{powers} are convenient when we multiply a number by itself several times
\item
  e.g.~\(5 \cdot 5 \cdot 5\) is written as \(5^3\) and \(4 \cdot 4 \cdot 4 \cdot 4 \cdot 4\) is written as \(4^5\)
\item
  in the expression \(x^y\), \(x\) is called the \emph{base} and \(y\) is called \emph{index} or \emph{power}
\end{itemize}

The laws of indices state:

\begin{itemize}
\tightlist
\item
  \(a^m \cdot a^n = a^{m+n}\)
\item
  \(\frac{a^m}{a^n} = a^{m-n}\)
\item
  \((a^m)^n = a^{m\cdot n}\)
\end{itemize}

Rules derived from the laws of indices:

\begin{itemize}
\tightlist
\item
  \(a^0 = 1\)
\item
  \(a^1 = a\)
\end{itemize}

Negative and fractional indices:

\begin{itemize}
\tightlist
\item
  \(a^{-m} = \frac{1}{a^m}\) e.g.~\(5^{-2} = \frac{1}{5^2} = \frac{1}{25}\) for negative indices
\item
  e.g.~\(4^{\frac{1}{2}} = \sqrt{4}\) or \(8^{\frac{1}{3}} = \sqrt[3]{8}\) for fractional indices
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{exercises-notations}{%
\section{Exercises: notations}\label{exercises-notations}}

\begin{exercise}
\protect\hypertarget{exr:m-notations-numbers}{}{\label{exr:m-notations-numbers} }
Classify numbers as natural, integers or real. If reall, specify if they are rational or irrational.

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  \(\frac{1}{3}\)
\item
  2
\item
  \(\sqrt{4}\)
\item
  2.3
\item
  \(\pi\)
\item
  \(\sqrt{5}\)
\item
  -7
\item
  0
\item
  0.25
\end{enumerate}
\end{exercise}

\begin{exercise}
\protect\hypertarget{exr:m-notations-variables-constants}{}{\label{exr:m-notations-variables-constants} }Classify below descriptors as variables or constants. Do you know the letters or symbols commonly used to represent these?

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  speed of light in vacuum
\item
  mass of an apple
\item
  volume of an apple
\item
  concentration of vitamin C in an apple
\item
  distance from Stockholm central station to Uppsala central station
\item
  time on the train to travel between the above stations
\item
  electron charge
\end{enumerate}
\end{exercise}

\begin{exercise}
\protect\hypertarget{exr:m-notations-sigma-product}{}{\label{exr:m-notations-sigma-product} }Write out explicitly what is meant by the following:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  \(\displaystyle \sum_{i=1}^{i=6}k_i\)
\item
  \(\displaystyle \prod_{i=1}^{i=6}k_i\)
\item
  \(\displaystyle \sum_{i=1}^{i=6}i^k\)
\item
  \(\displaystyle \prod_{i=1}^{i=3}i^k\)
\item
  \(\displaystyle \sum_{i=1}^{n}i\)
\item
  \(\displaystyle \sum_{i=1}^{i=4}(i + 1)^k\)
\item
  \(\displaystyle \prod_{i=1}^{i=4}(k + 1)^i\)
\item
  \(\displaystyle \prod_{i=0}^{n}i\)
\end{enumerate}
\end{exercise}

\begin{exercise}
\protect\hypertarget{exr:m-notations-sigma-product-reverse}{}{\label{exr:m-notations-sigma-product-reverse} }
Use Sigma or Product notation to represent the long sums and products below:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  \(1+2+3+4+5+6\)
\item
  \(2^2+3^2+4^2+5^2\)
\item
  \(4 \cdot 5 \cdot 6 \cdot 7 \cdot 8\)
\item
  \(1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + \frac{1}{5} +...+ \frac{1}{n}\)
\item
  \(2-2^2+2^3-2^4 + ...+2^n\)
\item
  \(3+6+9+12+···+60\)
\item
  \(3x + 6x^2 + 9x^3 + 12x^4 +...+60x^{20}\)
\item
  \(3x \cdot 6x^2 \cdot 9x^3 \cdot 12x^4 \cdot...\cdot 60x^{20}\)
\end{enumerate}
\end{exercise}

\hypertarget{answers-to-selected-exercises-notations}{%
\section*{Answers to selected exercises (notations)}\label{answers-to-selected-exercises-notations}}
\addcontentsline{toc}{section}{Answers to selected exercises (notations)}

Exr. \ref{exr:m-notations-numbers}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  real, rational
\item
  natural and integers, integers include natural numbers
\item
  \(\sqrt{4} = 2\) so it is a natural number and/subset of integers
\item
  real number, rational as it could be written as \(\frac{23}{10}\)
\item
  real number, irrational as it cannot be explained by a simple fraction
\item
  real number, irrational as it cannot be explained by a simple fraction
\item
  integer, non a natural number as these do not include negative numbers
\item
  natural number, although there is some argument about it as some define natural numbers as positive integers starting from 1, 2 etc. while others include 0.
\item
  real, rational number, could be written as \(\frac{25}{100}\)
\end{enumerate}

Exr. \ref{exr:m-notations-variables-constants}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  constant, speed of light in vacuum is a constant, denoted \(c\) with \(c=299 792 458 \frac{m}{s}\)
\item
  variable, mass of an apple is a variable, different for different apple sizes, for instance 138 grams, denoted as \(m = 100 g\)
\item
  variable, like mass volume can be different from apple to apple, denoted as \(V\), e.g.~\(V = 200 cm^3\)
\item
  variable, like volume and mass can vary, denoted as \(\rho_i\) and defined as \(\rho_i=\frac{m}{V}\). So given 6.3 milligrams of vitamin C in our example apple, we have \(\rho_i=\frac{0.0063}{2}\frac{g}{cm^3} = 0.0000315 \frac{g}{cm^3}\) concentration of vitamin D
\item
  constant, the distance between Stockholm and Uppsala is fixed; it could be a variable though if we were to consider an experiment on a very long time scale; distance is often denoted in physics as \(d\)
\item
  variable, time on the train to travel between the stations varies, often denoted as \(t\) with speed being calculated as \(s = \frac{d}{t}\)
\item
  constant, electron charge is \(e = 1.60217663\cdot10^{-19} C\)
\end{enumerate}

Exr. \ref{exr:m-notations-sigma-product}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  \(\displaystyle \sum_{i=1}^{i=6}k_i = k_1 + k_2 + k_3 + k_4 + k_5 + k_6\)
\item
  \(\displaystyle \prod_{i=1}^{i=6}k_i = k_1 \cdot k_2 \cdot k_3 \cdot k_4 \cdot k_5 \cdot k_6\)
\item
  \(\displaystyle \sum_{i=1}^{i=3}i^k = 1^k + 2^k + 3^k\)
\item
  \(\displaystyle \prod_{i=1}^{i=3}i^k = 1^k \cdot 2^k \cdot 3^k\)
\item
  \(\displaystyle \sum_{i=1}^{n}i = 1 + 2 + 3 + ... + n\) we are using dots (\ldots) to represent all the number until \(n\). Here, thanks to Gauss we can also write \(\displaystyle \sum_{i=1}^{n}i = \frac{n(n+1)}{2}\), i.e.~Gauss formula for sum of first \(n\) natural numbers
\end{enumerate}

Exr. \ref{exr:m-notations-sigma-product-reverse}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  \(1+2+3+4+5+6 = \displaystyle \sum_{k=1}^{6}k\)
\item
  \(2^2+3^2+4^2+5^2 = \displaystyle \sum_{x=2}^{5}x^2\)
\item
  \(4 \cdot 5 \cdot 6 \cdot 7 \cdot 8 = \displaystyle \prod_{x=4}^{8}x\)
\item
  \(1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + \frac{1}{5} + ... + \frac{1}{n} = \displaystyle \sum_{k=1}^{n}\frac{1}{k}\)
\end{enumerate}

\hypertarget{sets}{%
\chapter{Sets}\label{sets}}

\textbf{Aims}

\begin{itemize}
\tightlist
\item
  to introduce sets and basic operations on sets
\end{itemize}

\textbf{Learning outcomes}

\begin{itemize}
\tightlist
\item
  to be able to explain what a set is
\item
  to be able to construct new sets from given sets using the basic set operations
\item
  to be able to use Venn diagrams to shows all possible logical relations between two and three sets
\end{itemize}

\hypertarget{definitions}{%
\section{Definitions}\label{definitions}}

\begin{itemize}
\tightlist
\item
  \textbf{set}: a well-defined collection of distinct objects, e.g.~\(S = \{2, 4, 6\}\)
\item
  \textbf{elements}: the objects that make up the set are also known as \textbf{elements} of the set
\item
  if \(x\) is an element of \(S\), we say that \(x\) belongs to \(S\) and write \(x \in S\) and if \(x\) is not an element of \(S\) we say that \(x\) does not belong to \(S\) and write \(x \notin S\)
\item
  a set may contain \textbf{finitely} many or \textbf{infinitely} many elements
\end{itemize}

\begin{itemize}
\tightlist
\item
  \textbf{subset, \(\subseteq\)}: if every element of set A is also in B, then A is said to be a subset of B, written as \(A \subseteq B\) and pronounced A is contained in B, e.g.~\(A \subseteq B\), when \(A = \{2, 4, 6\}\) and \$ = \(B = \{2, 4, 6, 8, 10\}\). Every set is a subset if itself.
\item
  \textbf{superset}: for our outs \(A\) and \(B\) we can also say that \(B\) is a \textbf{superset} of \(A\) and write \(B \supset A\)
\end{itemize}

\begin{itemize}
\tightlist
\item
  \textbf{cardinality}: the number of elements within a set \(S\), denoted as \(|S|\)
\item
  \textbf{empty set, \(\emptyset\)}: is a unique set with no members, denoted by \(E = \emptyset\) or \(E = \{\}\). The empty set is a subset of very set.
\end{itemize}

\hypertarget{basic-set-operations}{%
\section{Basic set operations}\label{basic-set-operations}}

\begin{itemize}
\tightlist
\item
  \textbf{union of two sets, \(\cup\) }: two sets can be ``added'' together, the union of A and B, written as \(A \cup B\), e.g.~\(\{1, 2\} \cup \{2, 3\} = \{1, 2, 3\}\) or \(\{1, 2, 3\} \cup \{1, 4, 5, 6\} = \{1, 2, 3, 4, 5, 6\}\)
\item
  \textbf{intersection of two sets, \(\cap\)}: a new set can be constructed by taking members of two sets that are ``in common'', written as \(A \cap B\), e.g.~\(\{1, 2, 3, 4, 5, 6\} \cap \{2, 3, 7\} = \{2, 3\}\) or \(\{1, 2, 3\} \cap \{7 \} = \{\emptyset \}\)
\end{itemize}

\begin{itemize}
\tightlist
\item
  \textbf{complement of a set, \(A'\), \(A^c\)}: are the elements not in A
\item
  \textbf{difference of two sets, \(\setminus\)}: two sets can be ``substracted'', denoted by \(A \setminus B\), by taking all elements that are members of A but are not members of B, e.g.~\(\{1, 2, 3, 4\} \setminus \{1, 3\} = \{2, 4\}\). This is also in other words a relative complement of A with respect to B.
\end{itemize}

\begin{itemize}
\tightlist
\item
  \textbf{partition of a set}: a partition of a set S is a set of nonempty subset of S, such that every element x in S is in exactly one of these subsets. That is, the subset are pairwise \emph{disjoint}, meaning no two sets of the partition contain elements in common, and the union of all the subset of the partition is S, e.g.~Set \(\{1, 2, 3\}\) has five partitions: i) \(\{1\}, \{2\}, \{3\}\), ii) \(\{1, 2\}, \{3\}\), iii) \(\{1,3\}, \{2\}\), iv) \(\{1\}, \{2, 3\}\) and v) \(\{1,2,3\}\)
\end{itemize}

\hypertarget{venn-diagrams}{%
\section{Venn diagrams}\label{venn-diagrams}}

Venn diagram is a diagram that shows all possible logical relations between a finite collection of different sets. A Venn diagrams shows elements as points in the plane, and sets as regions inside closed curves. A Venn diagram consists of multiple overlapping closed curves, usually circles, each representing a set.

E.g. given \(A = \{1, 2, 5\}\) and \(B = \{1, 6\}\) Venn diagram of \(A\) and \(B\):

\begin{center}\includegraphics{102-math-sets_files/figure-latex/unnamed-chunk-2-1} \end{center}

And given \(A = \{1, 2, 5\}\), \(B = \{1, 6\}\) and \(C= \{4, 7\}\) Venn diagram of \(A\), \(B\) and \(C\):

\begin{center}\includegraphics{102-math-sets_files/figure-latex/unnamed-chunk-3-1} \end{center}

And given \(A = \{1, 2, 3, 4, 5, 6\}\) and \(B= \{2, 4, 6\}\) Venn diagram of \(A\) and \(B\):

\begin{center}\includegraphics{102-math-sets_files/figure-latex/unnamed-chunk-4-1} \end{center}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{exercises-sets}{%
\section{Exercises: sets}\label{exercises-sets}}

\begin{exercise}
\protect\hypertarget{exr:m-sets-01}{}{\label{exr:m-sets-01} }
Given set \(S = \{1, 2, 3, 4, 5, 6\}\):

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  what is the subset \(T\) of \(S\) consisting of its even elements?
\item
  what is the complement \(T^c\)?
\item
  what is the subset \(U\) of \(S\) containing of the prime numbers in \(S\)?
\item
  what is the intersection \(T \cap U\)?
\item
  what is the union of \(T \cup U\)?
\item
  what is the set difference \(U \setminus T\)?
\end{enumerate}
\end{exercise}

\begin{exercise}
\protect\hypertarget{exr:m-sets-02}{}{\label{exr:m-sets-02} }
Given set \[A = \{cat, elephant, dog, turtle, goldfish, hamster, parrot, tiger, guinea pig, lion\}\]

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  what is the subset \(D\) of \(A\) consiting of domesticated animals?
\item
  what is the subset \(C\) of \(A\) consiting of Felidae (cat) family?
\item
  what is the interection of \(D\) and \(C\)?
\item
  what is the complement of \(D\), \(D^c\)?
\item
  what is the union of \(D\) and \(C\)?
\item
  what is the set difference of \(A \setminus C\)?
\item
  can you draw Venn diagram showing relationship between \(D\) and \(C\)?
\end{enumerate}
\end{exercise}

\hypertarget{answers-to-selected-exercises-sets}{%
\section*{Answers to selected exercises (sets)}\label{answers-to-selected-exercises-sets}}
\addcontentsline{toc}{section}{Answers to selected exercises (sets)}

Exr. \ref{exr:m-sets-01}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  \(T = \{2, 4, 6\}\)
\item
  \(T^c = \{1, 3, 5\}\), i.e.~\(T^c\) contains all the elements of \(S\) not in \(T\)
\item
  \(U = \{2, 3, 5\}\), the primes in \(S\)
\item
  \(T \cap U = \{2\}\), common elements of \(T\) and \(U\), i.e.~the even and prime numbers
\item
  \(T \cup U = \{2, 3, 4, 5, 6\}\)
\item
  \(U \setminus T = \{3, 5\}\), consisting of the elements of \(U\) that are not in \(T\)
\end{enumerate}

\hypertarget{functions}{%
\chapter{Functions}\label{functions}}

\textbf{Aims}

\begin{itemize}
\tightlist
\item
  to revisit the concept of a function
\end{itemize}

\textbf{Learning outcomes}

\begin{itemize}
\tightlist
\item
  to be able to explain what function, function domain and function range are
\item
  to be able to identify input, output, argument, independent variable, dependent variable
\item
  to be able to evaluate function for a given value and plot the function
\end{itemize}

\hypertarget{definitions}{%
\section{Definitions}\label{definitions}}

\begin{figure}

{\centering \includegraphics{figures/precourse/math-functions-definition} 

}

\caption{Formal function defition}\label{fig:func-def}
\end{figure}

\begin{itemize}
\tightlist
\item
  A \textbf{function}, \(f(x)\), can be viewed as a rule that relates input \(x\) to an output \(f(x)\)
\item
  In order for a rule to be a function it must produce a single output for any given input
\item
  Input \(x\) is also known as \textbf{argument} of the function
\item
  \textbf{Domain of a function}: the set of all values that the function ``maps''
\item
  \textbf{Range}: the set of all values that the function maps into
\end{itemize}

\textbf{Many names are used interchangeably}

Functions have been around for a while and there are many alternative names and writing conventions are being used. Common terms worth knowing:

\begin{figure}

{\centering \includegraphics{figures/precourse/math-functions-terms} 

}

\caption{Common function terms}\label{fig:func-ters}
\end{figure}

\hypertarget{evaluating-function}{%
\section{Evaluating function}\label{evaluating-function}}

To evaluate a function is to replace (substitute) its variable with a given number or expression. E.g. given a rule (function) that maps temperature measurements from Celsius to Fahrenheit scale:
\[f(x) = 1.8x + 32\]
where \(x\) is temperature measurements in Celsius and \(f(x)\) is the associated value in Fahrenheit, we can find for a given temperature in Celsius corresponding temperature in Fahrenheit. Let's say we measure 10 Celsius degrees one autumn day in Uppsala and we want to share this information with a friend in USA. We can find the equivalent temperature in Fahrenheit by evaluating our function at 10, \(f(10)\), giving us \[f(10) = 1.8\cdot 10 + 32 = 50\]

\hypertarget{plotting-function}{%
\section{Plotting function}\label{plotting-function}}

Function graphs are a convenient way of showing functions, by looking at the graph it is easier to notice function's properties, e.g.~for which input values functions yields positive outcomes or whether the function is increasing or decreasing. To graph a function, one can start by evaluating function at different values for the argument \(x\) obtaining \(f(x)\), plotting the points by plotting the pairs \((x, f(x))\) and connecting the dots. E.g. evaluating our above temperature rule at -20, -10, 0, 10, 20, 30 Celsius degrees results in:

\begin{longtable}[]{@{}ccc@{}}
\toprule
x (Celsius degrees) & evaluates & f(x) (Farenheit degress)\tabularnewline
\midrule
\endhead
-20 & \(f(-20) = 1.8 \cdot (-20) + 32\) & -4\tabularnewline
-10 & \(f(-20) = 1.8 \cdot (-10) + 32\) & 14\tabularnewline
0 & \(f(-20) = 1.8 \cdot (0) + 32\) & 32\tabularnewline
10 & \(f(-20) = 1.8 \cdot (10) + 32\) & 50\tabularnewline
20 & \(f(-20) = 1.8 \cdot (20) + 32\) & 68\tabularnewline
20 & \(f(-20) = 1.8 \cdot (30) + 32\) & 86\tabularnewline
\bottomrule
\end{longtable}

\begin{figure}

{\centering \includegraphics{103-math-functions_files/figure-latex/unnamed-chunk-2-1} 

}

\caption{Graph of f(x) for the temeprature rule}\label{fig:unnamed-chunk-2}
\end{figure}

\hypertarget{standard-classes-of-functions}{%
\section{Standard classes of functions}\label{standard-classes-of-functions}}

\textbf{Algebraic function}: functions that can be expressed as the solution of a polynomial equation with integer coefficients, e.g.~

\begin{itemize}
\tightlist
\item
  constant function \(f(x) = a\)
\item
  identity function \(f(x) = x\)
\item
  linear function \(f(x) = ax + b\)
\item
  quadratic function \(f(x) = a + bx + cx^2\)
\item
  cubic function \(fx() = a + bx + cx^2 + dx^3\)
\end{itemize}

\textbf{Transcedental functions}: functions that are not algebraic, e.g.~

\begin{itemize}
\tightlist
\item
  exponential function \(f(x) = e^x\)
\item
  logarithimic function \(f(x) = log(x)\)
\item
  trigonometric function \(f(x) = -3sin(2x)\)
\end{itemize}

\begin{figure}

{\centering \includegraphics{103-math-functions_files/figure-latex/unnamed-chunk-3-1} 

}

\caption{Examples of the standard classess of functions}\label{fig:unnamed-chunk-3}
\end{figure}

\hypertarget{piecewise-functions}{%
\section{Piecewise functions}\label{piecewise-functions}}

A function can be in pieces, i.e.~we can create functions that behave differently based on the input \(x\) value. They are useful to describe situations in w which a rule changes as the input value crosses certain ``boundaries''. E.g. a function value could be fixed in a given range and equal to the input value (identify function) for input values outside this range

\begin{equation}
    f(x) =
    \left\{
        \begin{array}{cc}
                2 & \mathrm{if\ } x \le 1 \\
                x & \mathrm{if\ } x>1 \\
        \end{array}
    \right.
\end{equation}

The function can be split in many pieces, e.g.~the personal training fee in SEK may depend whether the personal trainer is hired for an hour, two hours or three or more hours:
\begin{equation}
    f(h) =
    \left\{
        \begin{array}{cc}
                500  & \mathrm{if\ } h \le 1 \\
                750  & \mathrm{if\ } 1 < h \le 2 \\
                500 + 250 \cdot h & \mathrm{if\ } h > 2 \\
        \end{array}
    \right.
\end{equation}

\begin{figure}

{\centering \includegraphics{103-math-functions_files/figure-latex/unnamed-chunk-4-1} 

}

\caption{Examples of piece-wise functions}\label{fig:unnamed-chunk-4}
\end{figure}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{exercises-functions}{%
\section{Exercises: functions}\label{exercises-functions}}

\begin{exercise}
\protect\hypertarget{exr:m-functions-evaluate-01}{}{\label{exr:m-functions-evaluate-01} }
Given the function for the personal trainer costs:

\begin{equation}
    f(h) =
    \left\{
        \begin{array}{cc}
                500  & \mathrm{if\ } h \le 1 \\
                750  & \mathrm{if\ } 1 < h \le 2 \\
                500 + 250 \cdot h & \mathrm{if\ } h > 2 \\
        \end{array}
    \right.
\end{equation}

How much would you pay

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  for a 4-hours session? Evaluate function f(h) for value 4.
\item
  for a 2-hour session? Evalue function f(h) for value 2.
\end{enumerate}
\end{exercise}

\begin{exercise}
\protect\hypertarget{exr:m-functions-write}{}{\label{exr:m-functions-write} }
A museum charges 50 SEK per person for a guided tour with a group of 1 to 9 people or a fixed 500 SEK fee for a group of 10 or more people. Write a function relating the number of people \(n\) to the cost \(C\).
\end{exercise}

\begin{exercise}
\protect\hypertarget{exr:m-functions-plot-evaluate}{}{\label{exr:m-functions-plot-evaluate} }
Given function

\begin{equation}
    f(x) =
    \left\{
        \begin{array}{cc}
                x^2  & \mathrm{if\ } x \le 1 \\
                3  & \mathrm{if\ } 1 < x \le 2 \\
                x & \mathrm{if\ } x > 2 \\
        \end{array}
    \right.
\end{equation}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  sketch a graph of a function for \(x \in (-4, 4)\), i.e.. for \(x\) between -4 and 4
\item
  evaluate function at f(1)
\item
  evaluate function at f(4)
\end{enumerate}
\end{exercise}

\hypertarget{answers-to-selected-exercises-functions}{%
\section*{Answers to selected exercises (functions)}\label{answers-to-selected-exercises-functions}}
\addcontentsline{toc}{section}{Answers to selected exercises (functions)}

Exr. \ref{exr:m-functions-evaluate-01}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  \(f(4) = 500 + 250 \cdot 4 = 1500\)
\item
  \(f(2) = 750\) as \(h \le 2\) means less or equal to 2, that is including 2
\end{enumerate}

\hypertarget{differentiation}{%
\chapter{Differentiation}\label{differentiation}}

\textbf{Aims}

\begin{itemize}
\tightlist
\item
  introduce the concept of differentiation and rules of differentiation
\end{itemize}

\textbf{Learning outcomes}

\begin{itemize}
\tightlist
\item
  to be able to explain differentiation in terms of rate of change
\item
  to be able to find derivatives in simple cases
\end{itemize}

\hypertarget{rate-of-change}{%
\section{Rate of change}\label{rate-of-change}}

\begin{itemize}
\tightlist
\item
  We are often interested in the rate at which some variable is changing, e.g.~we may be interested in the rate at which the temperature is changing or the rate of water levels increasing
\item
  Rapid or unusual changes may indicate that we are dealing with unusual situations, e.g.~global warming or a flood
\item
  Rates of change can be positive, negative or zero corresponding to a variable increasing, decreasing and non-changing
\end{itemize}

\begin{figure}

{\centering \includegraphics{104-math-differentiation_files/figure-latex/diff-rate-1} 

}

\caption{The function $f(x)$ changes at different rates for different values of $x$}\label{fig:diff-rate}
\end{figure}

The function \(f(x) = x^4 - 4x^3 - x^2 - e^{-x}\) changes at different rates for different values of \(x\), e.g.~

\begin{itemize}
\tightlist
\item
  between \(x \in (-10, -9)\) the \(f(x)\) is increasing at slightly higher pace than \(x \in (5,6)\)
\item
  between \(x \in (-7, -5)\) the \(f(x)\) is decreasing and
\item
  between \(x \in (0, 1)\) the \(f(x)\) is not changing
\item
  to be able to talk more precisely about the rate of change than just saying ``large and positive'' or ``small and negative'' change we need to quantify the changes, i.e.~assign the rate of change an exact value
\item
  \textbf{Differentiation} is a technique for calculating the rate of change of any function
\end{itemize}

\hypertarget{average-rate-of-change-across-an-interval}{%
\section{Average rate of change across an interval}\label{average-rate-of-change-across-an-interval}}

\begin{figure}

{\centering \includegraphics{figures/precourse/math-differentiation-01} 

}

\caption{The average rate of change of $f(x)$ with respect to $x$ over $[a, b]$ is equal to the slope of the secant line (in black)}\label{fig:diff-01}
\end{figure}

To dive further into calculating the rate of change let's look at Figure \ref{fig:diff-01} and define the \emph{average rate of change} of a function across an interval. Figure \ref{fig:diff-01} shows a function \(f(x)\) with two possible argument values \(a\) and \(b\) marked and their corresponding function values \(f(a)\) and \(f(b)\).

Consider that \(x\) is increasing from \(a\) to \(b\). The change in \(x\) is \(b-a\), i.e.~as \(x\) increases from \(a\) to \(b\) the function \(f(x)\) increase from \(f(a)\) to \(f(b)\). The change in \(f(x)\) is \(f(b)-f(a)\) and the average rate of change of \(y\) across the \([a,b]\) interval is:

\begin{equation}
\frac{change\:in\:y}{change\:in\:x}=\frac{f(b)-f(a)}{b-a}
\label{eq:diff-point}
\end{equation}

E.g. let's take a quadratic function \(f(x)=x^2\) and calculate the average rate of change across the interval \([1, 4]\).

\begin{itemize}
\tightlist
\item
  The change in \(x\) is \(4-1\) and the change in \(f(x)\) is \(f(4) - f(1) = 4^2 -1^2 = 16 - 1 = 15\). So the average rate of change is \(\frac{15}{3}=5\). What does this mean? It means that across the interval \([1,4]\) on average the \(f(x)\) value increases by 5 for every 1 unit increase in \(x\).
\item
  If we were to look at the average rate of change across the interval \([-2, 0]\) we would get \(\frac{f(0)-f(-2)}{0 - (-2)}=\frac{0 - (-2)^2}{2}=\frac{-4}{2} = -2\). Here, over the \([-2, 0]\) on average the \(f(x)\) value decreases by 2 for every 1 unit increase in \(x\).
\item
  Looking at the graph of \(f(x)=x^2\) verifies our calculations
\end{itemize}

\begin{figure}

{\centering \includegraphics{104-math-differentiation_files/figure-latex/diff-avg-rate-1} 

}

\caption{Example function $f(x) = x^2$}\label{fig:diff-avg-rate}
\end{figure}

\hypertarget{rate-of-change-at-a-point}{%
\section{Rate of change at a point}\label{rate-of-change-at-a-point}}

\begin{itemize}
\tightlist
\item
  We often need to know the rate of change of a function at a point, and not simply an average rate of change across an interval.
\item
  Figure \ref{fig:diff-02}, similar to Figure \ref{fig:diff-01}, shows, instead of two points \(a\) and \(b\), point \(a\) and a second point defined in terms of its distance from the first point \(a\). Thus, the two points are now \(a\) and \(a + h\) and the distance between the two points is equal to \(h\).
\item
  Now we can write that:
  \[\frac{change\:in\:y}{change\:in\:x}=\frac{f(a+h)-f(a)}{a+h-a} = \frac{f(a+h)-f(a)}{h}\]
\end{itemize}

\begin{figure}

{\centering \includegraphics{figures/precourse/math-differentiation-02} 

}

\caption{The average rate of change of $f(x)$ with respect to $x$ over $[a, b]$ is equal to the slope of the secant line (in black)}\label{fig:diff-02}
\end{figure}

Further:

\begin{itemize}
\tightlist
\item
  if we assume that the second point \(a+h\) is really close to \(a\), meaning that \(h\) approaches 0, denoted as \(h \rightarrow 0\), we can find the rate of change at the point \(a\)
\item
  the distance between the two points \(a\) and \(a+h\) is getting smaller and so is the difference of the function values \(f(a+h) - f(a)\). We denote these small differences as \(\delta x\) and \(\delta y\), pronounced ``delta x'' and ``delta y'', respectively.
\item
  the term \(\delta\) reads as ``delta'' and represents a small change
\end{itemize}

We can thus continue and write that a \textbf{rate of change of a function at a point} is given by
\begin{equation}
\frac{small\:change\:in\:y}{small\:change\:in\:x} = \lim_{h\to0}\frac{f(a+h)-f(a)}{h}
\label{eq:diff-point}
\end{equation}

E.g. let's look at the linear function \(f(x) = 2x+3\). We can find the rate of change at any point of \(x\) by:
\[\frac{small\:change\:in\:y}{small\:change\:in\:x} = \\\frac{f(x+h)-f(x)}{x+h-x}= \lim_{h\to0}\frac{2(x+h)+3-(2x+3)}{x+h-x}=\lim_{h\to0}\frac{2h}{h}=2\]
It means that the function value \(f(x)\) increases by 2 for every small increase, \(h\), in \(x\). Here, this increase is the same for all the values of \(x\), i.e.~it does not depend on \(x\). \textbf{The change in function value \(f(x)\) can depend} on the value of \(x\), for instance if we look at the quadratic \(f(x)=x^2\) function, we get:
\[\frac{small\:change\:in\:y}{small\:change\:in\:x} = \\ \frac{f(x+h)-f(x)}{x+h-x}=\lim_{h\to0}\frac{x^2+2xh+h^2-x^2}{h}=\lim_{h\to0}\frac{2xh+h^2}{h}=2x+h\]
This means that:

\begin{itemize}
\tightlist
\item
  the rate of change for the function \(f(x)\) at a point \(x\) is \(2x\)
\item
  the \(f(x)\) value increases by \(2x\) for every small increase, \(h\), in \(x\)
\item
  the rate of change along a quadratic function is changing constantly according to the value of \(x\) we are looking at, it is a function of \(x\)
\item
  and finally that the rate of change does not give us any information about the rate of change globally.
\end{itemize}

\hypertarget{terminology-and-notation}{%
\section{Terminology and notation}\label{terminology-and-notation}}

\begin{itemize}
\tightlist
\item
  \textbf{differentiation} is the process of finding the rate of change of a given function
\item
  the function is said to be \textbf{differentiated}
\item
  the rate of change of a function is also known as the \textbf{derivative} of the function
\item
  given a function \(f(x)\) we say that we differentiate function in respect to \(x\) and write:
\end{itemize}

\[\lim_{h\to0}\frac{\delta y}{\delta x}= \frac{dy}{dx}\]

or use the ``prime'' \[f´(x)\]

\hypertarget{table-of-derivatives}{%
\section{Table of derivatives}\label{table-of-derivatives}}

\begin{itemize}
\tightlist
\item
  in practice, there is no need to compute \(\displaystyle \lim_{h\to0}\frac{\delta y}{\delta x}\) every time when we want to find a derivative of a function
\item
  instead, we can use patterns of the common functions and their derivatives
\end{itemize}

\begin{longtable}[]{@{}cc@{}}
\caption{\label{tab:diff-table} Common functions and their derivatives, \(k\) denotes a constant}\tabularnewline
\toprule
Function \(f(x)\) & Derivative \(f'(x)\)\tabularnewline
\midrule
\endfirsthead
\toprule
Function \(f(x)\) & Derivative \(f'(x)\)\tabularnewline
\midrule
\endhead
\(k\) & \(0\)\tabularnewline
\(x\) & \(1\)\tabularnewline
\(kx\) & \(k\)\tabularnewline
\(x^n\) & \(nx^{n-1}\)\tabularnewline
\(kx^n\) & \(knx^{n-1}\)\tabularnewline
\(e^x\) & \(e^x\)\tabularnewline
\(e^{kx}\) & \(ke^{kx}\)\tabularnewline
\(\ln(x)\) & \(\frac{1}{x}\)\tabularnewline
\(\ln(kx)\) & \(\frac{1}{x}\)\tabularnewline
\bottomrule
\end{longtable}

We can use the Table \ref{tab:diff-table} to find derivatives of some of the functions e.g.

\begin{itemize}
\tightlist
\item
  \(f(x) = 3x\), \(f'(x) = 3\)
\item
  \(f(x) = 2x^4\), \(f'(x) = 2*4x^{4-1} = 8x^3\)
\item
  \(f(x) = e^{2x}\), \(f'(x) = 2e^{2x}\)
\item
  \(f(x) = \ln(4x)\), \(f'(x) = \frac{1}{x}\)
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{exercises-differentiation}{%
\section{Exercises (differentiation)}\label{exercises-differentiation}}

\begin{exercise}
\protect\hypertarget{exr:m-diff}{}{\label{exr:m-diff} }
\# Find derivatives of the functions

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  \(f(x) = 2\)
\item
  \(f(x) = 2x + 1\)
\item
  \(f(x) = 5x^2\)
\item
  \(f(x) = 4x^3 + x^2\)
\item
  \(f(x) = \sqrt(x)\)
\item
  \(f(x) = \ln(2x)\)
\item
  \(f(x) = e^{x}\)
\item
  \(f(x) = \frac{9}{x^2} + ln(4x)\)
\item
  \(f(x) = 4x−6x^6\)
\item
  \(f(x) = \frac{3}{x^2}\)
\end{enumerate}
\end{exercise}

\hypertarget{answers-to-selected-exercises-differentiation}{%
\section*{Answers to selected exercises (differentiation)}\label{answers-to-selected-exercises-differentiation}}
\addcontentsline{toc}{section}{Answers to selected exercises (differentiation)}

Exr. \ref{exr:m-diff}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  \(f(x) = 2\), \(f'(x) = 0\)
\item
  \(f(x) = 2x + 1\), \(f'(x) = 2\)
\item
  \(f(x) = 5x^2\), \(f'(x)= 10x\)
\item
  \(f(x) = 4x^3 + x^2\), \(f'(x)=12x^2 + 2x\)
\item
  \(f(x) = \sqrt(x) = x^{\frac{1}{2}}\), \(f'(x)=\frac{1}{2}x^{\frac{1}{2}-1} = \frac{1}{2}x^{-\frac{1}{2}}\)
\item
  \(f(x) = \ln(2x)\), \(f'(x) = \frac{1}{x}\)
\item
  \(f(x) = e^{x}\), \(f'(x) = e^x\)
\end{enumerate}

\hypertarget{integration}{%
\chapter{Integration}\label{integration}}

\textbf{Aims}

\begin{itemize}
\tightlist
\item
  to introduce the concept of integration
\end{itemize}

\textbf{Learning outcomes}

\begin{itemize}
\tightlist
\item
  to be able to explain what integration is
\item
  to be able to explain the relationship between differentiation and integration
\item
  to be able to integrate simple functions
\item
  to to able to use integration to calculate the area under the curve in simple cases
\end{itemize}

\hypertarget{reverse-to-differentiation}{%
\section{Reverse to differentiation}\label{reverse-to-differentiation}}

\begin{itemize}
\tightlist
\item
  when a function \(f(x)\) is known we can differentiate it to obtain the derivative \(f'(x)\)
\item
  the reverse process is to obtain \(f(x)\) from the derivative
\item
  this process is called \textbf{integration}
\item
  apart from simple reversing differentiation integration comes very useful in finding \textbf{areas under curves}, i.e.~the area above the x-axis and below the graph of \(f(x)\), assuming that \(f(x)\) is positive
\item
  the symbol for integration is \(\int\) and is known as ``integral sign''
\end{itemize}

E.g. let's take a function \(f(x) = x^2\). Suppose we only have a derivative, which is \(f'(x) = 2x\) and we would like to find the function given this derivative. Formally we write: \[\int 2x dx = x^2 +c\]

where:

\begin{itemize}
\tightlist
\item
  the term \(2x\) within the integral is called the \textbf{integrand}
\item
  the term \(dx\) indicates the name of the variable involved, here \(x\)
\item
  \(c\) is \textbf{constant of integration}
\end{itemize}

\hypertarget{what-is-constant-of-integration}{%
\section{What is constant of integration?}\label{what-is-constant-of-integration}}

\begin{itemize}
\tightlist
\item
  Integration reverses the process of differentiation, here, given our example function \(f(x) = x^2\) that we pretended we do not know, we started with the derivative \(f´(x) = 2x\) and via integration we obtained back the very function \[\int 2x dx = x^2\]
\item
  However, many function can result in the very same derivative since the derivative of a constant is 0 e.g.~a derivatives of \(f(x) = x^2\), \(f(x) = x^2 + 10\) and \(f(x) = x^2 + \frac{1}{2}\) all equal to \(f'(x) = 2x\)
\item
  We have to take this into account when we are integrating, i.e.~reverting differentiation. As we have no way of knowing what the original function constant is, we add it in form of \(c\), i.e.~unknown constant, called the constant of integration.
\end{itemize}

\hypertarget{table-of-integrals}{%
\section{Table of integrals}\label{table-of-integrals}}

Similar to differentiation, in practice we can use tables of integrals to be able to find integrals in simple cases

\begin{longtable}[]{@{}cc@{}}
\caption{\label{tab:int-table} Common functions and their integrals, \(k\) denotes a constant}\tabularnewline
\toprule
Function \(f(x)\) & Integral \(\int f(x) dx\)\tabularnewline
\midrule
\endfirsthead
\toprule
Function \(f(x)\) & Integral \(\int f(x) dx\)\tabularnewline
\midrule
\endhead
\(constant\:k\) & \(kx + c\)\tabularnewline
\(x\) & \(\frac{x^2}{2}+c\)\tabularnewline
\(kx\) & \(k\frac{x^2}{2}+c\)\tabularnewline
\(x^n\) & \(\frac{x^{n+1}}{n+1}+c\;\; if\;n\neq-1\)\tabularnewline
\(kx^n\) & \(k\frac{x^{n+1}}{n+1}+c\)\tabularnewline
\(e^x\) & \(e^x+c\)\tabularnewline
\(e^{kx}\) & \(\frac{e^{kx}}{k}+c\)\tabularnewline
\(\frac{1}{x}\) & \(\ln(x)+c\)\tabularnewline
\bottomrule
\end{longtable}

E.g.

\begin{itemize}
\tightlist
\item
  \(\int 4x^3 dx = \frac{4x^{3+1}}{3+1}=x^4 + c\)
\item
  \(\int (x^2 + x) dx = \frac{x^3}{3} + \frac{x^2}{2} +c\) (note: we can evaluate integrals separately and add them as integration as differentiation is linear)
\end{itemize}

\hypertarget{definite-integrals}{%
\section{Definite integrals}\label{definite-integrals}}

\begin{itemize}
\item
  the above examples of integrals are \textbf{indefinite integrals}, the result of finding an indefinite integral is usually a function plus a constant of integration
\item
  we have also \textbf{definite integrals}, so called because the result is a definite answer, usually a number, with no constant of integration
\item
  definite integrals are often used to areas bounded by curves or, as we will cover later on, estimating probabilities
\item
  we write: \[\int_{a}^bf(x)dx\] where:
\item
  \(\int_{a}^bf(x)dx\) is called the definite integral of \(f(x)\) from \(a\) to \(b\)
\item
  the numbers \(a\) and \(b\) are known as lower and upper limits of the integral
\end{itemize}

E.g. let's look at the function \(f(x) = x\) plotted below and calculate a definite integral from \(0\) to \(2\).

\begin{figure}

{\centering \includegraphics{105-math-integration_files/figure-latex/int-area-1} 

}

\caption{Graph of function $f(x) = x$}\label{fig:int-area}
\end{figure}

We write \[\int_{0}^2f(x)dx = \int_{0}^2 xdx =  \Bigr[ \frac{1}{2}x^2\Bigr]_0^2 = \frac{1}{2}(2)^2 - \frac{1}{2}(0)^2 = 2\] so first find the integral and then we evaluate it at upper limit and subtracting the evaluation at the lower limit. Here, the result it 2. What would be the result if you tried to calculate the triangle area on the above plot, area defined by the blue vertical lines drawn at 0 and 2 and horizontal x-axis? The formula for the triangle area is \(Area = \frac{1}{2}\cdot base \cdot height\) so here \(Area = \frac{1}{2} \cdot 2 \cdot 2 = 2\) the same result as achieved with integration.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{exercises-integration}{%
\section{Exercises (integration)}\label{exercises-integration}}

\begin{exercise}
\protect\hypertarget{exr:m-int}{}{\label{exr:m-int} }
Integrate:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  \(\int 2 \cdot dx\)
\item
  \(\int 2x\cdot dx\)
\item
  \(\int (x^4 + x^2 + 1)\cdot dx\)
\item
  \(\int e^x\cdot dx\)
\item
  \(\int e^{2x}\cdot dx\)
\item
  \(\int \frac{2}{x}\cdot dx\)
\item
  \(\int_2^4 2x\cdot dx\)
\item
  \(\int_0^4 (x^2+1)dx\)
\item
  \(\int (x^4 + \frac{2}{x} + e^{2x}) dx\)
\item
  \(\int_0^4 (x^4+1) dx\)
\end{enumerate}
\end{exercise}

\hypertarget{answers-to-selected-exercises-integration}{%
\section*{Answers to selected exercises (integration)}\label{answers-to-selected-exercises-integration}}
\addcontentsline{toc}{section}{Answers to selected exercises (integration)}

Exr. \ref{exr:m-int}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  \(\int 2 \cdot dx = 2x +c\)
\item
  \(\int 2x\cdot dx = \frac{2x^2}{2} = x^2 + c\)
\item
  \(\int (x^4 + x^2 + 1)\cdot dx = \frac{x^5}{5} + \frac{x^3}{3} + x + c\)
\item
  \(\int e^x\cdot dx = e^x + c\)
\item
  \(\int e^{2x}\cdot dx = \frac{1}{2}e^{2x}\)
\item
  \(\int \frac{2}{x}\cdot dx =\int 2\cdot \frac{1}{x}\cdot dx = 2 \ln{x}+ c\)
\item
  \(\int_2^4 2x\cdot dx = \Bigr[x^2\Bigr]_2^4 = 16 - 4 = 12\)
\item
  \(\int_0^4 (x^2+1)dx = \Bigr[\frac{x^3}{3} + x \Bigr]_0^4=\frac{4^3}{3}+4 - 0 = \frac{64}{3}+4 = \frac{76}{3}\)
\end{enumerate}

\hypertarget{vectors}{%
\chapter{Vectors}\label{vectors}}

\textbf{Aims}

\begin{itemize}
\tightlist
\item
  to introduce vectors and basic vectors operations
\end{itemize}

\textbf{Learning outcomes}

\begin{itemize}
\tightlist
\item
  to be able to write \(n\)-dimensional vectors using vector notations
\item
  to be able to perform addition and scalar multiplication
\item
  to be able to check if two vectors are orthogonal
\end{itemize}

A large number of statistical models use vectors and matrices, both for compact representations, and for the calculations, e.g.~parameter estimates.

\hypertarget{vectors-1}{%
\section{Vectors}\label{vectors-1}}

\begin{itemize}
\tightlist
\item
  A vector is an ordered set of number
\item
  These numbers, e.g.~in vector \(\mathbf{x}\) can be expressed as a row \(\mathbf{x}=[6\quad 0\quad 5 \dots1]\)
\item
  or as a column \(\mathbf{x}=\begin{bmatrix} 6 \\ 0 \\ 5 \\ \vdots \\ 1 \end{bmatrix}\)
\item
  the number of elements in a vector is referred to as its \textbf{dimension} and we often use \(n\) to express \(n\)-dimensional vector, where \(n\) can be any natural number
\item
  here, we denote vectors using small bold font \(\mathbf{x}\), other notations may include an arrow \(\vec x\) or overline \(\overline{x}\)
\item
  also \textbf{parentheses} are used interchangeably with \textbf{square bracket}, e.g.~\(\mathbf{x}=[6\quad 0\quad 5 \dots1]\) can be written as \(\mathbf{x}=(6\quad 0\quad 5 \dots1)\) or \(\begin{pmatrix} 6\\ 0\\ 5\\ \vdots \\ 1 \end{pmatrix}\)
\end{itemize}

\hypertarget{operations-on-vectors}{%
\section{Operations on vectors}\label{operations-on-vectors}}

Given two vectors of the same dimension:
\(\mathbf{x}=\begin{bmatrix}  x_1 \\  x_2 \\  x_3 \\  \vdots \\  x_n \end{bmatrix}\)
and
\(\mathbf{y}=\begin{bmatrix}  y_1 \\  y_2 \\  y_3 \\  \vdots \\  y_n \end{bmatrix}\)

\textbf{Addition}: we add two vectors, element by element \(\mathbf{x} + \mathbf{y}=\begin{bmatrix}  x_1 + y_1 \\  x_2 + y_2 \\  x_3 + y_3 \\  \vdots \\  x_n + y_n \end{bmatrix}\)

\textbf{Scalar multiplication}: we can multiple vector by a numerical value, scalar, denoted as \(\gamma\):
\[\gamma \cdot \mathbf{x} =\begin{bmatrix}
  \gamma \cdot x_1 \\ 
  \gamma \cdot x_2 \\
  \gamma \cdot x_3 \\
  \vdots \\
  \gamma \cdot x_n 
\end{bmatrix}\]

\textbf{Difference} \(\mathbf{x} - \mathbf{y}\) can be written as \(\mathbf{x} + (-1) \cdot \mathbf{y}\), thus we multiply second vector with \(-1\) and then add two vectors

\textbf{Linear combination of vectors}: the vector \(\gamma \cdot \mathbf{x} + \delta \cdot \mathbf{y}\) is said to be a linear combination of \(\mathbf{x}\) and \(\mathbf{y}\):
\[\gamma \cdot \mathbf{x} + \delta \cdot \mathbf{y} =\begin{bmatrix}
  \gamma \cdot x_1 + \delta \cdot y_1 \\ 
  \gamma \cdot x_2 + \delta \cdot y_2\\
  \gamma \cdot x_3 + \delta \cdot y_3\\
  \vdots \\
  \gamma \cdot x_n + \delta \cdot y_n
\end{bmatrix}\]

\textbf{Inner product of vectors} is given by: \[\mathbf{x} \cdot \mathbf{y} = x_1 \cdot y_1 + x_2 \cdot y_2 + \dots x_n \cdot y_n = \displaystyle\sum_{i=1}^{n}x_i\cdot y_i\]

\textbf{Orthogonality of vectors}: two vectors are said to be orthogonal if their inner product is zero \[\mathbf{x} \cdot \mathbf{y} =\displaystyle\sum_{i=1}^{n}x_i\cdot y_i = 0\]

\hypertarget{null-and-unit-vector}{%
\section{Null and unit vector}\label{null-and-unit-vector}}

\begin{itemize}
\tightlist
\item
  a \textbf{null vector} is a vector whose elements are all \(0\); the difference between any vector and itself yields a null vector
\item
  a \textbf{unit vector} is a vector whose elements are all \(1\)
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{exercise}
\protect\hypertarget{exr:m-vectors}{}{\label{exr:m-vectors} }Based on vector definitions and operations:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  find the vector \(\mathbf{x} + \mathbf{y}\) when \(\mathbf{x} =\begin{bmatrix}  1 \\  2 \\  5 \end{bmatrix}\) and \(\mathbf{y} =\begin{bmatrix}  0\\  3 \\  1  \end{bmatrix}\)
\item
  find the vector \(2\mathbf{x} - \mathbf{y}\) when \(\mathbf{x} =\begin{bmatrix}  -2 \\  3 \\  5 \end{bmatrix}\) and \(\mathbf{y} =\begin{bmatrix}  0\\  -4 \\  7  \end{bmatrix}\)
\item
  are \(\mathbf{u}\) and \(\mathbf{v}\) vectors orthogonal when when \(\mathbf{u} =\begin{bmatrix}  1 \\  2 \end{bmatrix}\) and \(\mathbf{v} =\begin{bmatrix}  2\\  -1  \end{bmatrix}\)?
\item
  are \(\mathbf{u}\) and \(\mathbf{v}\) vectors orthogonal when when \(\mathbf{u} =\begin{bmatrix}  3 \\  -1 \end{bmatrix}\) and \(\mathbf{v} =\begin{bmatrix}  7\\  5  \end{bmatrix}\)?
\item
  find the value \(n\) such that the vectors \(\mathbf{u} =\begin{bmatrix}  2 \\  4 \\  1 \end{bmatrix}\) and \(\mathbf{v} =\begin{bmatrix}  n\\  1 \\  8  \end{bmatrix}\) are orthogonal.
\end{enumerate}
\end{exercise}

\hypertarget{answers-to-selected-exercises-vectors-and-matrices}{%
\section*{Answers to selected exercises (vectors and matrices)}\label{answers-to-selected-exercises-vectors-and-matrices}}
\addcontentsline{toc}{section}{Answers to selected exercises (vectors and matrices)}

Exr. \ref{exr:m-vectors}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
\end{enumerate}

\[\mathbf{x} + \mathbf{y} = \begin{bmatrix} 1 \\ 2 \\ 5 \end{bmatrix} + \begin{bmatrix} 0 \\ 3 \\ 1 \end{bmatrix} = \begin{bmatrix} 1 + 0\\ 2 + 3 \\ 5 + 1 \end{bmatrix} = \begin{bmatrix} 1 \\ 5 \\ 6 \end{bmatrix}\]

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{1}
\item
  \[2\mathbf{x} - \mathbf{y} = \begin{bmatrix} 2 \cdot (-2) \\ 2 \cdot 3 \\ 2 \cdot 5 \end{bmatrix} + \begin{bmatrix} (-1) \cdot 0 \\ (-1) \cdot (-4) \\ (-1) \cdot 7 \end{bmatrix} = \begin{bmatrix} -4 \\ 6 \\ 10 \end{bmatrix}  + \begin{bmatrix} 0 \\ 4 \\ -7 \end{bmatrix}  = \begin{bmatrix} -4 + 0 \\ 6 + 4 \\ 10 - 7 \end{bmatrix} = \begin{bmatrix} -4 \\ 10 \\ 3 \end{bmatrix}\]
\item
  Yes, to check orthogonality we need to calculate the inner product of two vectors and see if it is equal to 0, here
  \(\mathbf{u} \cdot \mathbf{v} =\displaystyle\sum_{i=1}^{2}u_i\cdot v_i = 1 \cdot 2 + 2 \cdot (-1) = 2 - 2 = 0\)
\item
  No, since the inner product does not equal to 0 \[\mathbf{u} \cdot \mathbf{v} =\displaystyle\sum_{i=1}^{2}u_i\cdot v_i = 3 \cdot 7 + (-1) \cdot 5 = 21 - 5 = 16 \neq 0\]
\end{enumerate}

\hypertarget{matrices}{%
\chapter{Matrices}\label{matrices}}

\textbf{Aims}

\begin{itemize}
\tightlist
\item
  to introduce matrix and basic matrices operations
\end{itemize}

\textbf{Learning outcomes}

\begin{itemize}
\tightlist
\item
  to be able to write matrices using matrix notations
\item
  to be able to perform simple matrix operations such as adding and multiplication
\item
  to be able to find the reverse of the 2-dimensional matrix
\end{itemize}

\hypertarget{matrix}{%
\section{Matrix}\label{matrix}}

A matrix is a rectangular array of numbers e.g.~

\[\mathbf{A}=\begin{bmatrix}
  x_{11} & x_{12} & x_{13} & \dots & x_{1n} \\
  x_{21} & x_{22} & x_{23} & \dots & x_{2n} \\
  \dots & \dots & \dots& \dots & \dots\\
  x_{m1} & x_{m2} & x_{1m3} & \dots & x_{mn} \\
\end{bmatrix}\]

where:

\begin{itemize}
\tightlist
\item
  the notional subscripts in the typical element \(x_{ij}\) refers to its row and column location in the array, e.g.~\(x_{12}\) refers to element in the first row and second column
\item
  we say that matrix has \(m\) rows and \(n\) columns and the \textbf{dimension} of a matrix is defined as \(m \times n\)
\item
  a matrix can be viewed as a set of column vectors or a set of row vectors
\item
  a vector can be viewed as a matrix with only one column or with only one row
\end{itemize}

\hypertarget{special-matrices}{%
\section{Special matrices}\label{special-matrices}}

\begin{itemize}
\tightlist
\item
  A matrix with the same number of rows as columns, \(m = n\), is said to be a \textbf{square matrix}
\item
  A matrix that is not squared, \(m \neq n\) is called \textbf{rectangular matrix}
\item
  A \textbf{null matrix} is composed of all 0
\item
  An \textbf{identity matrix}, denoted as \(\mathbf{I}\) or \(\mathbf{I_n}\), is a square matrix with 1's on the main diagonal and all other elements equal to 0, e.g.~a three-dimensional identity matrix is \[\mathbf{I}=\begin{bmatrix}
  1 & 0 & 0  \\
  0 & 1 & 0  \\
  0 & 0 & 1
  \end{bmatrix}\]
\item
  A square matrix is said to be \textbf{symmetric} if \(x_{ij} = x_{ji}\) e.g.~
  \[\mathbf{A}=\begin{bmatrix}
  1 & 4 & 2  \\
  4 & 1 & 0  \\
  2 & 0 & 1
  \end{bmatrix}\]
\item
  A \textbf{diagonal matrix} is a square matrix whose non-diagonal entries are all zero, that is \(x_{ij} = 0\) for \(i \neq j\), e.g.~
  \[\mathbf{A}=\begin{bmatrix}
  1 & 0 & 0  \\
  0 & 2 & 0  \\
  0 & 0 & 3
  \end{bmatrix}\]
\item
  An \textbf{upper-triangular matrix} is a square matrix in which all entries below the diagonal are 0, that is \(x_{ij}=0\) for \(i<j\) e.g.~
  \[\mathbf{A}=\begin{bmatrix}
  1 & 3 & 4  \\
  0 & 2 & 5  \\
  0 & 0 & 3
  \end{bmatrix}\]
\item
  A \textbf{lower-triangular matrix} is a square matrix in which all entries above the digonal are 0, that is hat is \(x_{ij}=0\) for \(i>j\) e.g.~
  \[\mathbf{A}=\begin{bmatrix}
  1 & 0 & 0  \\
  1 & 1 & 0  \\
  1 & 1 & 1
  \end{bmatrix}\]
\end{itemize}

\hypertarget{matrix-operations}{%
\section{Matrix operations}\label{matrix-operations}}

\begin{itemize}
\tightlist
\item
  matrix \(\mathbf{A} = \mathbf{B}\) if both matrices have exactly the same dimension and if each element of \(\mathbf{A}\) equals to the corresponding element of e.g.~\(\mathbf{A} = \mathbf{B}\) if
  \(\mathbf{A}=\begin{bmatrix} 1 & 3 & 4 \\ 0 & 2 & 5 \\ 0 & 0 & 3 \end{bmatrix}\) and \(\mathbf{B}=\begin{bmatrix} 1 & 3 & 4 \\ 0 & 2 & 5 \\ 0 & 0 & 3 \end{bmatrix}\)
\end{itemize}

\begin{itemize}
\tightlist
\item
  for any matrix \(\mathbf{A}\) the \textbf{transpose}, denoted by \(\mathbf{A}^\top\) or \(\mathbf{A}^\prime\), is obtained by interchanging rows and columns, e.g.~given matrix \(\mathbf{A}=\begin{bmatrix} 1 & 3 & 4 \\ 0 & 2 & 5 \\ 0 & 0 & 3 \end{bmatrix}\) we have \(\mathbf{A}^\top=\begin{bmatrix} 1 & 0 & 0 \\ 3 & 2 & 0 \\ 4 & 5 & 3 \end{bmatrix}\). The transpose of a transpose of a matrix yield the original matrix, \(\Big(\mathbf{A}^\top\Big)^\top = \mathbf{A}\)
\end{itemize}

\begin{itemize}
\tightlist
\item
  we can \textbf{add} two matrices if they have the same dimension, e.g.~
  \[\mathbf{A} + \mathbf{B} = \mathbf{A} =\begin{bmatrix}
  x_{11} & x_{12}   \\
  x_{21} & x_{22} 
  \end{bmatrix} + \begin{bmatrix}
  y_{11} & y_{12}   \\
  y_{21} & y_{22} 
  \end{bmatrix} = \begin{bmatrix}
  x_{11}+y_{11} & x_{12}+y_{12}   \\
  x_{21}+y_{21} & x_{22}+y_{22} 
  \end{bmatrix}\]
\end{itemize}

\begin{itemize}
\tightlist
\item
  we can \textbf{multiply} a matrix by \textbf{a scalar} \(\delta\) e.g.~\[\delta \cdot \mathbf{A} = \begin{bmatrix}
  \delta \cdot x_{11} & \delta \cdot x_{12}   \\
  \delta \cdot x_{21} & \delta \cdot x_{22} 
  \end{bmatrix}\]
\end{itemize}

\begin{itemize}
\tightlist
\item
  we can \textbf{multiply two matrices} if they are \textbf{conformable}, i.e.~first matrix has the same number of columns as the number of rows in the second matrix. We then can write:
  \[\mathbf{C} = \mathbf{A} \cdot \mathbf{B}  = \begin{bmatrix}
  x_{11} & x_{12} & x_{13}  \\
  x_{21} & x_{22} & x_{23}
  \end{bmatrix} \times \begin{bmatrix}
  y_{11} & y_{12}   \\
  y_{21} & y_{22}  \\
  y_{31} & y_{32}
  \end{bmatrix} = \\\ 
  \begin{bmatrix}
  x_{11} \cdot y_{11} + x_{12} \cdot y_{21} + x_{13} \cdot y_{31}  & x_{11} \cdot y_{12} + x_{12} \cdot y_{22} + x_{13} \cdot y_{32}  \\
  x_{21} \cdot y_{11} + x_{22} \cdot y_{21} + x_{23} \cdot y_{31} & x_{21} \cdot y_{12} + x_{22} \cdot y_{22} + x_{23} \cdot y_{32}
  \end{bmatrix}\]
\end{itemize}

\hypertarget{inverse-of-a-matrix}{%
\section{Inverse of a matrix}\label{inverse-of-a-matrix}}

For a square matrix \(\mathbf{A}\) there may exist a matrix \(\mathbf{B}\) such that \(\mathbf{A} \cdot \mathbf{B} = \mathbf{I}\). An \textbf{inverse}, if it exists, is denoted as \(\mathbf{A}^{-1}\) and we can rewrite the definition as \[\mathbf{A} \cdot \mathbf{A}^{-1} = \mathbf{I}\] where \(\mathbf{I}\) is an identify matrix (equivalent to 1). There is no division for matrices, instead we can use inverse to multiply the matrix by an inverse, similar to when instead of dividing the number \(a\) by \(b\) we multiply \(a\) by reciprocal of \(b = \frac{1}{b}\)

For a 2-dimensional matrix we can follow the below formula for obtaining the inverse
\[\begin{bmatrix}
  x_{11} & x_{12}   \\
  x_{21} & x_{22} 
\end{bmatrix}^{-1} = \frac{1}{x_{11} \cdot x_{22} - x_{12} \cdot x_{21}} \cdot \begin{bmatrix}
  x_{22} & -x_{12}   \\
  -x_{21} & x_{11} 
\end{bmatrix}\]

\hypertarget{orthogonal-matrix}{%
\section{Orthogonal matrix}\label{orthogonal-matrix}}

\begin{itemize}
\tightlist
\item
  A matrix \(\mathbf{A}\) for which \(\mathbf{A^\top} = \mathbf{A^{-1}}\) is true is said to be \textbf{orthogonal}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{exercise}
\protect\hypertarget{exr:m-matrix}{}{\label{exr:m-matrix} }
Given matrices

\(\mathbf{A} = \begin{bmatrix}  1 & 2 \\  3 & 4  \end{bmatrix}\),
\(\mathbf{B} = \begin{bmatrix}  1 & 0 \\  0 & 1  \end{bmatrix}\) and \(\mathbf{C} = \begin{bmatrix}  1 & 0 \\  0 & 2  \end{bmatrix}\)

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  what is the dimension of matrix \(\mathbf{A}\)?
\item
  what is \(\mathbf{A}^\top\)?
\item
  which of the matrices is i) an identity matrix ii) a square matrix, iii) null matrix, iv) diagonal matrix, v) a triangular matrix,?
\item
  calculate \(\mathbf{A} + \mathbf{B}\)?
\item
  calculate \(\mathbf{A} \cdot \mathbf{C}\)?
\item
  calculate \(\mathbf{B}^\top\)
\item
  calculate \(\mathbf{A}^{-1}\)
\item
  calculate \((\mathbf{A} + \mathbf{B})^{-1}\)
\end{enumerate}
\end{exercise}

\hypertarget{answers-to-selected-exercises-matrices}{%
\section*{Answers to selected exercises (matrices)}\label{answers-to-selected-exercises-matrices}}
\addcontentsline{toc}{section}{Answers to selected exercises (matrices)}

Exr. \ref{exr:m-matrix}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  \(2 \times 2\)
\item
  \(\mathbf{A}^\top = \begin{bmatrix}  1 & 3 \\  2 & 4  \end{bmatrix}\)
\item
  \begin{enumerate}
  \def\labelenumii{\roman{enumii})}
  \tightlist
  \item
    identity matrix: \(\mathbf{B}\), ii) a square matrix: \(\mathbf{A}\), \(\mathbf{B}\) and \(\mathbf{C}\), iii) null matrix: none, iv) diagonal matrix: \(\mathbf{B}\) (identity matrix is diagonal) and \(\mathbf{C}\), v) triangular \(\mathbf{B}\) and \(\mathbf{C}\) as both identify matrix \(\mathbf{B}\) and diagonal matrix \(\mathbf{C}\) is triangular, both lower and upper triangular
  \end{enumerate}
\item
  \(\mathbf{A} + \mathbf{B} = \begin{bmatrix}  1 & 2 \\  3 & 4  \end{bmatrix} + \begin{bmatrix}  1 & 0 \\  0 & 1  \end{bmatrix} = \begin{bmatrix}  2 & 2 \\  3 & 5  \end{bmatrix}\)
\item
  \(\mathbf{A} \cdot \mathbf{C} = \begin{bmatrix}  1 \cdot 1 + 2 \cdot 0 & 1 \cdot 0 + 2 \cdot 2 \\  3 \cdot 1 + 4 \cdot 0 & 3 \cdot 0 + 4 \cdot 2  \end{bmatrix} = \begin{bmatrix}  1 & 4 \\  3 & 8  \end{bmatrix}\)
\item
  \(\mathbf{B}^\top = \begin{bmatrix}  1 & 0 \\  0 & 1  \end{bmatrix}\)
\item
\end{enumerate}

\[\mathbf{A}^{-1} = \begin{bmatrix}
  1 & 2   \\
  3 & 4 
\end{bmatrix}^{-1} = \frac{1}{1 \cdot 4 - 2 \cdot 3} \cdot \begin{bmatrix}
  4 & -2   \\
  -3 & 1
\end{bmatrix} = -\frac{1}{2} \cdot \begin{bmatrix}
  4 & -2   \\
  -3 & 1
\end{bmatrix} = \begin{bmatrix}
  -2 & 1   \\
  \frac{3}{2} & -\frac{1}{2}
\end{bmatrix}\]

\hypertarget{part-linear-models}{%
\part{Linear Models}\label{part-linear-models}}

\hypertarget{introduction-to-linear-models}{%
\chapter{Introduction to linear models}\label{introduction-to-linear-models}}

\textbf{Aims}

\begin{itemize}
\tightlist
\item
  to introduce concept of linear models using simple linear regression
\end{itemize}

\textbf{Learning outcomes}

\begin{itemize}
\tightlist
\item
  to understand what a linear model is and be familiar with the terminology
\item
  to be able to state linear model in the general vector-matrix notation
\item
  to be able to use the general vector-matrix notation to numerically estimate model parameters
\item
  to be able to use \texttt{lm()} function for model fitting, parameter estimation, hypothesis testing and prediction
\end{itemize}

\hypertarget{statistical-vs.-deterministic-relationship}{%
\section{Statistical vs.~deterministic relationship}\label{statistical-vs.-deterministic-relationship}}

Relationships in probability and statistics can generally be one of three things: deterministic, random, or statistical:

\begin{itemize}
\tightlist
\item
  a \textbf{deterministic} relationship involves \textbf{an exact relationship} between two variables, for instance Fahrenheit and Celsius degrees is defined by an equation \(Fahrenheit=\frac{9}{5}\cdot Celcius+32\)
\item
  there is \textbf{no relationship} between variables in the \textbf{random relationship}, for instance number of succulents Olga buys and time of the year as Olga keeps buying succulents whenever she feels like it throughout the entire year
\item
  \textbf{a statistical relationship} is a \textbf{mixture of deterministic and random relationship}, e.g.~the savings that Olga has left in the bank account depend on Olga's monthly salary income (deterministic part) and the money spent on buying succulents (random part)
\end{itemize}

\begin{figure}

{\centering \includegraphics{301-linear-models_files/figure-latex/regression-deterministic-1} 

}

\caption{Deterministic vs. statistical relationship: a) deterministic: equation exactly describes the relationship between the two variables e.g. Ferenheit and Celcius relationship ; b) statistical relationship between $x$ and $y$ is not perfect (increasing relationship), c)  statistical relationship between $x$ and $y$ is not perfect (decreasing relationship), d) random signal}\label{fig:regression-deterministic}
\end{figure}

\hypertarget{what-linear-models-are-and-are-not}{%
\section{What linear models are and are not}\label{what-linear-models-are-and-are-not}}

\begin{itemize}
\tightlist
\item
  A linear model is one in which the parameters appear linearly in the deterministic part of the model
\item
  e.g.~\textbf{simple linear regression} through the origin is a simple linear model of the form \(Y_i = \beta x + \epsilon\) often used to express a relationship of one numerical variable to another, e.g.~the calories burnt and the kilometers cycled
\item
  linear models can become quite advanced by including more variables, e.g.~the calories burnt could be a function of both the kilometers cycled and status of bike, or the transformation of the variables
\end{itemize}

More examples where model parameters appear linearly:

\begin{itemize}
\tightlist
\item
  \(Y_i = \alpha + \beta x_i + \gamma x_i + \epsilon_i\)
\item
  \(Y_i = \alpha + \beta x_i^2 \epsilon\)
\item
  \(Y_i = \alpha + \beta x_i^2 + \gamma x_i^3 + \epsilon\)
\end{itemize}

and an example on a non-linear model where parameter \(\beta\) appears in the exponent of \(x_i\)

\begin{itemize}
\tightlist
\item
  \(Y_i = \alpha + x_i^\beta + \epsilon\)
\end{itemize}

\hypertarget{terminology}{%
\section{Terminology}\label{terminology}}

There are many terms and notations used interchangeably:

\begin{itemize}
\tightlist
\item
  \(y\) is being called:

  \begin{itemize}
  \tightlist
  \item
    response
  \item
    outcome
  \item
    dependent variable
  \end{itemize}
\item
  \(x\) is being called:

  \begin{itemize}
  \tightlist
  \item
    exposure
  \item
    explanatory variable
  \item
    dependent variable
  \item
    predictor
  \item
    covariate
  \end{itemize}
\end{itemize}

\hypertarget{with-linear-models-we-can-answer-questions-such-as}{%
\section{With linear models we can answer questions such as:}\label{with-linear-models-we-can-answer-questions-such-as}}

\begin{itemize}
\tightlist
\item
  is there a relationship between exposure and outcome, e.g.~body weight and plasma volume?
\item
  how strong is the relationship between the two variables?
\item
  what will be a predicted value of the outcome given a new set of exposure values?
\item
  how accurately can we predict outcome?
\item
  which variables are associated with the response, e.g.~is it body weight and height that can explain the plasma volume or is it just the body weight?
\end{itemize}

\hypertarget{simple-linear-regression}{%
\section{Simple linear regression}\label{simple-linear-regression}}

\begin{itemize}
\tightlist
\item
  It is used to check the association between the numerical outcome and one numerical explanatory variable
\item
  In practice, we are finding the best-fitting straight line to describe the relationship between the outcome and exposure
\item
  For example, let's look at the example data containing body weight (kg) and plasma volume (liters) for eight healthy men to see what the best-fitting straight line is.
\end{itemize}

Example data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{weight \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{58}\NormalTok{, }\DecValTok{70}\NormalTok{, }\DecValTok{74}\NormalTok{, }\FloatTok{63.5}\NormalTok{, }\FloatTok{62.0}\NormalTok{, }\FloatTok{70.5}\NormalTok{, }\FloatTok{71.0}\NormalTok{, }\FloatTok{66.0}\NormalTok{) }\CommentTok{\# body weight (kg)}
\NormalTok{plasma \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{2.75}\NormalTok{, }\FloatTok{2.86}\NormalTok{, }\FloatTok{3.37}\NormalTok{, }\FloatTok{2.76}\NormalTok{, }\FloatTok{2.62}\NormalTok{, }\FloatTok{3.49}\NormalTok{, }\FloatTok{3.05}\NormalTok{, }\FloatTok{3.12}\NormalTok{) }\CommentTok{\# plasma volume (liters)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{301-linear-models_files/figure-latex/fig-intro-example-1} 

}

\caption{Scatter plot of the data shows that high plasma volume tends to be associated with high weight and *vice verca*.}\label{fig:fig-intro-example}
\end{figure}

\begin{figure}

{\centering \includegraphics{301-linear-models_files/figure-latex/fig-intro-example-reg-1} 

}

\caption{Scatter plot of the data shows that high plasma volume tends to be associated with high weight and *vice verca*. Linear regression gives the equation of the straight line (red) that best describes how the outcome changes (increase or decreases) with a change of exposure variable}\label{fig:fig-intro-example-reg}
\end{figure}

The equation for the red line is:
\[Y_i=0.086 +  0.044 \cdot x_i \quad for \;i = 1 \dots 8\]
and in general:
\[Y_i=\alpha + \beta \cdot x_i \quad for \; i = 1 \dots n\]

\begin{itemize}
\tightlist
\item
  In other words, by finding the best-fitting straight line we are \textbf{building a statistical model} to represent the relationship between plasma volume (\(Y\)) and explanatory body weight variable (\(x\))
\item
  If were to use our model \(Y_i=0.086 + 0.044 \cdot x_i\) to find plasma volume given a weight of 58 kg (our first observation, \(i=1\)), we would notice that we would get \(Y=0.086 + 0.044 \cdot 58 = 2.638\), not exactly \(2.75\) as we have for our first man in our dataset that we started with, i.e.~\(2.75 - 2.638 = 0.112 \neq 0\).
\item
  We thus add to the above equation an \textbf{error term} to account for this and now we can write our \textbf{simple regression model} more formally as:
\end{itemize}

\begin{equation}
Y_i=\alpha + \beta \cdot x_i + \epsilon_i
\label{eq:regression-linear}
\end{equation}

where:

\begin{itemize}
\tightlist
\item
  we call \(\alpha\) and \(\beta\) \textbf{model coefficients}
\item
  and \(\epsilon_i\) \textbf{error terms}
\end{itemize}

\hypertarget{least-squares}{%
\section{Least squares}\label{least-squares}}

\begin{itemize}
\tightlist
\item
  in the above body weight - plasma volume example, the values of \(\alpha\) and \(\beta\) have just appeared
\item
  in practice, \(\alpha\) and \(\beta\) values are unknown and we use data to \textbf{estimate these coefficients}, noting the estimates with a \textbf{hat}, \(\hat{\alpha}\) and \(\hat{\beta}\)
\item
  \textbf{least squares} is one of the methods of parameters estimation, i.e.~finding \(\hat{\alpha}\) and \(\hat{\beta}\)
\end{itemize}

\begin{figure}

{\centering \includegraphics{301-linear-models_files/figure-latex/regression-errors-1} 

}

\caption{Scatter plot of the data shows that high plasma volume tends to be associated with high weight and *vice verca*. Linear regrssion gives the equation of the straight line (red) that best describes how the outcome changes with a change of exposure variable. Blue lines represent error terms, the vertical distances to the regression line}\label{fig:regression-errors}
\end{figure}

~\\
Let \(\hat{y_i}=\hat{\alpha} + \hat{\beta}x_i\) be the prediction \(y_i\) based on the \(i\)-th value of \(x\):

\begin{itemize}
\tightlist
\item
  Then \(\epsilon_i = y_i - \hat{y_i}\) represents the \(i\)-th \textbf{residual}, i.e.~the difference between the \(i\)-th observed response value and the \(i\)-th response value that is predicted by the linear model
\item
  RSS, the \textbf{residual sum of squares} is defined as: \[RSS = \epsilon_1^2 + \epsilon_2^2 + \dots + \epsilon_n^2\] or
  equivalently as: \[RSS=(y_1-\hat{\alpha}-\hat{\beta}x_1)^2+(y_2-\hat{\alpha}-\hat{\beta}x_2)^2+...+(y_n-\hat{\alpha}-\hat{\beta}x_n)^2\]
\item
  the least squares approach chooses \(\hat{\alpha}\) and \(\hat{\beta}\) \textbf{to minimize the RSS}. With some calculus we get Theorem \ref{thm:leastsq-01}
\end{itemize}

~\\
\begin{theorem}[Least squares estimates for a simple linear regression]
\protect\hypertarget{thm:leastsq-01}{}{\label{thm:leastsq-01} \iffalse (Least squares estimates for a simple linear regression) \fi{} }
\[\hat{\beta} = \frac{S_{xy}}{S_{xx}}\]
\[\hat{\alpha} = \bar{y}-\frac{S_{xy}}{S_{xx}}\cdot \bar{x}\]

where:

\begin{itemize}
\tightlist
\item
  \(\bar{x}\): mean value of \(x\)
\item
  \(\bar{y}\): mean value of \(y\)
\item
  \(S_{xx}\): sum of squares of \(X\) defined as \(S_{xx} = \displaystyle \sum_{i=1}^{n}(x_i-\bar{x})^2\)
\item
  \(S_{yy}\): sum of squares of \(Y\) defined as \(S_{yy} = \displaystyle \sum_{i=1}^{n}(y_i-\bar{y})^2\)
\item
  \(S_{xy}\): sum of products of \(X\) and \(Y\) defined as \(S_{xy} = \displaystyle \sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})\)
\end{itemize}
\end{theorem}

We can further re-write the above sum of squares to obtain

\begin{itemize}
\tightlist
\item
  sum of squares of \(X\), \[S_{xx} = \displaystyle \sum_{i=1}^{n}(x_i-\bar{x})^2 = \sum_{i=1}^{n}x_i^2-\frac{(\sum_{i=1}^{n}x_i)^2}{n})\]
\item
  sum of products of \(X\) and \(Y\)
\end{itemize}

\[S_{xy} = \displaystyle \sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})=\sum_{i=1}^nx_iy_i-\frac{\sum_{i=1}^{n}x_i\sum_{i=1}^{n}y_i}{n}\]

\textbf{Example (Least squares)}

Let's try least squares method to find coefficient estimates in our body weight and plasma volume example

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# initial data}
\NormalTok{weight \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{58}\NormalTok{, }\DecValTok{70}\NormalTok{, }\DecValTok{74}\NormalTok{, }\FloatTok{63.5}\NormalTok{, }\FloatTok{62.0}\NormalTok{, }\FloatTok{70.5}\NormalTok{, }\FloatTok{71.0}\NormalTok{, }\FloatTok{66.0}\NormalTok{) }\CommentTok{\# body weight (kg)}
\NormalTok{plasma \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{2.75}\NormalTok{, }\FloatTok{2.86}\NormalTok{, }\FloatTok{3.37}\NormalTok{, }\FloatTok{2.76}\NormalTok{, }\FloatTok{2.62}\NormalTok{, }\FloatTok{3.49}\NormalTok{, }\FloatTok{3.05}\NormalTok{, }\FloatTok{3.12}\NormalTok{) }\CommentTok{\# plasma volume (liters)}

\CommentTok{\# rename variables for convenience}
\NormalTok{x \textless{}{-}}\StringTok{ }\NormalTok{weight}
\NormalTok{y \textless{}{-}}\StringTok{ }\NormalTok{plasma}

\CommentTok{\# mean values of x and y}
\NormalTok{x.bar \textless{}{-}}\StringTok{ }\KeywordTok{mean}\NormalTok{(x)}
\NormalTok{y.bar \textless{}{-}}\StringTok{ }\KeywordTok{mean}\NormalTok{(y)}

\CommentTok{\# Sum of squares}
\NormalTok{Sxx \textless{}{-}}\StringTok{  }\KeywordTok{sum}\NormalTok{((x }\OperatorTok{{-}}\StringTok{ }\NormalTok{x.bar)}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{Sxy \textless{}{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{((x}\OperatorTok{{-}}\NormalTok{x.bar)}\OperatorTok{*}\NormalTok{(y}\OperatorTok{{-}}\NormalTok{y.bar))}

\CommentTok{\# Coefficient estimates}
\NormalTok{beta.hat \textless{}{-}}\StringTok{ }\NormalTok{Sxy }\OperatorTok{/}\StringTok{ }\NormalTok{Sxx}
\NormalTok{alpha.hat \textless{}{-}}\StringTok{ }\NormalTok{y.bar }\OperatorTok{{-}}\StringTok{ }\NormalTok{Sxy}\OperatorTok{/}\NormalTok{Sxx}\OperatorTok{*}\NormalTok{x.bar}

\CommentTok{\# Print estimated coefficients alpha and beta}
\KeywordTok{print}\NormalTok{(alpha.hat)}
\CommentTok{\#\# [1] 0.08572428}

\KeywordTok{print}\NormalTok{(beta.hat)}
\CommentTok{\#\# [1] 0.04361534}
\end{Highlighting}
\end{Shaded}

In R we can use \texttt{lm}, the built-in function, to fit a linear regression model and we can replace the above code with one line

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{lm}\NormalTok{(plasma }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{weight)}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = plasma \textasciitilde{} weight)}
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\# (Intercept)       weight  }
\CommentTok{\#\#     0.08572      0.04362}
\end{Highlighting}
\end{Shaded}

\hypertarget{intercept-and-slope}{%
\section{Intercept and Slope}\label{intercept-and-slope}}

\begin{itemize}
\tightlist
\item
  Linear regression gives us estimates of model coefficient \(Y_i = \alpha + \beta x_i + \epsilon_i\)
\item
  \(\alpha\) is known as the \textbf{intercept}
\item
  \(\beta\) is known as the \textbf{slope}
\end{itemize}

\begin{figure}

{\centering \includegraphics{301-linear-models_files/figure-latex/lm-parameters-1} 

}

\caption{Scatter plot of the data shows that high plasma volume tends to be associated with high weight and *vice verca*. Linear regression gives the equation of the straight line that best describes how the outcome changes (increase or decreases) with a change of exposure variable (in red)}\label{fig:lm-parameters}
\end{figure}

\hypertarget{hypothesis-testing}{%
\section{Hypothesis testing}\label{hypothesis-testing}}

\begin{itemize}
\tightlist
\item
  the calculated \(\hat{\alpha}\) and \(\hat{\beta}\) are estimates of the population values of the intercept and slope and are therefore subject to \textbf{sampling variation}
\item
  their precision is measure by their ** estimated standard errors**, e.s.e(\(\hat{\alpha}\)) and e.s.e(\(\hat{\beta}\))
\item
  these estimated standard errors are used in hypothesis testing and building confidence and prediction intervals
\end{itemize}

The most common hypothesis test involves testing the \texttt{null\ hypothesis} of:

\begin{itemize}
\tightlist
\item
  \(H_0:\) There is no relationship between \(X\) and \(Y\)
\item
  versus the \texttt{alternative\ hypothesis} \(H_a:\) there is some relationship between \(X\) and \(Y\)
\end{itemize}

Mathematically, this corresponds to testing:

\begin{itemize}
\tightlist
\item
  \(H_0: \beta=0\)
\item
  versus \(H_0: \beta\neq0\)
\item
  since if \(\beta=0\) then the model \(Y_i=\alpha+\beta x_i + \epsilon_i\) reduces to \(Y=\alpha + \epsilon_i\)
\end{itemize}

Under the null hypothesis:

\begin{itemize}
\tightlist
\item
  \(H_0: \beta = 0\) we have: \(\frac{\hat{\beta}-\beta}{e.s.e(\hat{\beta})} \sim t(n-p)\), where
\item
  \(n\) is number of observations
\item
  \(p\) is number of model parameters
\item
  \(\frac{\hat{\beta}-\beta}{e.s.e(\hat{\beta})}\) is called the t-statistics
\item
  that follows Student's t distribution with \(n-p\) degrees of freedom
\end{itemize}

\textbf{Example (Hypothesis testing)}

Let's look again at our example data. This time we will not only fit the linear regression model but look a bit more closely at the R summary of the model

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{weight \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{58}\NormalTok{, }\DecValTok{70}\NormalTok{, }\DecValTok{74}\NormalTok{, }\FloatTok{63.5}\NormalTok{, }\FloatTok{62.0}\NormalTok{, }\FloatTok{70.5}\NormalTok{, }\FloatTok{71.0}\NormalTok{, }\FloatTok{66.0}\NormalTok{) }\CommentTok{\# body weight (kg)}
\NormalTok{plasma \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{2.75}\NormalTok{, }\FloatTok{2.86}\NormalTok{, }\FloatTok{3.37}\NormalTok{, }\FloatTok{2.76}\NormalTok{, }\FloatTok{2.62}\NormalTok{, }\FloatTok{3.49}\NormalTok{, }\FloatTok{3.05}\NormalTok{, }\FloatTok{3.12}\NormalTok{) }\CommentTok{\# plasma volume (liters)}

\NormalTok{model \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(plasma }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{weight)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = plasma \textasciitilde{} weight)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}0.27880 {-}0.14178 {-}0.01928  0.13986  0.32939 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#             Estimate Std. Error t value Pr(\textgreater{}|t|)  }
\CommentTok{\#\# (Intercept)  0.08572    1.02400   0.084   0.9360  }
\CommentTok{\#\# weight       0.04362    0.01527   2.857   0.0289 *}
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 0.2188 on 6 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.5763,	Adjusted R{-}squared:  0.5057 }
\CommentTok{\#\# F{-}statistic:  8.16 on 1 and 6 DF,  p{-}value: 0.02893}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Under ``Estimate'' we see estimates of our model coefficients, \(\hat{\alpha}\) (intercept) and \(\hat{\beta}\) (slope, here weight), followed by their estimated standard errors.
\item
  If we were to test if there is an association between weight and plasma volume we would write under \(H_0: \beta = 0\) and \(\frac{\hat{\beta}-\beta}{e.s.e(\hat{\beta})} = \frac{0.04362-0}{0.01527} = 2.856582\)
\item
  and we would compare t-statistics to Student's t distribution with \(n-p = 8 - 2 = 6\) degrees of freedom (we have two model parameters, \(\alpha\) and \(\beta\))
\item
  we can use Student's t distribution table or R code to obtain the p-value
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}\OperatorTok{*}\KeywordTok{pt}\NormalTok{(}\FloatTok{2.856582}\NormalTok{, }\DataTypeTok{df=}\DecValTok{6}\NormalTok{, }\DataTypeTok{lower=}\NormalTok{F)}
\CommentTok{\#\# [1] 0.02893095}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  here the observed t-statistics is large and therefore yields a small p-value, meaning that there is sufficient evidence to reject null hypothesis in favor of the alternative and conclude that there is an significant association between weight and plasma volume
\end{itemize}

\hypertarget{vector-matrix-notations}{%
\section{Vector-matrix notations}\label{vector-matrix-notations}}

While in simple linear regression it is feasible to arrive at the parameters estimates using calculus in more realistic settings with multiple regression (more than one explanatory variable in the model) it is more efficient to use vectors and matrices to define the regression model.

Let's rewrite our simple linear regression model \(Y_i = \alpha + \beta_i + \epsilon_i \quad i=1,\dots n\) into vector-matrix notations.

\begin{itemize}
\tightlist
\item
  First we rename our \(\alpha\) to \(\beta_0\) and \(\beta\) to \(\beta_1\) (it is easier to keep tracking the number of model parameters this way)
\item
  Then we notice that we actually have \(n\) equations such as:
  \[y_1 = \beta_0 + \beta_1 x_1 + \epsilon_1\]
  \[y_2 = \beta_0 + \beta_1 x_2 + \epsilon_2\]
  \[y_3 = \beta_0 + \beta_1 x_3 + \epsilon_3\]
  \[\dots\]
  \[y_n = \beta_0 + \beta_1 x_n + \epsilon_n\]
\item
  we can group all \(Y_i\) and \(\epsilon_i\) into column vectors:
  \(\mathbf{Y}=\begin{bmatrix} y_1 \\ y_2 \\ \vdots \\ y_{n} \end{bmatrix}\) and
  \(\boldsymbol\epsilon=\begin{bmatrix} \epsilon_1 \\ \epsilon_2 \\ \vdots \\ \epsilon_{n} \end{bmatrix}\)
\item
  we stack two parameters \(\beta_0\) and \(\beta_1\) into another column vector:\[\boldsymbol\beta=\begin{bmatrix}
  \beta_0  \\
  \beta_1
  \end{bmatrix}\]
\item
  we then append a vector of ones with the single predictor for each \(i\) and create a matrix with two columns:
  design matrix \[\mathbf{X}=\begin{bmatrix}
  1 & x_1  \\
  1 & x_2  \\
  \vdots & \vdots \\
  1 & x_{n}
  \end{bmatrix}\]
\end{itemize}

Now we can write our linear model in a vector-matrix notations as:
\[\mathbf{Y} = \boldsymbol\beta\mathbf{X} + \boldsymbol\epsilon\]

\textbf{Definition: vector matrix form of the linear model}

The vector-matrix representation of a linear model with \(p-1\) predictors can be written as
\[\mathbf{Y} = \boldsymbol\beta\mathbf{X} + \boldsymbol\epsilon\]

where:

\begin{itemize}
\tightlist
\item
  \(\mathbf{Y}\) is \(n \times1\) vector of observations
\item
  \(\boldsymbol\beta\) is \(p \times1\) vector of parameters
\item
  \(\mathbf{X}\) is \(n \times p\) design matrix
\item
  \(\boldsymbol\epsilon\) is \(n \times1\) vector of vector of random errors, indepedent and identically distributed (i.i.d) N(0, \(\sigma^2\))
\end{itemize}

In full, the above vectors and matrix have the form:

\(\mathbf{Y}=\begin{bmatrix}  y_1 \\  y_2 \\  \vdots \\  y_{n} \end{bmatrix}\)
\(\boldsymbol\beta=\begin{bmatrix}  \beta_0 \\  \beta_1 \\  \vdots \\  \beta_{p} \end{bmatrix}\)
\(\boldsymbol\epsilon=\begin{bmatrix}  \epsilon_1 \\  \epsilon_2 \\  \vdots \\  \epsilon_{n} \end{bmatrix}\)
\(\mathbf{X}=\begin{bmatrix}  1 & x_{1,1} & \dots & x_{1,p-1} \\  1 & x_{2,1} & \dots & x_{2,p-1} \\  \vdots & \vdots & \vdots & \vdots \\  1 & x_{n,1} & \dots & x_{n,p-1} \end{bmatrix}\)

~\\
\begin{theorem}[Least squares in vector-matrix notation]
\protect\hypertarget{thm:leastsq-02}{}{\label{thm:leastsq-02} \iffalse (Least squares in vector-matrix notation) \fi{} }

The least squares estimates for a linear regression of the form:
\[\mathbf{Y} = \boldsymbol\beta\mathbf{X} + \boldsymbol\epsilon\]

is given by:
\[\hat{\mathbf{\beta}}= (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}\]
\end{theorem}

\textbf{Example: vector-matrix notation}

Following the above definition we can write our weight - plasma volume model as:
\[\mathbf{Y} = \boldsymbol\beta\mathbf{X} + \boldsymbol\epsilon\]
where:

\(\mathbf{Y}=\begin{bmatrix}  2.75 \\ 2.86 \\ 3.37 \\ 2.76 \\ 2.62 \\ 3.49 \\ 3.05 \\ 3.12 \end{bmatrix}\)

\(\boldsymbol\beta=\begin{bmatrix}  \beta_0 \\  \beta_1 \end{bmatrix}\)
\(\boldsymbol\epsilon=\begin{bmatrix}  \epsilon_1 \\  \epsilon_2 \\  \vdots \\  \epsilon_{8} \end{bmatrix}\)
\(\mathbf{X}=\begin{bmatrix}  1 & 58.0 \\  1 & 70.0 \\  1 & 74.0 \\  1 & 63.5 \\  1 & 62.0 \\  1 & 70.5 \\  1 & 71.0 \\  1 & 66.0 \\ \end{bmatrix}\)

and we can estimate model parameters using \(\hat{\mathbf{\beta}}= (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}\). We can do it by hand or in R as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n \textless{}{-}}\StringTok{ }\KeywordTok{length}\NormalTok{(plasma) }\CommentTok{\# no. of observation}
\NormalTok{Y \textless{}{-}}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(plasma, }\DataTypeTok{ncol=}\DecValTok{1}\NormalTok{)}
\NormalTok{X \textless{}{-}}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DataTypeTok{length=}\NormalTok{n), weight)}
\NormalTok{X \textless{}{-}}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(X)}

\CommentTok{\# print Y and X to double{-}check that the format is according to the definition}
\KeywordTok{print}\NormalTok{(Y) }
\CommentTok{\#\#      [,1]}
\CommentTok{\#\# [1,] 2.75}
\CommentTok{\#\# [2,] 2.86}
\CommentTok{\#\# [3,] 3.37}
\CommentTok{\#\# [4,] 2.76}
\CommentTok{\#\# [5,] 2.62}
\CommentTok{\#\# [6,] 3.49}
\CommentTok{\#\# [7,] 3.05}
\CommentTok{\#\# [8,] 3.12}
\KeywordTok{print}\NormalTok{(X) }
\CommentTok{\#\#        weight}
\CommentTok{\#\# [1,] 1   58.0}
\CommentTok{\#\# [2,] 1   70.0}
\CommentTok{\#\# [3,] 1   74.0}
\CommentTok{\#\# [4,] 1   63.5}
\CommentTok{\#\# [5,] 1   62.0}
\CommentTok{\#\# [6,] 1   70.5}
\CommentTok{\#\# [7,] 1   71.0}
\CommentTok{\#\# [8,] 1   66.0}

\CommentTok{\# least squares estimate}
\CommentTok{\# solve() finds inverse of matrix}
\NormalTok{beta.hat \textless{}{-}}\StringTok{ }\KeywordTok{solve}\NormalTok{(}\KeywordTok{t}\NormalTok{(X)}\OperatorTok{\%*\%}\NormalTok{X)}\OperatorTok{\%*\%}\KeywordTok{t}\NormalTok{(X)}\OperatorTok{\%*\%}\NormalTok{Y }
\KeywordTok{print}\NormalTok{(beta.hat)}
\CommentTok{\#\#              [,1]}
\CommentTok{\#\#        0.08572428}
\CommentTok{\#\# weight 0.04361534}
\end{Highlighting}
\end{Shaded}

\hypertarget{confidence-intervals-and-prediction-intervals}{%
\section{Confidence intervals and prediction intervals}\label{confidence-intervals-and-prediction-intervals}}

\begin{itemize}
\tightlist
\item
  when we estimate coefficients we can also find their \textbf{confidence intervals}, typically 95\% confidence intervals, i.e.~a range of values that contain the true unknown value of the parameter
\item
  we can also use linear regression models to predict the response value given a new observation and find \textbf{prediction intervals}. Here, we look at any specific value of \(x_i\), and find an interval around the predicted value \(y_i'\) for \(x_i\) such that there is a 95\% probability that the real value of y (in the population) corresponding to \(x_i\) is within this interval
\end{itemize}

Earlier we said that we use estimated standard error in hypothesis testing and in finding the intervals but we have not yet said how to calculate e.s.e. Using vector-matrix notation we can now write that:
\[\frac{(\mathbf{b}\hat{{\boldsymbol\beta}}-\mathbf{b}^T\boldsymbol\beta)}{\sqrt{\frac{RSS}{n-p}\mathbf{b^T(X^TX)^{-1}b}}}\]

where:

\begin{itemize}
\item
  the denominator would yield e.s.e(\(\beta_1\)) if \(\mathbf{b^T}=(0 \quad 1)\) and a model \(Y_i = \beta_0 + \beta_1x + \epsilon_i\)
\item
  a confidence interval estimate for \(\beta_1\) could be estimated via:
  \[\mathbf{b^T}\hat{\boldsymbol\beta} \pm t(n-p; \frac{1+c}{2})\sqrt{\frac{RSS}{n-p}(\mathbf{b^T}(\mathbf{X^T}\mathbf{X})^{-1}\mathbf{b})}\]
\item
  and a prediction interval with confidence \(c\) is
  \[\mathbf{b^T}\hat{\boldsymbol\beta} \pm t(n-p; \frac{1+c}{2})\sqrt{(\frac{RSS}{n-p}(1+\mathbf{b^T}(\mathbf{X^T}\mathbf{X})^{-1}\mathbf{b}})\]
\end{itemize}

We will not go further into these calculations here but use R functions to obtain these

\begin{itemize}
\tightlist
\item
  just remember that the prediction interval is always \textbf{wider} than the confidence interval
\item
  note (1 + ) in the prediction interval equation
\end{itemize}

\textbf{Example: prediction and intervals}

Let's:

\begin{itemize}
\tightlist
\item
  find confidence intervals for our coefficient estimates
\item
  predict plasma volume for a men weighting 60 kg
\item
  find prediction interval
\item
  plot original data, fitted regression model, predicted observation
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fit regression model}
\NormalTok{model \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(plasma }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{weight)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = plasma \textasciitilde{} weight)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}0.27880 {-}0.14178 {-}0.01928  0.13986  0.32939 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#             Estimate Std. Error t value Pr(\textgreater{}|t|)  }
\CommentTok{\#\# (Intercept)  0.08572    1.02400   0.084   0.9360  }
\CommentTok{\#\# weight       0.04362    0.01527   2.857   0.0289 *}
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 0.2188 on 6 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.5763,	Adjusted R{-}squared:  0.5057 }
\CommentTok{\#\# F{-}statistic:  8.16 on 1 and 6 DF,  p{-}value: 0.02893}

\CommentTok{\# find confidence intervals for the model coefficients}
\KeywordTok{confint}\NormalTok{(model)}
\CommentTok{\#\#                    2.5 \%     97.5 \%}
\CommentTok{\#\# (Intercept) {-}2.419908594 2.59135716}
\CommentTok{\#\# weight       0.006255005 0.08097567}

\CommentTok{\# predict plasma volume for a new observation of 60 kg}
\CommentTok{\# we have to create data frame with a variable name matching the one used to build the model }
\NormalTok{new.obs \textless{}{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{weight =} \DecValTok{60}\NormalTok{)  }
\KeywordTok{predict}\NormalTok{(model, }\DataTypeTok{newdata =}\NormalTok{ new.obs) }
\CommentTok{\#\#        1 }
\CommentTok{\#\# 2.702645}

\CommentTok{\# find prediction intervals}
\KeywordTok{predict}\NormalTok{(model, }\DataTypeTok{newdata =}\NormalTok{ new.obs,  }\DataTypeTok{interval =} \StringTok{"prediction"}\NormalTok{)}
\CommentTok{\#\#        fit      lwr      upr}
\CommentTok{\#\# 1 2.702645 2.079373 3.325916}

\CommentTok{\# plot the original data, fitted regression and predicted value}
\KeywordTok{plot}\NormalTok{(weight, plasma, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{xlab=}\StringTok{"weight [kg]"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"plasma [l]"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(weight, model}\OperatorTok{$}\NormalTok{fitted.values, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{) }\CommentTok{\# fitted model in red}
\KeywordTok{points}\NormalTok{(new.obs, }\KeywordTok{predict}\NormalTok{(model, }\DataTypeTok{newdata =}\NormalTok{ new.obs), }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{) }\CommentTok{\# predicted value at 60kg}
\end{Highlighting}
\end{Shaded}

\includegraphics{301-linear-models_files/figure-latex/predict-1.pdf}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{exercises-linear-models-i}{%
\section{Exercises: linear models I}\label{exercises-linear-models-i}}

Data for exercises

\begin{itemize}
\tightlist
\item
  \href{https://github.com/olgadet/bookdown-mlbiostatistics/tree/master/data/data.zip}{Link 1}
\item
  \href{https://stockholmuniversity.box.com/s/z5kwg0nlwe5la4h5t8bshpj57pylif14}{Alternative Link 2}
\end{itemize}

\begin{exercise}
\protect\hypertarget{exr:lm-recognize}{}{\label{exr:lm-recognize} }Linear models form

Which of the following models are linear models and why?

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  \(Y_i=\alpha + \beta x_i + \epsilon_i\)
\item
  \(Y_i=\beta_0 + \beta_1 x_{i,1} + \beta_2 x_{i,2} + \epsilon_i\)
\item
  \(Y_i=\alpha + \beta x_i + \gamma x_i^2 + \epsilon_i\)
\item
  \(Y_i=\alpha + \gamma x_i^\beta + \epsilon_i\)
\end{enumerate}
\end{exercise}

\begin{exercise}
\protect\hypertarget{exr:lm-protein}{}{\label{exr:lm-protein} }Protein levels in pregnancy

The researchers were interested whether protein levels in expectant mothers are changing throughout the pregnancy. Observations have been taken on 19 healthy women and each woman was at different stage of pregnancy (gestation).

Assuming linear model:

\begin{itemize}
\tightlist
\item
  \(Y_i = \alpha + \beta x_i + \epsilon_i\), where \(Y_i\) corresponds to protein levels in i-th observation
\end{itemize}

and taking summary statisitcs:

\begin{itemize}
\tightlist
\item
  \(\sum_{i=1}^{n}x_i = 456\)
\item
  \(\sum_{i=1}^{n}x_i^2 = 12164\)
\item
  \(\sum_{i=1}^{n}x_iy_i = 369.87\)
\item
  \(\sum_{i=1}^{n}y_i = 14.25\)
\item
  \(\sum_{i=1}^{n}y_i^2 = 11.55\)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  find the least square estimates of \(\hat{\alpha}\) and \(\hat{\beta}\)
\item
  knowing that e.s.e(\(\hat{\beta}) = 0.003295\)
\end{enumerate}

can we:

\begin{itemize}
\item
  \begin{enumerate}
  \def\labelenumi{\roman{enumi})}
  \tightlist
  \item
    reject the null hypothesis that the is no relationship between protein level and gestation, i.e.~perform a hypothesis test to test \(H_0:\beta = 0\);
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\roman{enumi})}
  \setcounter{enumi}{1}
  \tightlist
  \item
    can we reject the null hypothesis that \(\beta = 0.02\), i.e.~perform a hypothesis test to test \(H_0:\beta = 0.02\)
  \end{enumerate}
\end{itemize}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  write down the linear model in the vector-matrix notation and identify response, parameter, design and error matrices
\item
  read in ``protein.csv'' data into R, set Y as protein (response) and calculate using matrix functions the least squares estimates of model coefficients
\item
  use \texttt{lm()} function in R to check your calculations
\item
  use the fitted model in R to predict the value of protein levels at week 20. Try plotting the data, fitted linear model and the predicted value to assess whether your prediction is to be expected.
\end{enumerate}
\end{exercise}

\begin{exercise}
\protect\hypertarget{exr:lm-potato}{}{\label{exr:lm-potato} }
The glucose level in potatoes depends on their storage time and the relationship is somehow curvilinear as shown below.
As we believe that the quadratic function might describe the relationship, assume linear model in form
\(Y_i = \alpha + \beta x_i + \gamma x_i^2 + \epsilon_i \quad i=1,\dots,n\) where \(n=14\) and

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  write down the model in vector-matrix notation
\item
  load data to from ``potatoes.csv'' and use least squares estimates for obtain estimates of model coefficients
\item
  perform a hypothesis test to test \(H_0:\gamma=0\); and comment whether there is a significant quadratic relationship
\item
  use \texttt{lm()} function to verify your calculations
\item
  predict glucose concentration at storage time 4 and 16 weeks. Plot the data, the fitted model and the predicted values
\end{enumerate}
\end{exercise}

\begin{figure}

{\centering \includegraphics{301-linear-models_files/figure-latex/potatoes-1} 

}

\caption{Sugar in potatoes: relationship between storage time and glucose content}\label{fig:potatoes}
\end{figure}

\hypertarget{answers-to-selected-exercises-linear-models}{%
\section*{Answers to selected exercises (linear models)}\label{answers-to-selected-exercises-linear-models}}
\addcontentsline{toc}{section}{Answers to selected exercises (linear models)}

Exr. \ref{exr:lm-protein}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \(S_{xx} = \sum_{i=1}^{n}x_i^2-\frac{(\sum_{i=1}^{n}x_i)^2}{n} = 12164 - \frac{456^2}{19} = 1220\)
\item
  \(S_{xy} = \sum_{i=1}^nx_iy_i-\frac{\sum_{i=1}^{n}x_i\sum_{i=1}^{n}y_i}{n} = 369.87 - \frac{(456 \cdot 14.25)}{19} = 27.87\)
\item
  \(\hat{\beta} = \frac{S_{xy}}{S_{xx}} = 27.87 / 1220 = 0.02284\)
\item
  \(\hat{\alpha} = \bar{y}-\frac{S_{xy}}{S_{xx}}\cdot \bar{x} = \frac{14.25}{19}-\frac{27.87}{1220}\cdot \frac{456}{19} = 0.20174\)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{1}
\item
  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
  \end{enumerate}
\end{enumerate}

We can calculate test statistics following:

\begin{itemize}
\tightlist
\item
  \(\frac{\hat{\beta} - \beta}{e.s.e(\hat{\beta})} \sim t(n-p) = \frac{0.02284 - 0}{0.003295} = 6.934\) where the value follows Student's t distribution with \(n-p = 19 - 2 = 17\) degrees of freedom. We can now estimate the a p-value using Student's t distribution table or use R function
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}\OperatorTok{*}\KeywordTok{pt}\NormalTok{(}\FloatTok{6.934}\NormalTok{, }\DataTypeTok{df=}\DecValTok{17}\NormalTok{, }\DataTypeTok{lower=}\NormalTok{F)}
\CommentTok{\#\# [1] 2.414315e{-}06}
\end{Highlighting}
\end{Shaded}

As p-value \textless\textless{} 0.001 there is sufficient evidence to reject \(H_0\) in favor of \(H_1\), thus we can conclude that there is a significant relationship between protein levels and gestation

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{1}
\item
  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \setcounter{enumii}{1}
  \tightlist
  \item
  \end{enumerate}
\end{enumerate}

Similarly, we can test \(H_0:\beta = 0.02\), i.e.~\(\frac{\hat{\beta} - \beta}{e.s.e(\hat{\beta})} \sim t(n-p) = \frac{0.02284 - 0.02}{0.20174} = 0.01407753\). Now the test statistics is small

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}\OperatorTok{*}\KeywordTok{pt}\NormalTok{(}\FloatTok{0.01407753}\NormalTok{, }\DataTypeTok{df=}\DecValTok{17}\NormalTok{, }\DataTypeTok{lower=}\NormalTok{F)}
\CommentTok{\#\# [1] 0.988932}
\end{Highlighting}
\end{Shaded}

p-value is large and hence there is no sufficient evidence to reject \(H_0\) and we can conclude that \(\beta = 0.02\)

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  We can rewrite the linear model in vector-matrix formation as \(\mathbf{Y}= \mathbf{\beta}\mathbf{X} + \mathbf{\epsilon}\) where:
\end{enumerate}

response \(\mathbf{Y}=\begin{bmatrix}  y_1 \\  y_2 \\  \vdots \\  y_{19} \end{bmatrix}\)

parameters \(\boldsymbol\beta=\begin{bmatrix}  \alpha \\  \beta \end{bmatrix}\)

design matrix \(\mathbf{X}=\begin{bmatrix}  1 & x_1 \\  1 & x_2 \\  \vdots & \vdots \\  1 & x_{19} \end{bmatrix}\)

errors \(\boldsymbol\epsilon=\begin{bmatrix}  \epsilon_1 \\  \epsilon_2 \\  \vdots \\  \epsilon_{19} \end{bmatrix}\)

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  The least squares estimates in vector-matrix notation is \(\hat{\boldsymbol\beta}= (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}\) and we can calculate this in R
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# read in data }
\NormalTok{data.protein \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/lm/protein.csv"}\NormalTok{)}

\CommentTok{\# print out top observations}
\KeywordTok{head}\NormalTok{(data.protein)}
\CommentTok{\#\#   Protein Gestation}
\CommentTok{\#\# 1    0.38        11}
\CommentTok{\#\# 2    0.58        12}
\CommentTok{\#\# 3    0.51        13}
\CommentTok{\#\# 4    0.38        15}
\CommentTok{\#\# 5    0.58        17}
\CommentTok{\#\# 6    0.67        18}

\CommentTok{\# define Y and X matrices given the data}
\NormalTok{n \textless{}{-}}\StringTok{ }\KeywordTok{nrow}\NormalTok{(data.protein) }\CommentTok{\# nu. of observations}
\NormalTok{Y \textless{}{-}}\StringTok{  }\KeywordTok{as.matrix}\NormalTok{(data.protein}\OperatorTok{$}\NormalTok{Protein, }\DataTypeTok{ncol=}\DecValTok{1}\NormalTok{) }\CommentTok{\# response }
\NormalTok{X \textless{}{-}}\StringTok{  }\KeywordTok{as.matrix}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DataTypeTok{length=}\NormalTok{n), data.protein}\OperatorTok{$}\NormalTok{Gestation)) }\CommentTok{\# design matrix}
\KeywordTok{head}\NormalTok{(X) }\CommentTok{\# double check that the design matrix looks like it should}
\CommentTok{\#\#      [,1] [,2]}
\CommentTok{\#\# [1,]    1   11}
\CommentTok{\#\# [2,]    1   12}
\CommentTok{\#\# [3,]    1   13}
\CommentTok{\#\# [4,]    1   15}
\CommentTok{\#\# [5,]    1   17}
\CommentTok{\#\# [6,]    1   18}

\CommentTok{\# least squares estimate}
\NormalTok{beta.hat \textless{}{-}}\StringTok{ }\KeywordTok{solve}\NormalTok{(}\KeywordTok{t}\NormalTok{(X)}\OperatorTok{\%*\%}\NormalTok{X)}\OperatorTok{\%*\%}\KeywordTok{t}\NormalTok{(X)}\OperatorTok{\%*\%}\NormalTok{Y }\CommentTok{\# beta.hat is a matrix that contains our alpha and beta in the model}
\KeywordTok{print}\NormalTok{(beta.hat)}
\CommentTok{\#\#            [,1]}
\CommentTok{\#\# [1,] 0.20173770}
\CommentTok{\#\# [2,] 0.02284426}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  We use \texttt{lm()} function to check our calculations
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fit linear regression model and print model summary}
\NormalTok{protein \textless{}{-}}\StringTok{ }\NormalTok{data.protein}\OperatorTok{$}\NormalTok{Protein }\CommentTok{\# our Y}
\NormalTok{gestation \textless{}{-}}\StringTok{ }\NormalTok{data.protein}\OperatorTok{$}\NormalTok{Gestation }\CommentTok{\# our X}

\NormalTok{model \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(protein }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{gestation)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = protein \textasciitilde{} gestation)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}0.16853 {-}0.08720 {-}0.01009  0.08578  0.20422 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#             Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept) 0.201738   0.083363   2.420    0.027 *  }
\CommentTok{\#\# gestation   0.022844   0.003295   6.934 2.42e{-}06 ***}
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 0.1151 on 17 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.7388,	Adjusted R{-}squared:  0.7234 }
\CommentTok{\#\# F{-}statistic: 48.08 on 1 and 17 DF,  p{-}value: 2.416e{-}06}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new.obs \textless{}{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{gestation =} \DecValTok{20}\NormalTok{)}
\NormalTok{y.pred \textless{}{-}}\StringTok{ }\KeywordTok{predict}\NormalTok{(model, }\DataTypeTok{newdata =}\NormalTok{ new.obs)}

\CommentTok{\# we can visualize the data, fitted linear model (red), and the predicted value (blue)}
\KeywordTok{plot}\NormalTok{(gestation, protein, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{xlab=}\StringTok{"gestation [weeks]"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"protein levels [mgml{-}1]"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(gestation, model}\OperatorTok{$}\NormalTok{fitted.values, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{)}
\KeywordTok{points}\NormalTok{(new.obs, y.pred, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{cex =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{301-linear-models_files/figure-latex/protein-predict-1.pdf}

Exr. \ref{exr:lm-potato}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  We can rewrite the linear model in vector-matrix formation as \(\mathbf{Y}= \boldsymbol\beta\mathbf{X} + \mathbf{\epsilon}\) where:
\end{enumerate}

response \(\mathbf{Y}=\begin{bmatrix}  y_1 \\  y_2 \\  \vdots \\  y_{14} \end{bmatrix}\)

parameters \(\boldsymbol\beta=\begin{bmatrix}  \alpha \\  \beta \\  \gamma \end{bmatrix}\)

design matrix \(\mathbf{X}=\begin{bmatrix}  1 & x_1 & x_1^2\\  1 & x_2 & x_2^2\\  \vdots & \vdots & \vdots \\  1 & x_{14} & x_{14}^2 \end{bmatrix}\)

errors \(\boldsymbol\epsilon=\begin{bmatrix}  \epsilon_1 \\  \epsilon_2 \\  \vdots \\  \epsilon_{14} \end{bmatrix}\)

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  load data to from ``potatoes.csv'' and use least squares estimates for obtain estimates of model coefficients
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data.potatoes \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/lm/potatoes.csv"}\NormalTok{)}

\CommentTok{\# define matrices}
\NormalTok{n \textless{}{-}}\StringTok{ }\KeywordTok{nrow}\NormalTok{(data.potatoes)}
\NormalTok{Y \textless{}{-}}\StringTok{  }\NormalTok{data.potatoes}\OperatorTok{$}\NormalTok{Glucose}
\NormalTok{X1 \textless{}{-}}\StringTok{ }\NormalTok{data.potatoes}\OperatorTok{$}\NormalTok{Weeks}
\NormalTok{X2 \textless{}{-}}\StringTok{ }\NormalTok{(data.potatoes}\OperatorTok{$}\NormalTok{Weeks)}\OperatorTok{\^{}}\DecValTok{2}
\NormalTok{X \textless{}{-}}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\KeywordTok{length}\NormalTok{(n)), X1, X2)}
\NormalTok{X \textless{}{-}}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(X)}

\CommentTok{\# least squares estimate}
\CommentTok{\# beta here refers to the matrix of model coefficients incl. alpha, beta and gamma}
\NormalTok{beta.hat \textless{}{-}}\StringTok{ }\KeywordTok{solve}\NormalTok{(}\KeywordTok{t}\NormalTok{(X)}\OperatorTok{\%*\%}\NormalTok{X)}\OperatorTok{\%*\%}\KeywordTok{t}\NormalTok{(X)}\OperatorTok{\%*\%}\NormalTok{Y }
\KeywordTok{print}\NormalTok{(beta.hat)}
\CommentTok{\#\#          [,1]}
\CommentTok{\#\#    200.169312}
\CommentTok{\#\# X1 {-}19.443122}
\CommentTok{\#\# X2   1.030423}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  we use \texttt{lm()} function to verify our calculations:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(Y }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{X1 }\OperatorTok{+}\StringTok{ }\NormalTok{X2)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Y ~ X1 + X2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -17.405 -11.250  -8.071  12.911  29.286 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 200.1693    15.0527  13.298 4.02e-08 ***
## X1          -19.4431     3.1780  -6.118 7.54e-05 ***
## X2            1.0304     0.1406   7.329 1.49e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 16.4 on 11 degrees of freedom
## Multiple R-squared:  0.8694,	Adjusted R-squared:  0.8457 
## F-statistic: 36.61 on 2 and 11 DF,  p-value: 1.373e-05
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  perform a hypothesis test to test \(H_0:\gamma=0\); and comment whether we there is a significant quadratic term
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \(\frac{\hat{\gamma} - \gamma}{e.s.e(\hat{\gamma})} \sim t(n-p) = \frac{1.030423 - 0}{0.1406} = 7.328755\) where the value follows Student's t distribution with \(n-p = 19 - 2 = 17\) degrees of freedom. We can now estimate the a p-value using Student's t distribution table or use a function in R
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}\OperatorTok{*}\KeywordTok{pt}\NormalTok{(}\FloatTok{7.328755}\NormalTok{, }\DataTypeTok{df=}\DecValTok{14{-}3}\NormalTok{, }\DataTypeTok{lower=}\NormalTok{F)}
\CommentTok{\#\# [1] 1.487682e{-}05}
\end{Highlighting}
\end{Shaded}

As p-value \textless\textless{} 0.001 there is sufficient evidence to reject \(H_0\) in favor of \(H_1\), thus we can conclude that there is a significant quadratic relationship between glucose and storage time

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  predict glucose concentration at storage time 4 and 16 weeks
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new.obs \textless{}{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{X1 =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{16}\NormalTok{), }\DataTypeTok{X2 =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{, }\DecValTok{16}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{pred.y \textless{}{-}}\StringTok{ }\KeywordTok{predict}\NormalTok{(model, }\DataTypeTok{newdata =}\NormalTok{ new.obs)}

\KeywordTok{plot}\NormalTok{(data.potatoes}\OperatorTok{$}\NormalTok{Weeks, data.potatoes}\OperatorTok{$}\NormalTok{Glucose, }\DataTypeTok{xlab=}\StringTok{"Storage time [weeks]"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Glucose [g/kg]"}\NormalTok{, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(data.potatoes}\OperatorTok{$}\NormalTok{Weeks, model}\OperatorTok{$}\NormalTok{fitted.values, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{)}
\KeywordTok{points}\NormalTok{(new.obs[,}\DecValTok{1}\NormalTok{], pred.y, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{301-linear-models_files/figure-latex/potato-predict-1.pdf}

\hypertarget{regression-coefficients}{%
\chapter{Regression coefficients}\label{regression-coefficients}}

\textbf{Aims}

\begin{itemize}
\tightlist
\item
  to clarify the interpretation of the fitted linear models
\end{itemize}

\textbf{Learning outcomes}

\begin{itemize}
\tightlist
\item
  to use lm() function to fit multiple linear regression model
\item
  to be able to interpret the output of the model
\item
  to be able to use lm() function to check for association between variables, group effects and interaction terms
\end{itemize}

\hypertarget{interpreting-and-using-linear-regression-models}{%
\section{Interpreting and using linear regression models}\label{interpreting-and-using-linear-regression-models}}

\begin{itemize}
\tightlist
\item
  In previous section we have seen how to find estimates of model coefficients, using theorems and vector-matrix notations.
\item
  Now, we will focus on what model coefficient values tell us and how to interpret them
\item
  And we will look at the common cases of using linear regression models
\item
  We will do this via analyzing some examples
\end{itemize}

\hypertarget{example-plasma-volume}{%
\section{Example: plasma volume}\label{example-plasma-volume}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# data}
\NormalTok{weight \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{58}\NormalTok{, }\DecValTok{70}\NormalTok{, }\DecValTok{74}\NormalTok{, }\FloatTok{63.5}\NormalTok{, }\FloatTok{62.0}\NormalTok{, }\FloatTok{70.5}\NormalTok{, }\FloatTok{71.0}\NormalTok{, }\FloatTok{66.0}\NormalTok{) }\CommentTok{\# body weight (kg)}
\NormalTok{plasma \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{2.75}\NormalTok{, }\FloatTok{2.86}\NormalTok{, }\FloatTok{3.37}\NormalTok{, }\FloatTok{2.76}\NormalTok{, }\FloatTok{2.62}\NormalTok{, }\FloatTok{3.49}\NormalTok{, }\FloatTok{3.05}\NormalTok{, }\FloatTok{3.12}\NormalTok{) }\CommentTok{\# plasma volume (liters)}

\CommentTok{\# fit regression model}
\NormalTok{model \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(plasma }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{weight)}

\CommentTok{\# plot the original data and fitted regression line}
\KeywordTok{plot}\NormalTok{(weight, plasma, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{xlab=}\StringTok{"weight [kg]"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"plasma [l]"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(weight, model}\OperatorTok{$}\NormalTok{fitted.values, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{) }\CommentTok{\# fitted model in red}
\KeywordTok{grid}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{302-linear-coeffcients_files/figure-latex/plasma-volume-plot-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{\# print model summary}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = plasma \textasciitilde{} weight)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}0.27880 {-}0.14178 {-}0.01928  0.13986  0.32939 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#             Estimate Std. Error t value Pr(\textgreater{}|t|)  }
\CommentTok{\#\# (Intercept)  0.08572    1.02400   0.084   0.9360  }
\CommentTok{\#\# weight       0.04362    0.01527   2.857   0.0289 *}
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 0.2188 on 6 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.5763,	Adjusted R{-}squared:  0.5057 }
\CommentTok{\#\# F{-}statistic:  8.16 on 1 and 6 DF,  p{-}value: 0.02893}
\end{Highlighting}
\end{Shaded}

\textbf{Model:}

\begin{itemize}
\tightlist
\item
  \(Y_i = \alpha + \beta x_i + \epsilon_i\) where \(x_i\) corresponds to \(weight_i\)
\end{itemize}

\textbf{Slope}

\begin{itemize}
\tightlist
\item
  The value of slope tells us how and by much the outcome changes with a unit change in \(x\)
\item
  If we go up in weight 1 kg what would be our expected change in plasma volume?
  \_ Answer: it would increase by 0.04 liter
\item
  And if we go up in weight 10 kg what would be our expected change in plasma volume?
\item
  Answer: it would increase by \(0.04 \cdot 10 = 0.4\) liter
\end{itemize}

\textbf{Intercept}

\begin{itemize}
\tightlist
\item
  the intercept, often labeled the constant, is the value of Y when \(x_i=0\)
\item
  in models where \(x_i\) can be equal 0, the intercept is simply the expected mean value of response
\item
  in models where \(x_i\) cannot be equal 0, like in our plasma example no weight makes no sense for healthy men, the intercept has no intrinsic meaning
\item
  the intercept is thus quite often ignored in linear models, as it is the value of slope that dictates the association between exposure and outcome
\end{itemize}

\hypertarget{example-galapagos-islands}{%
\section{Example: Galapagos Islands}\label{example-galapagos-islands}}

Researchers were interested in biological diversity on the Galapagos islands. They've collected data on number of plant species (Species) and number of endemic species on 30 islands as well as some descriptors of the islands such as area {[}\(\mathrm{km^2}\){]}, elevation {[}m{]}, distance to nearest island {[}km{]}, distance to Santa Cruz {[}km{]} and the area of the adjacent island {[}\(\mathrm{km^2}\){]}.

The preview of data is here:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Data is available via faraway package}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(faraway))\{}
    \KeywordTok{install.packages}\NormalTok{(}\StringTok{"faraway"}\NormalTok{)}
    \KeywordTok{library}\NormalTok{(faraway)}
\NormalTok{\}}

\KeywordTok{head}\NormalTok{(gala)}
\CommentTok{\#\#              Species Endemics  Area Elevation Nearest Scruz Adjacent}
\CommentTok{\#\# Baltra            58       23 25.09       346     0.6   0.6     1.84}
\CommentTok{\#\# Bartolome         31       21  1.24       109     0.6  26.3   572.33}
\CommentTok{\#\# Caldwell           3        3  0.21       114     2.8  58.7     0.78}
\CommentTok{\#\# Champion          25        9  0.10        46     1.9  47.4     0.18}
\CommentTok{\#\# Coamano            2        1  0.05        77     1.9   1.9   903.82}
\CommentTok{\#\# Daphne.Major      18       11  0.34       119     8.0   8.0     1.84}
\end{Highlighting}
\end{Shaded}

And we can fit a linear regression model to model number of Species given the remaining variables. Let's keep aside for now that number of Species is actually a count variable, not a continuous numerical variable, we just want to estimate the number of Species for now.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fit multiple linear regression and print model summary}
\NormalTok{model1 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(Species }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Area }\OperatorTok{+}\StringTok{ }\NormalTok{Elevation }\OperatorTok{+}\StringTok{ }\NormalTok{Nearest }\OperatorTok{+}\StringTok{ }\NormalTok{Scruz }\OperatorTok{+}\StringTok{ }\NormalTok{Adjacent, }\DataTypeTok{data =}\NormalTok{ gala)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model1))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = Species \textasciitilde{} Area + Elevation + Nearest + Scruz + Adjacent, }
\CommentTok{\#\#     data = gala)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}111.679  {-}34.898   {-}7.862   33.460  182.584 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#              Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept)  7.068221  19.154198   0.369 0.715351    }
\CommentTok{\#\# Area        {-}0.023938   0.022422  {-}1.068 0.296318    }
\CommentTok{\#\# Elevation    0.319465   0.053663   5.953 3.82e{-}06 ***}
\CommentTok{\#\# Nearest      0.009144   1.054136   0.009 0.993151    }
\CommentTok{\#\# Scruz       {-}0.240524   0.215402  {-}1.117 0.275208    }
\CommentTok{\#\# Adjacent    {-}0.074805   0.017700  {-}4.226 0.000297 ***}
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 60.98 on 24 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.7658,	Adjusted R{-}squared:  0.7171 }
\CommentTok{\#\# F{-}statistic:  15.7 on 5 and 24 DF,  p{-}value: 6.838e{-}07}
\end{Highlighting}
\end{Shaded}

\textbf{Model}

\begin{itemize}
\tightlist
\item
  \(Y_i = \beta_0 + \beta_1 Area_i + \beta_2 Area_i + \beta_3 Elevation_i + \beta_4 Scruz_i + \beta_5 Adjacent_i + \epsilon_i\)
\end{itemize}

\textbf{Slope}

\begin{itemize}
\tightlist
\item
  Compare two islands, where the second island has an elevation one meter higher than the first one, what can we say about the number of species according to the model?
\item
  Answer: the second island will have 0.32 species more than the first one
\item
  How about if the difference is 100 m?
\item
  Answer: now the second island will have \(0.32 \cdot 100 = 32\) more species
\end{itemize}

\textbf{Not so easy}

\begin{itemize}
\tightlist
\item
  Consider an alternative model where we only use evaluation to model the number of species
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model2 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(Species }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Elevation, }\DataTypeTok{data =}\NormalTok{ gala)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model2))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = Species \textasciitilde{} Elevation, data = gala)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}218.319  {-}30.721  {-}14.690    4.634  259.180 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#             Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept) 11.33511   19.20529   0.590     0.56    }
\CommentTok{\#\# Elevation    0.20079    0.03465   5.795 3.18e{-}06 ***}
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 78.66 on 28 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.5454,	Adjusted R{-}squared:  0.5291 }
\CommentTok{\#\# F{-}statistic: 33.59 on 1 and 28 DF,  p{-}value: 3.177e{-}06}
\end{Highlighting}
\end{Shaded}

\textbf{Model}

\begin{itemize}
\tightlist
\item
  \(Y_i = \beta_0 + \beta_1 Elevation_i + \epsilon_i\)
\end{itemize}

\textbf{Slope}

\begin{itemize}
\tightlist
\item
  Compare two islands, where the second island has an elevation one meter higher than the first one, what can we say about the number of species according to the model?
\item
  Answer: the second island will have 0.20 species more than the first one
\item
  How about if the difference is 100 m?
\item
  Answer: now the second island will have \(0.20 \cdot 100 = 20\) more species
\end{itemize}

\textbf{Specific interpretation}

\begin{itemize}
\tightlist
\item
  obviously there is difference between 32 and 20 species given the same elevation difference and using the two different models
\item
  our interpretations need to be more specific and we say
\item
  \textbf{a unit increase in \(x\) with other predictors held constant will produce a change equal to \(\hat{\beta}\) in the response \(y\)}
\item
  it is of course often quite unrealistic to be able to control other variables and keep them constant and for our simple regression, model 2, a change in evaluation is most likely associated with other variables, even though they are not included in the model
\item
  further, our explanation contains \textbf{no notation of causation}, even thought the two models are showing a strong association between elevation and number of species
\item
  we will learn later how to assess models and select variables (feature selection), here, we continue focusing on learning how to interpret the coefficients given a model
\end{itemize}

\hypertarget{example-height-and-gender}{%
\section{Example: Height and gender}\label{example-height-and-gender}}

\begin{itemize}
\tightlist
\item
  Data are available containing the weight {[}lbs{]} and height {[}inches{]} of 10000 men and women
\item
  We want to compare the average height of men and women
\item
  We can do that using linear regression and including gender as \textbf{binary variable}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# read in data}
\NormalTok{htwtgen \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/lm/heights\_weights\_genders.csv"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(htwtgen)}
\CommentTok{\#\#   Gender   Height   Weight}
\CommentTok{\#\# 1   Male 73.84702 241.8936}
\CommentTok{\#\# 2   Male 68.78190 162.3105}
\CommentTok{\#\# 3   Male 74.11011 212.7409}
\CommentTok{\#\# 4   Male 71.73098 220.0425}
\CommentTok{\#\# 5   Male 69.88180 206.3498}
\CommentTok{\#\# 6   Male 67.25302 152.2122}

\CommentTok{\# boxplot for females and males}
\KeywordTok{boxplot}\NormalTok{(htwtgen}\OperatorTok{$}\NormalTok{Height }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{htwtgen}\OperatorTok{$}\NormalTok{Gender, }\DataTypeTok{xlab=}\StringTok{""}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Height"}\NormalTok{, }\DataTypeTok{col=}\StringTok{"lightblue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{302-linear-coeffcients_files/figure-latex/height-gender-1} \end{center}

\textbf{Model}

\[Y_i = \alpha + \beta I_{x_i} + \epsilon_i\]
where
\begin{equation}
    I_{x_i} =
    \left\{
        \begin{array}{cc}
                1 & \mathrm{if\ } x_i=1 \\
                0 & \mathrm{if\ } x_i=0 \\
        \end{array}
    \right.
\end{equation}
for some coding, e.g.~we choose to set ``Female=1'' and ``Male=0'' or vice versa.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fit linear regression and print model summary}
\NormalTok{model1 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(Height }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Gender, }\DataTypeTok{data =}\NormalTok{ htwtgen)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model1))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = Height \textasciitilde{} Gender, data = htwtgen)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}10.6194  {-}1.8374   0.0088   1.9185   9.9724 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#             Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept) 63.70877    0.03933  1619.8   \textless{}2e{-}16 ***}
\CommentTok{\#\# GenderMale   5.31757    0.05562    95.6   \textless{}2e{-}16 ***}
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 2.781 on 9998 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.4776,	Adjusted R{-}squared:  0.4775 }
\CommentTok{\#\# F{-}statistic:  9140 on 1 and 9998 DF,  p{-}value: \textless{} 2.2e{-}16}
\end{Highlighting}
\end{Shaded}

\textbf{Estimates}
\[\hat{\alpha} = 63.71\]
\[\hat{\beta} = 5.32\]

\begin{itemize}
\tightlist
\item
  The lm() function choose one of the category as baseline, here Females
\item
  model summary prints the output of the model with the baseline category ``hidden''
\item
  notice the only label we have is ``GenderMale''
\item
  meaning that we ended-up having a model coded as below:
  \begin{equation}
    I_{x_i} =
    \left\{
        \begin{array}{cc}
                1 & \mathrm{if\ } \quad person_i\;is\;male \\
                0 & \mathrm{if\ } \quad person_i\;is\;female \\
        \end{array}
    \right.
  \end{equation}
\item
  Consequently, if observation \(i\) is male then the expected value of height is:
  \[E(Height_i|Male) = 63.71 + 5.32 = 69.03\]
\item
  and if observation \(i\) is female then the expected value of height is:
  \[E(Height_i|Male) = 63.71\]
\end{itemize}

\hypertarget{example-heigth-weight-and-gender-i}{%
\section{Example: Heigth, weight and gender I}\label{example-heigth-weight-and-gender-i}}

\begin{itemize}
\tightlist
\item
  So there is a difference in height between the gender, as expected
\item
  Is there a relationship between weight and height?
\item
  If so, does this relationship depend on gender?
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}

\CommentTok{\# plot the data separately for Male and Female}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data=}\NormalTok{htwtgen, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Weight, }\DataTypeTok{y=}\NormalTok{Height, }\DataTypeTok{col =}\NormalTok{ Gender)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{302-linear-coeffcients_files/figure-latex/htwtgen-plot-1} \end{center}

\begin{itemize}
\tightlist
\item
  From the plot we can see that height increases with weight
\item
  Males have higher heights than females
\item
  Males have higher weights than females
\item
  The relationship between height and weight appears to be the same for males and females, i.e.~height increass with weight for both men and women
\end{itemize}

\textbf{Model}

\[Y_i = \alpha + \beta I_{x_i} + \gamma x_{2,i} + \epsilon_i\]
where
\begin{equation}
    I_{x_i} =
    \left\{
        \begin{array}{cc}
                1 & \mathrm{if\ } \quad person_i\;is\;male \\
                0 & \mathrm{if\ } \quad person_i\;is\;female \\
        \end{array}
    \right.
\end{equation}

and \(x_{2,i}\) is the weight of person \(i\)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Fit linear model and print model summary}
\NormalTok{model2 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(Height }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Gender }\OperatorTok{+}\StringTok{ }\NormalTok{Weight, }\DataTypeTok{data =}\NormalTok{ htwtgen) }
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model2))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = Height \textasciitilde{} Gender + Weight, data = htwtgen)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#     Min      1Q  Median      3Q     Max }
\CommentTok{\#\# {-}5.4956 {-}0.9583  0.0126  0.9867  5.8358 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#               Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept) 47.0306678  0.1025161  458.76   \textless{}2e{-}16 ***}
\CommentTok{\#\# GenderMale  {-}0.9628643  0.0474947  {-}20.27   \textless{}2e{-}16 ***}
\CommentTok{\#\# Weight       0.1227594  0.0007396  165.97   \textless{}2e{-}16 ***}
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 1.435 on 9997 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.8609,	Adjusted R{-}squared:  0.8609 }
\CommentTok{\#\# F{-}statistic: 3.093e+04 on 2 and 9997 DF,  p{-}value: \textless{} 2.2e{-}16}
\end{Highlighting}
\end{Shaded}

\textbf{Estimates}
\[\hat{\alpha} = 47.031\]
\[\hat{\beta} = -0.963\]
\[\hat{\gamma} = 0.123\]

\begin{itemize}
\tightlist
\item
  therefore, for a male of weight 161.4 we would predict a height of:
  \[E(Height_i|Male, Weight = 161.4) = 47.031 - 0.963 + (0.123 \cdot 161.4) = 65.9\]
\item
  and for a female of weight 161.4 we would predict a height of
  \[E(Height_i|Female, Weight = 161.4) = 47.031 + (0.123 \cdot 161.4) = 66.9\]
\item
  as much as our calculations are correct, the above example also shows the need of considering the data when interpreting coefficients. Our expected female height at weight 161.4 is 66.9, larger than the men height, 65.9. However, our data show that the the majority of our values for female lie between 100 and 175 and between 150 and 250 for males, i.e.~in different ranges
\item
  we should \textbf{not predict outside the data range}
\item
  finally, we can plot our data and the fitted model
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot the data separately for Male and Female}
\CommentTok{\# using ggplot() and geom\_smooth()}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data=}\NormalTok{htwtgen, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Weight, }\DataTypeTok{y=}\NormalTok{Height, }\DataTypeTok{col =}\NormalTok{ Gender)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.1}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom\_smooth}\NormalTok{(}\DataTypeTok{method=}\NormalTok{lm)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{302-linear-coeffcients_files/figure-latex/unnamed-chunk-3-1} \end{center}

\hypertarget{example-heigth-weight-and-gender-ii}{%
\section{Example: Heigth, weight and gender II}\label{example-heigth-weight-and-gender-ii}}

\begin{itemize}
\tightlist
\item
  The fitted lines in the above example are parallel, the slope is modeled to be the same for male and females, and the intercept denotes the group differences
\item
  It is also possible to allow both intercept and slope being fitted separately for each group
\item
  This is done when we except that the relationships are different in different groups
\item
  And we then talk about including \textbf{interaction effect}
\end{itemize}

\textbf{Model}

\[Y_{i,j} = \alpha_i + \beta_ix_{ij} + \epsilon_{i,j}\]
where:

\begin{itemize}
\tightlist
\item
  \(Y_{i,j}\) is the height of person \(j\) of gender \(i\)
\item
  \(x_{ij}\) is the weight of person \(j\) of gender \(i\)
\item
  \(i=1\) corresponds to males in our example (keeping the same coding as above)
\item
  \(i=2\) corresponds to females
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fit linear model with interaction }
\NormalTok{model3 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(Height }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Gender }\OperatorTok{*}\StringTok{ }\NormalTok{Weight, }\DataTypeTok{data =}\NormalTok{ htwtgen)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model3))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = Height \textasciitilde{} Gender * Weight, data = htwtgen)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#     Min      1Q  Median      3Q     Max }
\CommentTok{\#\# {-}5.4698 {-}0.9568  0.0092  0.9818  5.7544 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#                    Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept)       47.347783   0.146325 323.579  \textless{} 2e{-}16 ***}
\CommentTok{\#\# GenderMale        {-}1.683668   0.242119  {-}6.954 3.78e{-}12 ***}
\CommentTok{\#\# Weight             0.120425   0.001067 112.903  \textless{} 2e{-}16 ***}
\CommentTok{\#\# GenderMale:Weight  0.004493   0.001480   3.036   0.0024 ** }
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 1.435 on 9996 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.861,	Adjusted R{-}squared:  0.861 }
\CommentTok{\#\# F{-}statistic: 2.064e+04 on 3 and 9996 DF,  p{-}value: \textless{} 2.2e{-}16}
\end{Highlighting}
\end{Shaded}

Now, based on the regression output we would expect:

\begin{itemize}
\tightlist
\item
  for a male of weight \(x\), a height of:
  \[E(height|male\; and \; weight=x)=47.34778 - 1.68367 + 0.12043x + 0.00449x = 45.7 + 0.125x\]
\item
  for a female of weight \(x\), a height of \[E(height|female\; and \; weight=x)=47.34778 + 0.12043x\]
\end{itemize}

\textbf{Estimates}
\[\hat{\alpha_1} = 45.7\]
\[\hat{\beta_1} = 0.125\]

\[\hat{\alpha_2} = 47.34778\]
\[\hat{\beta_2} = 0.12043\]

\begin{itemize}
\tightlist
\item
  we can see from the regression output that the interaction term, "GenderMale:Weight, is significant
\item
  and therefore the relationship between weight and height is different in males and females
\item
  we can plot the fitted model now and see that the lines are no longer parallel
\item
  we will see clearer example of interactions in exercises
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# ggiraphExtra makes it easy to visualize fitted models}
\ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{require}\NormalTok{(ggiraphExtra))\{}
    \KeywordTok{install.packages}\NormalTok{(}\StringTok{"ggiraphExtra"}\NormalTok{)}
    \KeywordTok{library}\NormalTok{(ggiraphExtra)}
\NormalTok{\}}

\KeywordTok{ggPredict}\NormalTok{(model3)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{302-linear-coeffcients_files/figure-latex/unnamed-chunk-5-1} \end{center}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{exercises-linear-models-ii}{%
\section{Exercises: linear models II}\label{exercises-linear-models-ii}}

Data for exercises

\begin{itemize}
\tightlist
\item
  \href{https://github.com/olgadet/bookdown-mlbiostatistics/tree/master/data/data.zip}{Link 1}
\item
  \href{https://stockholmuniversity.box.com/s/z5kwg0nlwe5la4h5t8bshpj57pylif14}{Alternative Link 2}
\end{itemize}

\begin{exercise}
\protect\hypertarget{exr:lm-rerun}{}{\label{exr:lm-rerun} }
Given the ``height-weight-gender'' data:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  repeat fitting the models with a) gender, b) weight and gender and c) interaction between weight and gender
\item
  given the model with the interaction term, what is expected height of males and females give weight of 120 lbs?
\item
  can you use predict() function to check your calculations?
\end{enumerate}
\end{exercise}

\begin{exercise}
\protect\hypertarget{exr:lm-trout}{}{\label{exr:lm-trout} }
When the behavior of a group of trout is studied, some fish are observed to become dominant and others to become subordinate. Dominant fish have freedom of movement whereas subordinate fish tend to congregate in the periphery of the waterway to avoid crossing the path of the dominant fish. Data on energy expenditure and ration of blood obtained were collected as part of a laboratory experiment for 20 trout. Energy and ration is measured in calories per kilo-calorie per trout per day.

Use the below code to load the data to R and use linear regression models to answer:

\begin{itemize}
\item
  \begin{enumerate}
  \def\labelenumi{\alph{enumi})}
  \tightlist
  \item
    is there a relationship between ration obtained and energy expenditure
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\alph{enumi})}
  \setcounter{enumi}{1}
  \tightlist
  \item
    is the relationship between ration obtained and energy expenditure different for each type of fish?
  \end{enumerate}
\item
  Hint: it is good to start with some explanatory plots between every pair of variable
\end{itemize}
\end{exercise}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# read in data and show preview}
\NormalTok{trout \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/lm/trout.csv"}\NormalTok{)}

\CommentTok{\# recode the Group variable and treat like categories (factor)}
\NormalTok{trout}\OperatorTok{$}\NormalTok{Group \textless{}{-}}\StringTok{ }\KeywordTok{factor}\NormalTok{(trout}\OperatorTok{$}\NormalTok{Group, }\DataTypeTok{labels=}\KeywordTok{c}\NormalTok{(}\StringTok{"Dominant"}\NormalTok{, }\StringTok{"Subordinate"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{exercise}
\protect\hypertarget{exr:lm-blooddrug}{}{\label{exr:lm-blooddrug} }A clinical trial

A clinical trial has been carried out to compare three drug treatments which are intended to lower blood pressure in hypertensive patients. The data contains initial values fo systolic blood pressure (bp) in mmHg for each patient and the reduction achieved during the course of the trial. For each patient, allocation to treatment (drug) was carried out randomly and conditions such as the length of the treatment and dose of the drug were standardized as far as possible.

Use linear regression to answer questions:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  is there an association between the reduction in blood pressure and initial blood pressure
\item
  is reduction in blood pressure different across the treatment (in three drug groups)?
\item
  is reduction in blood pressure different across the treatment when accounting for initial blood pressure?
\item
  is reduction in blood pressure chaining differently under different treatment?
  Hint: here we have three categories which can be seen as expalnding the models with tow categories by an additional one: one category will be treated as baseline
\end{enumerate}
\end{exercise}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{blooddrug \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/lm/bloodrug.csv"}\NormalTok{)}
\NormalTok{blooddrug}\OperatorTok{$}\NormalTok{drug \textless{}{-}}\StringTok{ }\KeywordTok{factor}\NormalTok{(blooddrug}\OperatorTok{$}\NormalTok{drug)}
\KeywordTok{head}\NormalTok{(blooddrug)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   initial redn drug
## 1     158    4    1
## 2     176   21    1
## 3     174   36    1
## 4     168   14    1
## 5     174   34    1
## 6     186   37    1
\end{verbatim}

\hypertarget{answers-to-selected-exercises-linear-models-ii}{%
\section*{Answers to selected exercises (linear models II)}\label{answers-to-selected-exercises-linear-models-ii}}
\addcontentsline{toc}{section}{Answers to selected exercises (linear models II)}

Exr. \ref{exr:lm-rerun}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{htwtgen \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/lm/heights\_weights\_genders.csv"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(htwtgen)}
\CommentTok{\#\#   Gender   Height   Weight}
\CommentTok{\#\# 1   Male 73.84702 241.8936}
\CommentTok{\#\# 2   Male 68.78190 162.3105}
\CommentTok{\#\# 3   Male 74.11011 212.7409}
\CommentTok{\#\# 4   Male 71.73098 220.0425}
\CommentTok{\#\# 5   Male 69.88180 206.3498}
\CommentTok{\#\# 6   Male 67.25302 152.2122}

\CommentTok{\# a)}
\NormalTok{model1 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(Height }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Gender, }\DataTypeTok{data =}\NormalTok{ htwtgen)}
\NormalTok{model2 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(Height }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Gender }\OperatorTok{+}\StringTok{ }\NormalTok{Weight, }\DataTypeTok{data =}\NormalTok{ htwtgen)}
\NormalTok{model3 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(Height }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Gender }\OperatorTok{*}\StringTok{ }\NormalTok{Weight, }\DataTypeTok{data =}\NormalTok{ htwtgen)}

\CommentTok{\# print(summary(model1))}
\CommentTok{\# print(summary(model2))}
\CommentTok{\# print(summary(model3))}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{1}
\item
  use equations to find the height for men and women respectively:
  \[E(height|male\; and \; weight=x)=47.34778 - 1.68367 + 0.12043x + 0.00449x = 45.7 + 0.125x\]
  \[E(height|female\; and \; weight=x)=47.34778 + 0.12043x\]
\item
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# for men}
\NormalTok{new.obs \textless{}{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{Weight=}\DecValTok{120}\NormalTok{, }\DataTypeTok{Gender=}\StringTok{"Male"}\NormalTok{)}
\KeywordTok{predict}\NormalTok{(model3, }\DataTypeTok{newdata =}\NormalTok{ new.obs)}
\CommentTok{\#\#        1 }
\CommentTok{\#\# 60.65427}

\CommentTok{\# for female}
\NormalTok{new.obs \textless{}{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{Weight=}\DecValTok{120}\NormalTok{, }\DataTypeTok{Gender=}\StringTok{"Female"}\NormalTok{)}
\KeywordTok{predict}\NormalTok{(model3, }\DataTypeTok{newdata =}\NormalTok{ new.obs)}
\CommentTok{\#\#        1 }
\CommentTok{\#\# 61.79882}
\end{Highlighting}
\end{Shaded}

Exr. \ref{exr:lm-trout}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# read in data and show preview}
\NormalTok{trout \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/lm/trout.csv"}\NormalTok{)}

\CommentTok{\# recode the Group variable and treat like categories (factor)}
\NormalTok{trout}\OperatorTok{$}\NormalTok{Group \textless{}{-}}\StringTok{ }\KeywordTok{factor}\NormalTok{(trout}\OperatorTok{$}\NormalTok{Group, }\DataTypeTok{labels=}\KeywordTok{c}\NormalTok{(}\StringTok{"Dominant"}\NormalTok{, }\StringTok{"Subordinate"}\NormalTok{))}
\KeywordTok{head}\NormalTok{(trout)}
\CommentTok{\#\#   Energy Ration    Group}
\CommentTok{\#\# 1  44.26  81.35 Dominant}
\CommentTok{\#\# 2  67.16  91.68 Dominant}
\CommentTok{\#\# 3  48.15  58.00 Dominant}
\CommentTok{\#\# 4  34.53  58.63 Dominant}
\CommentTok{\#\# 5  67.93  91.93 Dominant}
\CommentTok{\#\# 6  72.45  96.56 Dominant}

\CommentTok{\# plot data}
\CommentTok{\# boxplots of Energy and Ration per group}
\KeywordTok{boxplot}\NormalTok{(trout}\OperatorTok{$}\NormalTok{Energy }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{trout}\OperatorTok{$}\NormalTok{Group, }\DataTypeTok{xlab=}\StringTok{""}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Energy"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{302-linear-coeffcients_files/figure-latex/unnamed-chunk-10-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{boxplot}\NormalTok{(trout}\OperatorTok{$}\NormalTok{Ration }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{trout}\OperatorTok{$}\NormalTok{Group, }\DataTypeTok{xlab=}\StringTok{""}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Ration"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{302-linear-coeffcients_files/figure-latex/unnamed-chunk-10-2} \end{center}

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{\# scatter plot of Ration vs. Energy}
\KeywordTok{plot}\NormalTok{(trout}\OperatorTok{$}\NormalTok{Ration, trout}\OperatorTok{$}\NormalTok{Energy, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{xlab=}\StringTok{"Ration"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Energy"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{302-linear-coeffcients_files/figure-latex/unnamed-chunk-10-3} \end{center}

\begin{itemize}
\tightlist
\item
  From the exploratory plots we see that there is some sort of relationship between ratio and energy, i.e.~energy increase while ration obtained increases
\item
  From boxplots we see that the ration obtained may be different in two groups
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Is there a relationship between ration obtained and energy expenditure}
\NormalTok{model1 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(Energy }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Ration, }\DataTypeTok{data =}\NormalTok{ trout)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model1))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = Energy \textasciitilde{} Ration, data = trout)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#     Min      1Q  Median      3Q     Max }
\CommentTok{\#\# {-}18.704  {-}4.703  {-}0.578   2.432  33.506 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#             Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept)   4.3037    12.5156   0.344 0.734930    }
\CommentTok{\#\# Ration        0.7211     0.1716   4.203 0.000535 ***}
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 12.05 on 18 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.4953,	Adjusted R{-}squared:  0.4673 }
\CommentTok{\#\# F{-}statistic: 17.66 on 1 and 18 DF,  p{-}value: 0.0005348}
\CommentTok{\# from the regression output we can see that yes, a unit increase in ratio increase energy expenditure by 0.72}

\CommentTok{\# Is there a relationship between ration obtained and energy expenditure different for each type of fish?}
\CommentTok{\# we first check if there is a group effect}
\NormalTok{model2 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(Energy }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Ration }\OperatorTok{+}\StringTok{ }\NormalTok{Group, }\DataTypeTok{data =}\NormalTok{ trout)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model2))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = Energy \textasciitilde{} Ration + Group, data = trout)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#     Min      1Q  Median      3Q     Max }
\CommentTok{\#\# {-}13.130  {-}5.139  {-}0.870   2.199  25.622 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#                  Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept)      {-}24.8506    13.3031  {-}1.868  0.07910 .  }
\CommentTok{\#\# Ration             1.0109     0.1626   6.218 9.36e{-}06 ***}
\CommentTok{\#\# GroupSubordinate  17.0120     5.1075   3.331  0.00396 ** }
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 9.647 on 17 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.6946,	Adjusted R{-}squared:  0.6587 }
\CommentTok{\#\# F{-}statistic: 19.33 on 2 and 17 DF,  p{-}value: 4.182e{-}05}
\KeywordTok{ggPredict}\NormalTok{(model2)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{302-linear-coeffcients_files/figure-latex/unnamed-chunk-11-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{\# and whether there is interaction effect}
\NormalTok{model3 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(Energy }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Ration }\OperatorTok{*}\StringTok{ }\NormalTok{Group, }\DataTypeTok{data =}\NormalTok{ trout)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model3))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = Energy \textasciitilde{} Ration * Group, data = trout)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}12.7951  {-}6.0981  {-}0.1554   3.9612  23.5946 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#                         Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept)              {-}9.2330    15.9394  {-}0.579 0.570483    }
\CommentTok{\#\# Ration                    0.8149     0.1968   4.141 0.000767 ***}
\CommentTok{\#\# GroupSubordinate        {-}18.9558    22.6934  {-}0.835 0.415848    }
\CommentTok{\#\# Ration:GroupSubordinate   0.5200     0.3204   1.623 0.124148    }
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 9.214 on 16 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.7378,	Adjusted R{-}squared:  0.6886 }
\CommentTok{\#\# F{-}statistic:    15 on 3 and 16 DF,  p{-}value: 6.537e{-}05}
\KeywordTok{ggPredict}\NormalTok{(model3)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{302-linear-coeffcients_files/figure-latex/unnamed-chunk-11-2} \end{center}

Based on the regression output and plots we can say:

\begin{itemize}
\tightlist
\item
  there is relationship between ration obtained and energy expenditure
\item
  that this relationship is the same in the two groups although the energy expenditure is higher in the dominant fish
\end{itemize}

\hypertarget{model-summary-assumptions}{%
\chapter{Model summary \& assumptions}\label{model-summary-assumptions}}

\textbf{Aims}

\begin{itemize}
\tightlist
\item
  to introduce concepts of linear models summary and assumptions
\end{itemize}

\textbf{Learning outcomes}

\begin{itemize}
\tightlist
\item
  to able to interpret \(R^2\) and \(R^2(adj)\) values
\item
  state the assumptions of a linear model and assess them using residual plots
\end{itemize}

\hypertarget{assessing-model-fit}{%
\section{Assessing model fit}\label{assessing-model-fit}}

\begin{itemize}
\tightlist
\item
  earlier we learned how to estimate parameters in a liner model using least squares
\item
  now we will consider how to assess the goodness of fit of a model
\item
  we do that by calculating the amount of variability in the response that is explained by the model
\end{itemize}

\hypertarget{r2-summary-of-the-fitted-model}{%
\section{\texorpdfstring{\(R^2\): summary of the fitted model}{R\^{}2: summary of the fitted model}}\label{r2-summary-of-the-fitted-model}}

\begin{itemize}
\tightlist
\item
  considering a simple linear regression, the simplest model, \textbf{Model 0}, we could consider fitting is \[Y_i = \beta_0+ \epsilon_i\] that corresponds to a line that run through the data but lies parallel to the horizontal axis
\item
  in our plasma volume example that would correspond the mean value of plasma volume being predicted for any value of weight (in purple)
\end{itemize}

\begin{center}\includegraphics{303-linear-summary-assumptions_files/figure-latex/unnamed-chunk-1-1} \end{center}

\begin{itemize}
\tightlist
\item
  TSS, denoted \textbf{Total corrected sum-of-squares} is the residual sum-of-squares for Model 0
  \[S(\hat{\beta_0}) = TSS = \sum_{i=1}^{n}(y_i - \bar{y})^2 = S_{yy}\] corresponding the to the sum of squared distances to the purple line
\end{itemize}

\begin{center}\includegraphics{303-linear-summary-assumptions_files/figure-latex/unnamed-chunk-2-1} \end{center}

\begin{itemize}
\tightlist
\item
  Fitting \textbf{Model 1} of the form \[Y_i = \beta_0 + \beta_1x + \epsilon_i\] we have earlier defined
\item
  \textbf{RSS}, the residual sum-of-squares as:
  \[RSS = \displaystyle \sum_{i=1}^{n}(y_i - \{\hat{\beta_0} + \hat{\beta}_1x_{1i} + \dots + \hat{\beta}_px_{pi}\}) = \sum_{i=1}^{n}(y_i - \hat{y_i})^2\]
\item
  that corresponds to the squared distances between the observed values \(y_i, \dots,y_n\) to fitted values \(\hat{y_1}, \dots \hat{y_n}\), i.e.~distances to the red fitted line
\end{itemize}

\begin{center}\includegraphics{303-linear-summary-assumptions_files/figure-latex/unnamed-chunk-3-1} \end{center}

\begin{definition}
\protect\hypertarget{def:unnamed-chunk-4}{}{\label{def:unnamed-chunk-4} }
A simple but useful measure of model fit is given by \[R^2 = 1 - \frac{RSS}{TSS}\] where:

\begin{itemize}
\tightlist
\item
  RSS is the residual sum-of-squares for Model 1, the fitted model of interest
\item
  TSS is the sum of squares of the \textbf{null model}
\end{itemize}
\end{definition}

\begin{itemize}
\tightlist
\item
  \(R^2\) quantifies how much of a drop in the residual sum-of-squares is accounted for by fitting the proposed model
\item
  \(R^2\) is also referred as \textbf{coefficient of determination}
\item
  It is expressed on a scale, as a proportion (between 0 and 1) of the total variation in the data
\item
  Values of \(R^2\) approaching 1 indicate he model to be a good fit
\item
  Values of \(R^2\) less than 0.5 suggest that the model gives rather a poor fit to the data
\end{itemize}

\hypertarget{r2-and-correlation-coefficient}{%
\section{\texorpdfstring{\(R^2\) and correlation coefficient}{R\^{}2 and correlation coefficient}}\label{r2-and-correlation-coefficient}}

\begin{theorem}
\protect\hypertarget{thm:unnamed-chunk-5}{}{\label{thm:unnamed-chunk-5} }
In the case of simple linear regression:

Model 1: \(Y_i = \beta_0 + \beta_1x + \epsilon_i\)
\[R^2 = r^2\]
where:

\begin{itemize}
\tightlist
\item
  \(R^2\) is the coefficient of determination
\item
  \(r^2\) is the sample correlation coefficient
\end{itemize}
\end{theorem}

\hypertarget{r2adj}{%
\section{\texorpdfstring{\(R^2(adj)\)}{R\^{}2(adj)}}\label{r2adj}}

\begin{itemize}
\tightlist
\item
  in the case of multiple linear regression, where there is more than one explanatory variable in the model
\item
  we are using the adjusted version of R\^{}2 to assess the model fit
\item
  as the number of explanatory variables increase, \(R^2\) also increases
\item
  \(R^2(adj)\) takes this into account, i.e.~adjusts for the fact that there is more than one explanatory variable in the model
\end{itemize}

\begin{theorem}
\protect\hypertarget{thm:unnamed-chunk-6}{}{\label{thm:unnamed-chunk-6} }For any multiple linear regression
\[Y_i = \beta_0 + \beta_1x_{1i} + \dots + \beta_{p-1}x_{(p-1)i} +  \epsilon_i\] \(R^2(adj)\) is defined as
\[R^2(adj) = 1-\frac{\frac{RSS}{n-p-1}}{\frac{TSS}{n-1}}\] where

\begin{itemize}
\tightlist
\item
  \(p\) is the number of independent predictors, i.e.~the number of variables in the model, excluding the constant
\end{itemize}

\(R^2(adj)\) can also be calculated from \(R^2\):
\[R^2(adj) = 1 - (1-R^2)\frac{n-1}{n-p-1}\]
\end{theorem}

We can calculate the values in R and compare the results to the output of linear regression

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{htwtgen \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/lm/heights\_weights\_genders.csv"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(htwtgen)}
\CommentTok{\#\#   Gender   Height   Weight}
\CommentTok{\#\# 1   Male 73.84702 241.8936}
\CommentTok{\#\# 2   Male 68.78190 162.3105}
\CommentTok{\#\# 3   Male 74.11011 212.7409}
\CommentTok{\#\# 4   Male 71.73098 220.0425}
\CommentTok{\#\# 5   Male 69.88180 206.3498}
\CommentTok{\#\# 6   Male 67.25302 152.2122}
\KeywordTok{attach}\NormalTok{(htwtgen)}

\CommentTok{\#\# Simple linear regression}
\NormalTok{model.simple \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(Height }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Weight, }\DataTypeTok{data=}\NormalTok{htwtgen)}

\CommentTok{\# TSS}
\NormalTok{TSS \textless{}{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{((Height }\OperatorTok{{-}}\StringTok{ }\KeywordTok{mean}\NormalTok{(Height))}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{)}

\CommentTok{\# RSS}
\CommentTok{\# residuals are returned in the model type names(model.simple)}
\NormalTok{RSS \textless{}{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{((model.simple}\OperatorTok{$}\NormalTok{residuals)}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{R2 \textless{}{-}}\StringTok{ }\DecValTok{1} \OperatorTok{{-}}\StringTok{ }\NormalTok{(RSS}\OperatorTok{/}\NormalTok{TSS)}

\KeywordTok{print}\NormalTok{(R2)}
\CommentTok{\#\# [1] 0.8551742}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model.simple))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = Height \textasciitilde{} Weight, data = htwtgen)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#     Min      1Q  Median      3Q     Max }
\CommentTok{\#\# {-}5.8142 {-}0.9907  0.0263  0.9918  5.5950 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#              Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept) 4.848e+01  7.507e{-}02   645.8   \textless{}2e{-}16 ***}
\CommentTok{\#\# Weight      1.108e{-}01  4.561e{-}04   243.0   \textless{}2e{-}16 ***}
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 1.464 on 9998 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.8552,	Adjusted R{-}squared:  0.8552 }
\CommentTok{\#\# F{-}statistic: 5.904e+04 on 1 and 9998 DF,  p{-}value: \textless{} 2.2e{-}16}

\CommentTok{\#\# Multiple regression}
\NormalTok{model.multiple \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(Height }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Weight }\OperatorTok{+}\StringTok{ }\NormalTok{Gender, }\DataTypeTok{data=}\NormalTok{htwtgen)}
\NormalTok{n \textless{}{-}}\StringTok{ }\KeywordTok{length}\NormalTok{(Weight)}
\NormalTok{p \textless{}{-}}\StringTok{ }\DecValTok{1}

\NormalTok{RSS \textless{}{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{((model.multiple}\OperatorTok{$}\NormalTok{residuals)}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{R2\_adj \textless{}{-}}\StringTok{ }\DecValTok{1} \OperatorTok{{-}}\StringTok{ }\NormalTok{(RSS}\OperatorTok{/}\NormalTok{(n}\OperatorTok{{-}}\NormalTok{p}\DecValTok{{-}1}\NormalTok{))}\OperatorTok{/}\NormalTok{(TSS}\OperatorTok{/}\NormalTok{(n}\DecValTok{{-}1}\NormalTok{))}

\KeywordTok{print}\NormalTok{(R2\_adj)}
\CommentTok{\#\# [1] 0.8608793}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model.multiple))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = Height \textasciitilde{} Weight + Gender, data = htwtgen)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#     Min      1Q  Median      3Q     Max }
\CommentTok{\#\# {-}5.4956 {-}0.9583  0.0126  0.9867  5.8358 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#               Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept) 47.0306678  0.1025161  458.76   \textless{}2e{-}16 ***}
\CommentTok{\#\# Weight       0.1227594  0.0007396  165.97   \textless{}2e{-}16 ***}
\CommentTok{\#\# GenderMale  {-}0.9628643  0.0474947  {-}20.27   \textless{}2e{-}16 ***}
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 1.435 on 9997 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.8609,	Adjusted R{-}squared:  0.8609 }
\CommentTok{\#\# F{-}statistic: 3.093e+04 on 2 and 9997 DF,  p{-}value: \textless{} 2.2e{-}16}
\end{Highlighting}
\end{Shaded}

\hypertarget{the-assumptions-of-a-linear-model}{%
\section{The assumptions of a linear model}\label{the-assumptions-of-a-linear-model}}

\begin{itemize}
\tightlist
\item
  up until now we were fitting models and discussed how to assess the model fit
\item
  before making use of a fitted model for explanation or prediction, it is wise to check that the model provides an adequate description of the data
\item
  informally we have been using box plots and scatter plots to look at the data
\item
  there are however formal definitions of the assumptions
\end{itemize}

\textbf{Assumption A: The deterministic part of the model captures all the non-random structure in the data}

\begin{itemize}
\tightlist
\item
  this implies that the \textbf{mean of the errors \(\epsilon_i\)} is zero
\item
  it applies only over the range of explanatory variables
\end{itemize}

\textbf{Assumption B: the scale of variability of the errors is constant at all values of the explanatory variables}

\begin{itemize}
\tightlist
\item
  practically we are looking at whether the observations are equally spread on both side of the regression line
\end{itemize}

\textbf{Assumption C: the errors are independent}

\begin{itemize}
\tightlist
\item
  broadly speaking this means that knowledge of errors attached to one observation does not give us any information about the error attached to another
\end{itemize}

\textbf{Assumptions D: the errors are normally distributed}

\begin{itemize}
\tightlist
\item
  this will allow us to describe the variation in the model's parameters estimates and therefore make inferences about the population from which our sample was taken
\end{itemize}

\textbf{Assumption E: the values of the explanatory variables are recorded without error}

\begin{itemize}
\tightlist
\item
  this one is not possible to check via examining the data, instead we have to consider the nature of the experiment
\end{itemize}

\hypertarget{checking-assumptions}{%
\section{Checking assumptions}\label{checking-assumptions}}

\textbf{Residuals}, \(\hat{\epsilon_i} = y_i - \hat{y_i}\) are the \textbf{main ingredient to check model assumptions}. We use plots such as:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Histograms or normal probability plots of \(\hat{\epsilon_i}\)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  useful to check the assumption of normality
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Plots of \(\hat{\epsilon_i}\) versus the fitted values \(\hat{y_i}\)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  used to detect changes in error variance
\item
  used to check if the mean of the errors is zero
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Plots of \(\hat{\epsilon_i}\) vs.~an explanatory variable \(x_{ij}\)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  this helps to check that the variable \(x_j\) has a linear relationship with the response variable
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Plots of \(\hat{\epsilon_i}\) vs.~an explanatory variable \(x_{kj}\) that is \textbf{not} in the model
\end{enumerate}

\begin{itemize}
\tightlist
\item
  this helps to check whether the additional variable \(x_k\) might have a relationship with the response variable
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Plots of \(\hat{\epsilon_i}\) in the order of the observations were collected
\end{enumerate}

\begin{itemize}
\tightlist
\item
  this is useful to check whether errors might be correlated over time
\end{itemize}

Let's look at the ``good'' example going back to our data of protein levels during pregnancy

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# read in data}
\NormalTok{data.protein \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/lm/protein.csv"}\NormalTok{)}

\NormalTok{protein \textless{}{-}}\StringTok{ }\NormalTok{data.protein}\OperatorTok{$}\NormalTok{Protein }\CommentTok{\# our Y}
\NormalTok{gestation \textless{}{-}}\StringTok{ }\NormalTok{data.protein}\OperatorTok{$}\NormalTok{Gestation }\CommentTok{\# our X}

\NormalTok{model \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(protein }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{gestation)}

\CommentTok{\# plot diagnostic plots of the linear model}
\CommentTok{\# by default plot(model) calls four diagnostics plots}
\CommentTok{\# par() divides plot window in 2 x 2 grid}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(model)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{303-linear-summary-assumptions_files/figure-latex/unnamed-chunk-8-1} \end{center}

\begin{itemize}
\tightlist
\item
  the residual plots provides examples of a situation where the assumptions appear to be met
\item
  the linear regression appears to describe data quite well
\item
  there is no obvious trend of any kind in the residuals vs.~fitted values (the shape is scatted)
\item
  points lie reasonably well along the line in the normal probability plot, hence normality appears to be met
\end{itemize}

\textbf{Examples of assumptions not being met}

\begin{figure}

{\centering \includegraphics{figures/linear-models/lm-assumptions-01} 

}

\caption{Example of data with a typical seasonal variation (up and down) coupled wtih a linear trend. The blue line gives the linear regression fit to the data, which clearly is not adequate. In comparison, if we used a non-parametric fit, we will get the red line as the fitted relationship. The residual plot retains pattern, given by orange line, indicating that the linear model is not appropriate in this case.}\label{fig:lm-viol-01}
\end{figure}

\begin{figure}

{\centering \includegraphics{figures/linear-models/lm-assumptions-02} 

}

\caption{Example of non-constant variance}\label{fig:lm-viol-02}
\end{figure}

\begin{figure}

{\centering \includegraphics{figures/linear-models/lm-assumptions-03} 

}

\caption{Example of residulas deviating from QQ plot, i.e. not following normal distribution. The residuals can deviate in both upper and lower tail. On the left tails are lighter meaning that they have smaller values that what would be expected, on the right there are heavier tails with values larger than expected}\label{fig:lm-viol-03}
\end{figure}

\hypertarget{influential-observations}{%
\section{Influential observations}\label{influential-observations}}

\begin{itemize}
\tightlist
\item
  Sometimes individual observations can exert a great deal of influence on the fitted model
\item
  One routine way of checking for this is to fit the model \(n\) times, missing out each observation in turn
\item
  If we removed i-th observation and compared the fitted value from the full model, say \(\hat{y_j}\) to those obtained by removing this point, denoted \(\hat{y_{j(i)}}\) then
\item
  observations with a high Cook's distance (measuring the effect of deleting a given observation) could be influential
\end{itemize}

Let's remove some observation with higher Cook's distance from protein data set, re-fit our model and compare the diagnostics plots

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# observations to be removed (based on Residuals vs. Leverage plot)}
\NormalTok{obs \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{18}\NormalTok{,}\DecValTok{7}\NormalTok{)}

\CommentTok{\# fit models removing observations}
\NormalTok{model}\FloatTok{.2}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(protein[}\OperatorTok{{-}}\NormalTok{obs] }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{gestation[}\OperatorTok{{-}}\NormalTok{obs])}

\CommentTok{\# plot diagnostics plot}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(model}\FloatTok{.2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{303-linear-summary-assumptions_files/figure-latex/unnamed-chunk-9-1.pdf}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{exercises-linear-models-iii}{%
\section{Exercises: linear models III}\label{exercises-linear-models-iii}}

Data for exercises

\begin{itemize}
\tightlist
\item
  \href{https://github.com/olgadet/bookdown-mlbiostatistics/tree/master/data/data.zip}{Link 1}
\item
  \href{https://stockholmuniversity.box.com/s/z5kwg0nlwe5la4h5t8bshpj57pylif14}{Alternative Link 2}
\end{itemize}

\begin{exercise}
\protect\hypertarget{exr:lm-brozek}{}{\label{exr:lm-brozek} }
Brozek score

Researchers collected age, weight, height and 10 body circumference measurements for 252 men in an attempt to find an alternative way of calculate body fat as oppose to measuring someone weight and volume, the latter one by submerging in a water tank. Is it possible to predict body fat using easy-to-record measurements?

Use lm() function and fit a linear method to model brozek, score estimate of percent body fat

\begin{itemize}
\tightlist
\item
  find \(R^2\) and \(R^2(adj)\)
\item
  assess the diagnostics plots to check for model assumptions
\item
  delete observation \#86 with the highest Cook's distance and re-fit the model (model.clean)
\item
  look at the model summary. Are all variables associated with brozek score?
\item
  try improving the model fit by removing variables with the highest p-value first and re-fitting the model until all the variables are significantly associated with the response (p value less than 0.1); note down the \(R^2(adj)\) values while doing so
\item
  compare the output models for model.clean and final model
\end{itemize}
\end{exercise}

To access and preview the data:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(fat, }\DataTypeTok{package =} \StringTok{"faraway"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{answers-to-selected-exercises-linear-models-iii}{%
\section*{Answers to selected exercises (linear models III)}\label{answers-to-selected-exercises-linear-models-iii}}
\addcontentsline{toc}{section}{Answers to selected exercises (linear models III)}

Exr. \ref{exr:lm-brozek}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# access and preview data}
\KeywordTok{data}\NormalTok{(fat, }\DataTypeTok{package =} \StringTok{"faraway"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(fat)}
\CommentTok{\#\#   brozek siri density age weight height adipos  free neck chest abdom   hip}
\CommentTok{\#\# 1   12.6 12.3  1.0708  23 154.25  67.75   23.7 134.9 36.2  93.1  85.2  94.5}
\CommentTok{\#\# 2    6.9  6.1  1.0853  22 173.25  72.25   23.4 161.3 38.5  93.6  83.0  98.7}
\CommentTok{\#\# 3   24.6 25.3  1.0414  22 154.00  66.25   24.7 116.0 34.0  95.8  87.9  99.2}
\CommentTok{\#\# 4   10.9 10.4  1.0751  26 184.75  72.25   24.9 164.7 37.4 101.8  86.4 101.2}
\CommentTok{\#\# 5   27.8 28.7  1.0340  24 184.25  71.25   25.6 133.1 34.4  97.3 100.0 101.9}
\CommentTok{\#\# 6   20.6 20.9  1.0502  24 210.25  74.75   26.5 167.0 39.0 104.5  94.4 107.8}
\CommentTok{\#\#   thigh knee ankle biceps forearm wrist}
\CommentTok{\#\# 1  59.0 37.3  21.9   32.0    27.4  17.1}
\CommentTok{\#\# 2  58.7 37.3  23.4   30.5    28.9  18.2}
\CommentTok{\#\# 3  59.6 38.9  24.0   28.8    25.2  16.6}
\CommentTok{\#\# 4  60.1 37.3  22.8   32.4    29.4  18.2}
\CommentTok{\#\# 5  63.2 42.2  24.0   32.2    27.7  17.7}
\CommentTok{\#\# 6  66.0 42.0  25.6   35.7    30.6  18.8}

\CommentTok{\# fit linear regression model}
\NormalTok{model.all \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(brozek }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{weight }\OperatorTok{+}\StringTok{ }\NormalTok{height }\OperatorTok{+}\StringTok{ }\NormalTok{neck }\OperatorTok{+}\StringTok{ }\NormalTok{abdom }\OperatorTok{+}\StringTok{ }\NormalTok{hip }\OperatorTok{+}\StringTok{ }\NormalTok{thigh }\OperatorTok{+}\StringTok{ }\NormalTok{knee }\OperatorTok{+}\StringTok{ }\NormalTok{ankle }\OperatorTok{+}\StringTok{ }\NormalTok{biceps }\OperatorTok{+}\StringTok{ }\NormalTok{forearm }\OperatorTok{+}\StringTok{ }\NormalTok{wrist, }\DataTypeTok{data =}\NormalTok{ fat)}

\CommentTok{\# print model summary}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model.all))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = brozek \textasciitilde{} age + weight + height + neck + abdom + }
\CommentTok{\#\#     hip + thigh + knee + ankle + biceps + forearm + wrist, data = fat)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}10.2664  {-}2.5658  {-}0.0798   2.8976   9.3204 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#               Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept) {-}17.063433  14.489336  {-}1.178  0.24011    }
\CommentTok{\#\# age           0.056520   0.029888   1.891  0.05983 .  }
\CommentTok{\#\# weight       {-}0.085513   0.045170  {-}1.893  0.05954 .  }
\CommentTok{\#\# height       {-}0.059703   0.086695  {-}0.689  0.49171    }
\CommentTok{\#\# neck         {-}0.439315   0.214802  {-}2.045  0.04193 *  }
\CommentTok{\#\# abdom         0.875779   0.070589  12.407  \textless{} 2e{-}16 ***}
\CommentTok{\#\# hip          {-}0.192118   0.132655  {-}1.448  0.14885    }
\CommentTok{\#\# thigh         0.237304   0.131793   1.801  0.07303 .  }
\CommentTok{\#\# knee         {-}0.006595   0.222832  {-}0.030  0.97642    }
\CommentTok{\#\# ankle         0.164831   0.204681   0.805  0.42144    }
\CommentTok{\#\# biceps        0.149530   0.157693   0.948  0.34397    }
\CommentTok{\#\# forearm       0.424885   0.182801   2.324  0.02095 *  }
\CommentTok{\#\# wrist        {-}1.474317   0.494475  {-}2.982  0.00316 ** }
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 3.98 on 239 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.7489,	Adjusted R{-}squared:  0.7363 }
\CommentTok{\#\# F{-}statistic:  59.4 on 12 and 239 DF,  p{-}value: \textless{} 2.2e{-}16}

\CommentTok{\# diagnostics plots}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(model.all)}

\CommentTok{\# remove potentially influential observations}
\NormalTok{obs \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{86}\NormalTok{)}
\NormalTok{fat2 \textless{}{-}}\StringTok{ }\NormalTok{fat[}\OperatorTok{{-}}\NormalTok{obs, ]}

\CommentTok{\# re{-}fit the model}
\NormalTok{model.clean \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(brozek }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{weight }\OperatorTok{+}\StringTok{ }\NormalTok{height }\OperatorTok{+}\StringTok{ }\NormalTok{neck }\OperatorTok{+}\StringTok{ }\NormalTok{abdom }\OperatorTok{+}\StringTok{ }\NormalTok{hip }\OperatorTok{+}\StringTok{ }\NormalTok{thigh }\OperatorTok{+}\StringTok{ }\NormalTok{knee }\OperatorTok{+}\StringTok{ }\NormalTok{ankle }\OperatorTok{+}\StringTok{ }\NormalTok{biceps }\OperatorTok{+}\StringTok{ }\NormalTok{forearm }\OperatorTok{+}\StringTok{ }\NormalTok{wrist, }\DataTypeTok{data =}\NormalTok{ fat)}

\CommentTok{\# diagnostics plots}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(model.clean)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{303-linear-summary-assumptions_files/figure-latex/unnamed-chunk-11-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{\# model summary}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model.clean))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = brozek \textasciitilde{} age + weight + height + neck + abdom + }
\CommentTok{\#\#     hip + thigh + knee + ankle + biceps + forearm + wrist, data = fat)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}10.2664  {-}2.5658  {-}0.0798   2.8976   9.3204 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#               Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept) {-}17.063433  14.489336  {-}1.178  0.24011    }
\CommentTok{\#\# age           0.056520   0.029888   1.891  0.05983 .  }
\CommentTok{\#\# weight       {-}0.085513   0.045170  {-}1.893  0.05954 .  }
\CommentTok{\#\# height       {-}0.059703   0.086695  {-}0.689  0.49171    }
\CommentTok{\#\# neck         {-}0.439315   0.214802  {-}2.045  0.04193 *  }
\CommentTok{\#\# abdom         0.875779   0.070589  12.407  \textless{} 2e{-}16 ***}
\CommentTok{\#\# hip          {-}0.192118   0.132655  {-}1.448  0.14885    }
\CommentTok{\#\# thigh         0.237304   0.131793   1.801  0.07303 .  }
\CommentTok{\#\# knee         {-}0.006595   0.222832  {-}0.030  0.97642    }
\CommentTok{\#\# ankle         0.164831   0.204681   0.805  0.42144    }
\CommentTok{\#\# biceps        0.149530   0.157693   0.948  0.34397    }
\CommentTok{\#\# forearm       0.424885   0.182801   2.324  0.02095 *  }
\CommentTok{\#\# wrist        {-}1.474317   0.494475  {-}2.982  0.00316 ** }
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 3.98 on 239 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.7489,	Adjusted R{-}squared:  0.7363 }
\CommentTok{\#\# F{-}statistic:  59.4 on 12 and 239 DF,  p{-}value: \textless{} 2.2e{-}16}

\CommentTok{\# re{-}fit the model (no height)}
\NormalTok{model.red1 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(brozek }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{weight }\OperatorTok{+}\StringTok{ }\NormalTok{neck }\OperatorTok{+}\StringTok{ }\NormalTok{abdom }\OperatorTok{+}\StringTok{ }\NormalTok{hip }\OperatorTok{+}\StringTok{ }\NormalTok{thigh }\OperatorTok{+}\StringTok{ }\NormalTok{knee }\OperatorTok{+}\StringTok{ }\NormalTok{ankle }\OperatorTok{+}\StringTok{ }\NormalTok{biceps }\OperatorTok{+}\StringTok{ }\NormalTok{forearm }\OperatorTok{+}\StringTok{ }\NormalTok{wrist, }\DataTypeTok{data =}\NormalTok{ fat)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model.red1))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = brozek \textasciitilde{} age + weight + neck + abdom + hip + thigh + }
\CommentTok{\#\#     knee + ankle + biceps + forearm + wrist, data = fat)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}10.2830  {-}2.6162  {-}0.1017   2.8789   9.3713 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#              Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept) {-}22.66569   11.97691  {-}1.892  0.05963 .  }
\CommentTok{\#\# age           0.05948    0.02954   2.013  0.04521 *  }
\CommentTok{\#\# weight       {-}0.09829    0.04114  {-}2.389  0.01765 *  }
\CommentTok{\#\# neck         {-}0.43444    0.21445  {-}2.026  0.04389 *  }
\CommentTok{\#\# abdom         0.88762    0.06839  12.979  \textless{} 2e{-}16 ***}
\CommentTok{\#\# hip          {-}0.17180    0.12919  {-}1.330  0.18483    }
\CommentTok{\#\# thigh         0.25327    0.12960   1.954  0.05183 .  }
\CommentTok{\#\# knee         {-}0.02318    0.22128  {-}0.105  0.91665    }
\CommentTok{\#\# ankle         0.17300    0.20411   0.848  0.39752    }
\CommentTok{\#\# biceps        0.15695    0.15715   0.999  0.31894    }
\CommentTok{\#\# forearm       0.43091    0.18239   2.363  0.01895 *  }
\CommentTok{\#\# wrist        {-}1.51011    0.49120  {-}3.074  0.00235 ** }
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 3.976 on 240 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.7484,	Adjusted R{-}squared:  0.7369 }
\CommentTok{\#\# F{-}statistic:  64.9 on 11 and 240 DF,  p{-}value: \textless{} 2.2e{-}16}

\CommentTok{\# re{-}fit the model (no knee)}
\NormalTok{model.red2 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(brozek }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{weight }\OperatorTok{+}\StringTok{ }\NormalTok{neck }\OperatorTok{+}\StringTok{ }\NormalTok{abdom }\OperatorTok{+}\StringTok{ }\NormalTok{hip }\OperatorTok{+}\StringTok{ }\NormalTok{thigh }\OperatorTok{+}\StringTok{ }\NormalTok{ankle }\OperatorTok{+}\StringTok{ }\NormalTok{biceps }\OperatorTok{+}\StringTok{ }\NormalTok{forearm }\OperatorTok{+}\StringTok{ }\NormalTok{wrist, }\DataTypeTok{data =}\NormalTok{ fat)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model.red2))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = brozek \textasciitilde{} age + weight + neck + abdom + hip + thigh + }
\CommentTok{\#\#     ankle + biceps + forearm + wrist, data = fat)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}10.2552  {-}2.5979  {-}0.1133   2.8693   9.3584 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#              Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept) {-}23.08716   11.25781  {-}2.051  0.04137 *  }
\CommentTok{\#\# age           0.05875    0.02864   2.051  0.04134 *  }
\CommentTok{\#\# weight       {-}0.09965    0.03897  {-}2.557  0.01117 *  }
\CommentTok{\#\# neck         {-}0.43088    0.21131  {-}2.039  0.04253 *  }
\CommentTok{\#\# abdom         0.88875    0.06740  13.186  \textless{} 2e{-}16 ***}
\CommentTok{\#\# hip          {-}0.17231    0.12884  {-}1.337  0.18234    }
\CommentTok{\#\# thigh         0.24942    0.12403   2.011  0.04544 *  }
\CommentTok{\#\# ankle         0.16946    0.20089   0.844  0.39974    }
\CommentTok{\#\# biceps        0.15847    0.15616   1.015  0.31123    }
\CommentTok{\#\# forearm       0.42946    0.18150   2.366  0.01876 *  }
\CommentTok{\#\# wrist        {-}1.51470    0.48823  {-}3.102  0.00215 ** }
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 3.968 on 241 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.7484,	Adjusted R{-}squared:  0.738 }
\CommentTok{\#\# F{-}statistic: 71.69 on 10 and 241 DF,  p{-}value: \textless{} 2.2e{-}16}

\CommentTok{\# re{-}fit the model (no ankle)}
\NormalTok{model.red3 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(brozek }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{weight }\OperatorTok{+}\StringTok{ }\NormalTok{neck }\OperatorTok{+}\StringTok{ }\NormalTok{abdom }\OperatorTok{+}\StringTok{ }\NormalTok{hip }\OperatorTok{+}\StringTok{ }\NormalTok{thigh  }\OperatorTok{+}\StringTok{ }\NormalTok{biceps }\OperatorTok{+}\StringTok{ }\NormalTok{forearm }\OperatorTok{+}\StringTok{ }\NormalTok{wrist, }\DataTypeTok{data =}\NormalTok{ fat)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model.red3))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = brozek \textasciitilde{} age + weight + neck + abdom + hip + thigh + }
\CommentTok{\#\#     biceps + forearm + wrist, data = fat)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}10.0740  {-}2.5615  {-}0.1021   2.7999   9.3199 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#              Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept) {-}20.61247   10.86240  {-}1.898   0.0589 .  }
\CommentTok{\#\# age           0.05727    0.02857   2.004   0.0461 *  }
\CommentTok{\#\# weight       {-}0.09141    0.03770  {-}2.424   0.0161 *  }
\CommentTok{\#\# neck         {-}0.45458    0.20931  {-}2.172   0.0308 *  }
\CommentTok{\#\# abdom         0.88098    0.06673  13.203   \textless{}2e{-}16 ***}
\CommentTok{\#\# hip          {-}0.17575    0.12870  {-}1.366   0.1733    }
\CommentTok{\#\# thigh         0.25504    0.12378   2.061   0.0404 *  }
\CommentTok{\#\# biceps        0.15178    0.15587   0.974   0.3311    }
\CommentTok{\#\# forearm       0.42805    0.18138   2.360   0.0191 *  }
\CommentTok{\#\# wrist        {-}1.40948    0.47175  {-}2.988   0.0031 ** }
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 3.965 on 242 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.7477,	Adjusted R{-}squared:  0.7383 }
\CommentTok{\#\# F{-}statistic: 79.67 on 9 and 242 DF,  p{-}value: \textless{} 2.2e{-}16}

\CommentTok{\# re{-}fit the model (no biceps)}
\NormalTok{model.red4 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(brozek }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{weight }\OperatorTok{+}\StringTok{ }\NormalTok{neck }\OperatorTok{+}\StringTok{ }\NormalTok{abdom }\OperatorTok{+}\StringTok{ }\NormalTok{hip }\OperatorTok{+}\StringTok{ }\NormalTok{thigh  }\OperatorTok{+}\StringTok{ }\NormalTok{forearm }\OperatorTok{+}\StringTok{ }\NormalTok{wrist, }\DataTypeTok{data =}\NormalTok{ fat)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model.red4))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = brozek \textasciitilde{} age + weight + neck + abdom + hip + thigh + }
\CommentTok{\#\#     forearm + wrist, data = fat)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}10.0574  {-}2.7411  {-}0.1912   2.6929   9.4977 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#              Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept) {-}20.06213   10.84654  {-}1.850  0.06558 .  }
\CommentTok{\#\# age           0.05922    0.02850   2.078  0.03876 *  }
\CommentTok{\#\# weight       {-}0.08414    0.03695  {-}2.277  0.02366 *  }
\CommentTok{\#\# neck         {-}0.43189    0.20799  {-}2.077  0.03889 *  }
\CommentTok{\#\# abdom         0.87721    0.06661  13.170  \textless{} 2e{-}16 ***}
\CommentTok{\#\# hip          {-}0.18641    0.12821  {-}1.454  0.14727    }
\CommentTok{\#\# thigh         0.28644    0.11949   2.397  0.01727 *  }
\CommentTok{\#\# forearm       0.48255    0.17251   2.797  0.00557 ** }
\CommentTok{\#\# wrist        {-}1.40487    0.47167  {-}2.978  0.00319 ** }
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 3.965 on 243 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.7467,	Adjusted R{-}squared:  0.7383 }
\CommentTok{\#\# F{-}statistic: 89.53 on 8 and 243 DF,  p{-}value: \textless{} 2.2e{-}16}

\CommentTok{\# re{-}fit the model (no hip)}
\NormalTok{model.red5 \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(brozek }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{weight }\OperatorTok{+}\StringTok{ }\NormalTok{neck }\OperatorTok{+}\StringTok{ }\NormalTok{abdom  }\OperatorTok{+}\StringTok{ }\NormalTok{thigh  }\OperatorTok{+}\StringTok{ }\NormalTok{forearm }\OperatorTok{+}\StringTok{ }\NormalTok{wrist, }\DataTypeTok{data =}\NormalTok{ fat)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model.red5))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = brozek \textasciitilde{} age + weight + neck + abdom + thigh + forearm + }
\CommentTok{\#\#     wrist, data = fat)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}10.0193  {-}2.8016  {-}0.1234   2.9387   9.0019 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#              Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept) {-}30.17420    8.34200  {-}3.617 0.000362 ***}
\CommentTok{\#\# age           0.06149    0.02852   2.156 0.032047 *  }
\CommentTok{\#\# weight       {-}0.11236    0.03151  {-}3.565 0.000437 ***}
\CommentTok{\#\# neck         {-}0.37203    0.20434  {-}1.821 0.069876 .  }
\CommentTok{\#\# abdom         0.85152    0.06437  13.229  \textless{} 2e{-}16 ***}
\CommentTok{\#\# thigh         0.20973    0.10745   1.952 0.052099 .  }
\CommentTok{\#\# forearm       0.51824    0.17115   3.028 0.002726 ** }
\CommentTok{\#\# wrist        {-}1.40081    0.47274  {-}2.963 0.003346 ** }
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 3.974 on 244 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.7445,	Adjusted R{-}squared:  0.7371 }
\CommentTok{\#\# F{-}statistic: 101.6 on 7 and 244 DF,  p{-}value: \textless{} 2.2e{-}16}

\CommentTok{\# compare model.clean and final model}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model.clean))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = brozek \textasciitilde{} age + weight + height + neck + abdom + }
\CommentTok{\#\#     hip + thigh + knee + ankle + biceps + forearm + wrist, data = fat)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}10.2664  {-}2.5658  {-}0.0798   2.8976   9.3204 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#               Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept) {-}17.063433  14.489336  {-}1.178  0.24011    }
\CommentTok{\#\# age           0.056520   0.029888   1.891  0.05983 .  }
\CommentTok{\#\# weight       {-}0.085513   0.045170  {-}1.893  0.05954 .  }
\CommentTok{\#\# height       {-}0.059703   0.086695  {-}0.689  0.49171    }
\CommentTok{\#\# neck         {-}0.439315   0.214802  {-}2.045  0.04193 *  }
\CommentTok{\#\# abdom         0.875779   0.070589  12.407  \textless{} 2e{-}16 ***}
\CommentTok{\#\# hip          {-}0.192118   0.132655  {-}1.448  0.14885    }
\CommentTok{\#\# thigh         0.237304   0.131793   1.801  0.07303 .  }
\CommentTok{\#\# knee         {-}0.006595   0.222832  {-}0.030  0.97642    }
\CommentTok{\#\# ankle         0.164831   0.204681   0.805  0.42144    }
\CommentTok{\#\# biceps        0.149530   0.157693   0.948  0.34397    }
\CommentTok{\#\# forearm       0.424885   0.182801   2.324  0.02095 *  }
\CommentTok{\#\# wrist        {-}1.474317   0.494475  {-}2.982  0.00316 ** }
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 3.98 on 239 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.7489,	Adjusted R{-}squared:  0.7363 }
\CommentTok{\#\# F{-}statistic:  59.4 on 12 and 239 DF,  p{-}value: \textless{} 2.2e{-}16}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(model.red5))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = brozek \textasciitilde{} age + weight + neck + abdom + thigh + forearm + }
\CommentTok{\#\#     wrist, data = fat)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}10.0193  {-}2.8016  {-}0.1234   2.9387   9.0019 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#              Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept) {-}30.17420    8.34200  {-}3.617 0.000362 ***}
\CommentTok{\#\# age           0.06149    0.02852   2.156 0.032047 *  }
\CommentTok{\#\# weight       {-}0.11236    0.03151  {-}3.565 0.000437 ***}
\CommentTok{\#\# neck         {-}0.37203    0.20434  {-}1.821 0.069876 .  }
\CommentTok{\#\# abdom         0.85152    0.06437  13.229  \textless{} 2e{-}16 ***}
\CommentTok{\#\# thigh         0.20973    0.10745   1.952 0.052099 .  }
\CommentTok{\#\# forearm       0.51824    0.17115   3.028 0.002726 ** }
\CommentTok{\#\# wrist        {-}1.40081    0.47274  {-}2.963 0.003346 ** }
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 3.974 on 244 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.7445,	Adjusted R{-}squared:  0.7371 }
\CommentTok{\#\# F{-}statistic: 101.6 on 7 and 244 DF,  p{-}value: \textless{} 2.2e{-}16}
\end{Highlighting}
\end{Shaded}

\emph{Note: we have just run a very simple feature selection using stepwise regression. In this method, using backward elimination, we build a model containing all the variables and remove them one by one based on defined criteria (here we have used p-values) and we stop when we have a justifiable model or when removing a predictor does not change the chosen criterion significantly.}

\hypertarget{generalized-linear-models}{%
\chapter{Generalized linear models}\label{generalized-linear-models}}

\textbf{Aims}

\begin{itemize}
\tightlist
\item
  to briefly introduce GLMs via examples of modeling binary and count response
\end{itemize}

\textbf{Learning outcomes}

\begin{itemize}
\tightlist
\item
  to understand the limits of linear regression and the application of GLMs
\item
  to be able to use glm() function to fit and interpret logistic and Poisson regression
\end{itemize}

\hypertarget{why-generalized-linear-models-glms}{%
\section{Why Generalized Linear Models (GLMs)}\label{why-generalized-linear-models-glms}}

\begin{itemize}
\tightlist
\item
  GLMs extend linear model framework to outcome variables that do not follow normal distribution
\item
  They are most frequently used to model binary, categorical or count data
\item
  In the Galapagos Island example we have tried to model Species using linear model
\item
  It kind of worked but the predicted counts were not counts (natural numbers) but rational numbers instead that make no sense when taking about count data
\item
  Similarly, fitting a regression line to binary data yields predicted values that could take any value, including \(<0\)
\item
  not to mention that it is hard to argue that the values of 0 and 1s are normally distributed
\end{itemize}

\begin{figure}

{\centering \includegraphics{304-linear-GLM_files/figure-latex/unnamed-chunk-2-1} 

}

\caption{Example of fitting linear model to binary data, to model the acceptance to medical school, coded as 1 (Yes) and 0 (No) using GPA school scores. Linear model does not fit the data well in this case}\label{fig:unnamed-chunk-2}
\end{figure}

\hypertarget{warm-up}{%
\section{Warm-up}\label{warm-up}}

\begin{itemize}
\tightlist
\item
  go to the form
  \url{https://forms.gle/wKcZns85D9AN86KD6}
\item
  there is a link to \href{https://www.theguardian.com/global/video/2018/may/16/what-do-you-hear-in-this-audio-clip-yanny-or-laurel-takes-internet-by-storm-video}{a short video}.
\item
  list to the video, what do you hear to begin with? Answer the question in the form and give us a little bit insignificant information about yourself (it is anonymous).
\end{itemize}

\hypertarget{logisitc-regression}{%
\section{Logisitc regression}\label{logisitc-regression}}

\begin{itemize}
\tightlist
\item
  Yanny or Laurel auditory illusion appeared online in May 2018. You could find lots of information about it, together with some plausible explanations why some people hear Yanny and some year Laurel
\item
  One of the explanation is that with age we lose the ability to hear certain sounds
\item
  To see if there is evidence for that, someone has already collected some data for 53 people including their age and gender
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Read in and preview data}
\NormalTok{yl \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/lm/yanny{-}laurel.csv"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(yl)}
\CommentTok{\#\#     hear age gender}
\CommentTok{\#\# 1  Yanny  40 Female}
\CommentTok{\#\# 2  Yanny  48   Male}
\CommentTok{\#\# 3  Yanny  32 Female}
\CommentTok{\#\# 4 Laurel  47 Female}
\CommentTok{\#\# 5 Laurel  60   Male}
\CommentTok{\#\# 6  Yanny  11 Female}

\CommentTok{\# Recode Laurel to 0 and Yanny as 1 in new variable (what)}
\NormalTok{yl}\OperatorTok{$}\NormalTok{word \textless{}{-}}\StringTok{ }\DecValTok{0}
\NormalTok{yl}\OperatorTok{$}\NormalTok{word[yl}\OperatorTok{$}\NormalTok{hear}\OperatorTok{==}\StringTok{"Laurel"}\NormalTok{] \textless{}{-}}\StringTok{ }\DecValTok{1}

\CommentTok{\# Make some exploratory plots}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(yl}\OperatorTok{$}\NormalTok{age, yl}\OperatorTok{$}\NormalTok{word, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{xlab=}\StringTok{"age"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{""}\NormalTok{, }\DataTypeTok{las=}\DecValTok{1}\NormalTok{)}
\KeywordTok{boxplot}\NormalTok{(yl}\OperatorTok{$}\NormalTok{age}\OperatorTok{\textasciitilde{}}\NormalTok{yl}\OperatorTok{$}\NormalTok{hear, }\DataTypeTok{xlab=}\StringTok{""}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"age"}\NormalTok{, }\DataTypeTok{col=}\StringTok{"lightblue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{304-linear-GLM_files/figure-latex/unnamed-chunk-4-1} 

}

\caption{Yanny and Laurel auditory illusion data, Yanny (1), Luarel (0)}\label{fig:unnamed-chunk-4}
\end{figure}

\begin{itemize}
\tightlist
\item
  Since the response variable takes only two values (Yanny or Laurel) we use GLM model
\item
  to fit \textbf{logistic regression} model for the \textbf{probability of hearing Yanny}
\item
  we let \(p_i=P(Y_i=1)\) denote the probability of hearing Yanny
\item
  we further assume that \(Y_i \sim Bin(1, p_i)\) distribution with
  \[log(\frac{p_i}{1-p_i})=\beta_0 + \beta_1x_i\]
  this is equivalent to:
  \[p_i = \frac{exp(\beta_0 + \beta_1x_i)}{1 + exp(\beta_0 + \beta_1x_i)}\]
\item
  \textbf{link function} \(log(\frac{p_i}{1-p_i})\) provides the link between the distribution of \(Y_i\) and the linear predictor \(\eta_i\)
\item
  \textbf{GLM model} can be written as \(g(\mu_i)=\eta_i = \mathbf{X}\boldsymbol\beta\)
\item
  we use \texttt{glm()} function in R to fit GLM models
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fit logistic regression model}
\NormalTok{logmodel}\FloatTok{.1}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{glm}\NormalTok{(word }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{age, }\DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link=}\StringTok{"logit"}\NormalTok{), }\DataTypeTok{data =}\NormalTok{ yl)}

\CommentTok{\# print model summary}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(logmodel}\FloatTok{.1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = word ~ age, family = binomial(link = "logit"), 
##     data = yl)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.86068  -0.71414  -0.04733   0.64434   2.47887  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -3.56159    0.95790  -3.718 0.000201 ***
## age          0.08943    0.02297   3.893 9.89e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 83.178  on 59  degrees of freedom
## Residual deviance: 57.967  on 58  degrees of freedom
## AIC: 61.967
## 
## Number of Fisher Scoring iterations: 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot}
\KeywordTok{ggPredict}\NormalTok{(logmodel}\FloatTok{.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{304-linear-GLM_files/figure-latex/unnamed-chunk-5-1} 

}

\caption{Fitted logistic model to the Yanny and Laurel data}\label{fig:unnamed-chunk-5}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# to get predictions use predict() functions}
\CommentTok{\# if no new observations is specified predictions are returned for the values of exploratory variables used}
\CommentTok{\# we specify response to return prediction on the probability scale}
\KeywordTok{predict}\NormalTok{(logmodel}\FloatTok{.1}\NormalTok{, }\DataTypeTok{type=}\StringTok{"response"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          1          2          3          4          5          6          7 
## 0.50394192 0.67507724 0.33187793 0.65516152 0.85868941 0.07057982 0.87903410 
##          8          9         10         11         12         13         14 
## 0.06493370 0.35199768 0.69437930 0.91222027 0.15663558 0.78037334 0.43719992 
##         15         16         17         18         19         20         21 
## 0.39379165 0.59230535 0.20986467 0.45931517 0.69437930 0.22507939 0.48159183 
##         22         23         24         25         26         27         28 
## 0.20986467 0.71302217 0.10615359 0.97322447 0.65516152 0.11494328 0.20986467 
##         29         30         31         32         33         34         35 
## 0.12435950 0.90478991 0.87903410 0.93146108 0.15663558 0.18173908 0.33187793 
##         36         37         38         39         40         41         42 
## 0.59230535 0.94673070 0.06493370 0.82290366 0.91222027 0.82290366 0.92552645 
##         43         44         45         46         47         48         49 
## 0.83556313 0.04630975 0.50394192 0.37265683 0.97751124 0.45931517 0.41533155 
##         50         51         52         53         54         55         56 
## 0.35199768 0.04630975 0.83556313 0.15663558 0.20986467 0.22507939 0.15663558 
##         57         58         59         60 
## 0.73096842 0.35199768 0.43719992 0.87903410
\end{verbatim}

\begin{itemize}
\tightlist
\item
  The regression equation for the fitted model is:
  \[log(\frac{\hat{p_i}}{1-\hat{p_i}})=-3.56  +  0.09x_i\]
\item
  we see from the output that \(\hat{\beta_0} = -3.56\) and \(\hat{\beta_1} = 0.09\)
\item
  these estimates are arrived at via maximum likelihood estimation, something that is out of scope here
\item
  but similarly to linear models, we can test the null hypothesis \(H_0:\beta_1=0\) by comparing, \(z = \frac{\hat{\beta_1}}{e.s.e(\hat{\beta_1)}} = 3.89\) with a standard normal distribution, \textbf{Wald test}, and the associated value is small meaning that there is enough evidence to reject the null, meaning that age is significantly associated with the probability with hearing Laurel and Yanny
\item
  the same conclusion can be reached if we compare the \textbf{residual deviance}
\end{itemize}

\textbf{Deviance}

\begin{itemize}
\tightlist
\item
  we use saturated and residual deviance to assess model, instead of \(R^2\) or \(R^2(adj)\)
\item
  for a GLM model that fits the data well the approximate deviance \(D\) is
  \[\chi^2(m-p)\] where \(m\) is the number of parameters in the saturated model (full model) and \(p\) is the number of parameters in the model of interest
\item
  for our above model we have \(83.178 - 57.967 = 25.21\) which is larger than 95th percentile of \(\chi^2(59-58)\)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qchisq}\NormalTok{(}\DataTypeTok{df=}\DecValTok{1}\NormalTok{, }\DataTypeTok{p=}\FloatTok{0.95}\NormalTok{)}
\CommentTok{\#\# [1] 3.841459}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  i.e.~\(25.21 >> 3.84\) and again we can conclude that age is a significant term in the model
\end{itemize}

\textbf{Odds ratios}

\begin{itemize}
\tightlist
\item
  In logistic regression we often interpret the model coefficients by taking \(e^{\hat{\beta}}\)
\item
  and we talk about \textbf{odd ratios}
\item
  e.g.~we can say, given our above model, \(e^{0.08943} = 1.093551\) that for each unit increase in age the odds of hearing Laurel get multiplied by 1.09
\end{itemize}

\textbf{Other covariates}

\begin{itemize}
\tightlist
\item
  Finally, we can use the same logic as in multiple regression to expand by models by additional variables, numerical, binary or categorical
\item
  E.g. we can test whether there is a gender effect when hearing Yanny or Laurel
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fit logistic regression including age and gender}
\NormalTok{logmodel}\FloatTok{.2}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{glm}\NormalTok{(word }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{gender, }\DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link=}\StringTok{"logit"}\NormalTok{), }\DataTypeTok{data =}\NormalTok{ yl)}

\CommentTok{\# print model summary}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(logmodel}\FloatTok{.2}\NormalTok{))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# glm(formula = word \textasciitilde{} age + gender, family = binomial(link = "logit"), }
\CommentTok{\#\#     data = yl)}
\CommentTok{\#\# }
\CommentTok{\#\# Deviance Residuals: }
\CommentTok{\#\#      Min        1Q    Median        3Q       Max  }
\CommentTok{\#\# {-}1.81723  {-}0.72585  {-}0.06218   0.67360   2.44755  }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#             Estimate Std. Error z value Pr(\textgreater{}|z|)    }
\CommentTok{\#\# (Intercept) {-}3.72679    1.07333  {-}3.472 0.000516 ***}
\CommentTok{\#\# age          0.09061    0.02337   3.877 0.000106 ***}
\CommentTok{\#\# genderMale   0.23919    0.65938   0.363 0.716789    }
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# (Dispersion parameter for binomial family taken to be 1)}
\CommentTok{\#\# }
\CommentTok{\#\#     Null deviance: 83.178  on 59  degrees of freedom}
\CommentTok{\#\# Residual deviance: 57.835  on 57  degrees of freedom}
\CommentTok{\#\# AIC: 63.835}
\CommentTok{\#\# }
\CommentTok{\#\# Number of Fisher Scoring iterations: 5}

\CommentTok{\# plot model}
\KeywordTok{ggPredict}\NormalTok{(logmodel}\FloatTok{.2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{304-linear-GLM_files/figure-latex/unnamed-chunk-7-1} 

}

\caption{Yanny Laurel data modelled with logistic regression given age and gender. Regression lines in males and femals are very alike and the model suggest no gender effect}\label{fig:unnamed-chunk-7}
\end{figure}

\hypertarget{poisson-regression}{%
\section{Poisson regression}\label{poisson-regression}}

\begin{itemize}
\tightlist
\item
  GLMs can be also applied to count data
\item
  e.g.~hospital admissions due to respiratory disease or number of bird nests in a certain habitat
\item
  here, we commonly assume that data follow the Poisson distribution \(Y_i \sim Pois(\mu_i)\)
\item
  and the corresponding model is
  \[E(Y_i)=\mu_i = \eta_ie^{\mathbf{x_i}^T\boldsymbol\beta}\] with a log link \(\ln\mu_i = \ln \eta_i + \mathbf{x_i}^T\boldsymbol\beta\)
\end{itemize}

\textbf{Data set}
Suppose we wish to model \(Y_i\) the number of cancer cases in the i-th intermediate geographical location (IG) in Glasgow. We have collected data for 271 regions, a small areas that contain between 2500 and 6000 people. Together with cancer occurrence with have data:

\begin{itemize}
\tightlist
\item
  Y\_all: number of cases of all types of cancer in te IG in 2013
\item
  E\_all: expected number of cases of all types of cancer for the IG based on the population size and demographics of the IG in 2013
\item
  pm10: air pollution
\item
  smoke: percentage of people in an area that smoke
\item
  ethic: percentage of people who are non-white
\item
  logpice: natural log of average house price
\item
  easting and northing: co-ordinates of the central point of the IG divided by 10000
\end{itemize}

We can model the \textbf{rate of occurrence of cancer} using the very same \texttt{glm} function:¨
- now we use \textbf{poisson family distribution} to model counts
- and we will include an \textbf{offset term} to model as we are modeling the rate of occurrence of the cancer that has to be adjusted by different number of people living in different regions

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Read in and preview data}
\NormalTok{cancer \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"data/lm/cancer.csv"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(cancer)}
\CommentTok{\#\#          IG Y\_all     E\_all pm10 smoke ethnic log.price  easting northing}
\CommentTok{\#\# 1 S02000260   133 106.17907 17.8  21.9   5.58  11.59910 26.16245 66.96574}
\CommentTok{\#\# 2 S02000261    38  62.43131 18.6  21.8   7.91  11.84940 26.29271 67.00278}
\CommentTok{\#\# 3 S02000262    97 120.00694 18.6  20.8   9.58  11.74106 26.21429 67.04280}
\CommentTok{\#\# 4 S02000263    80 109.10245 17.0  14.0  10.39  12.30138 25.45705 67.05938}
\CommentTok{\#\# 5 S02000264   181 149.77821 18.6  15.2   5.67  11.88449 26.12484 67.09280}
\CommentTok{\#\# 6 S02000265    77  82.31156 17.0  14.6   5.61  11.82004 25.37644 67.09826}

\CommentTok{\# fit Poisson regression}
\NormalTok{epid1 \textless{}{-}}\StringTok{ }\KeywordTok{glm}\NormalTok{(Y\_all }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{pm10 }\OperatorTok{+}\StringTok{ }\NormalTok{smoke }\OperatorTok{+}\StringTok{ }\NormalTok{ethnic }\OperatorTok{+}\StringTok{ }\NormalTok{log.price }\OperatorTok{+}\StringTok{ }\NormalTok{easting }\OperatorTok{+}\StringTok{ }\NormalTok{northing }\OperatorTok{+}\StringTok{ }\KeywordTok{offset}\NormalTok{(}\KeywordTok{log}\NormalTok{(E\_all)), }
             \DataTypeTok{family =}\NormalTok{ poisson, }
             \DataTypeTok{data =}\NormalTok{ cancer)}

\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(epid1))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# glm(formula = Y\_all \textasciitilde{} pm10 + smoke + ethnic + log.price + easting + }
\CommentTok{\#\#     northing + offset(log(E\_all)), family = poisson, data = cancer)}
\CommentTok{\#\# }
\CommentTok{\#\# Deviance Residuals: }
\CommentTok{\#\#     Min       1Q   Median       3Q      Max  }
\CommentTok{\#\# {-}4.2011  {-}0.9338  {-}0.1763   0.8959   3.8416  }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#               Estimate Std. Error z value Pr(\textgreater{}|z|)    }
\CommentTok{\#\# (Intercept) {-}0.8592657  0.8029040  {-}1.070 0.284531    }
\CommentTok{\#\# pm10         0.0500269  0.0066724   7.498 6.50e{-}14 ***}
\CommentTok{\#\# smoke        0.0033516  0.0009463   3.542 0.000397 ***}
\CommentTok{\#\# ethnic      {-}0.0049388  0.0006354  {-}7.773 7.66e{-}15 ***}
\CommentTok{\#\# log.price   {-}0.1034461  0.0169943  {-}6.087 1.15e{-}09 ***}
\CommentTok{\#\# easting     {-}0.0331305  0.0103698  {-}3.195 0.001399 ** }
\CommentTok{\#\# northing     0.0300213  0.0111013   2.704 0.006845 ** }
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# (Dispersion parameter for poisson family taken to be 1)}
\CommentTok{\#\# }
\CommentTok{\#\#     Null deviance: 972.94  on 270  degrees of freedom}
\CommentTok{\#\# Residual deviance: 565.18  on 264  degrees of freedom}
\CommentTok{\#\# AIC: 2356.2}
\CommentTok{\#\# }
\CommentTok{\#\# Number of Fisher Scoring iterations: 4}
\end{Highlighting}
\end{Shaded}

\textbf{Hypothesis testing, model fit and predictions}

\begin{itemize}
\tightlist
\item
  follows stay the same as for logistic regression
\end{itemize}

\textbf{Rate ratio}

\begin{itemize}
\tightlist
\item
  similarly to logistic regression it common to look at the \(e^\beta\)
\item
  for instance we are interested in the effect of air pollution on health, we could look at the pm10 coefficient
\item
  coefficient is positive, 0.0500269, indicating that cancer incidence rate increase with increased air poluttion
\item
  the rate ratio allows us to quantify by how much, here by a factor of \(e^{0.0500269} = 1.05\)
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{exercises-glms}{%
\section{Exercises (GLMs)}\label{exercises-glms}}

Data for exercises

\begin{itemize}
\tightlist
\item
  \href{https://github.com/olgadet/bookdown-mlbiostatistics/tree/master/data/data.zip}{Link 1}
\item
  \href{https://stockholmuniversity.box.com/s/z5kwg0nlwe5la4h5t8bshpj57pylif14}{Alternative Link 2}
\end{itemize}

\begin{exercise}
\protect\hypertarget{exr:glm-yanny}{}{\label{exr:glm-yanny} }Our own Yanny or Laurel dataset

Exploratory data analysis:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  load the data that we have collected earlier on ``yanny-laurel-us.cvs''
\item
  plot the data to explore some basic relationships between every pair of variables
\item
  are they any outing values, e.g.~someone claiming to be too young or too skinny? Remove these observations.
\end{enumerate}

Logistic regression:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  fit a logistic linear regression model to check whether age is associated with the probability of hearing Laurel? What are the odds of hearing Laurel in our group when we get one year older?
\item
  are any other variables associated with hearing different words? Height? Weight? BMI? Commuting by bike?
\item
  if someone is 40 years of old, with 162cm, 60kg and cycling to work, what is the most likely world he/she hears?
\end{enumerate}

Poisson regression:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  fit a Poisson regression to model number of Facebook friends (no need to use offset here)
\item
  can you explain the number of Facebook friends with any of the variables collected?
\item
  if someone is 40 years of old, with 162cm, 60kg and cycling to work, how many Facebook friends he/she has?
\end{enumerate}
\end{exercise}

\begin{exercise}
\protect\hypertarget{exr:glm-wcgs}{}{\label{exr:glm-wcgs} }
Additional practice

More practice with bigger more realistic data set. We have not analyzed the data ourselves yet. Let us know what you find. Anything goes.

What might affect the chance of getting a heart disease? One of the earliest studies addressing this issue started in 1960 in 3154 healthy men in the San Francisco area. At the start of the study all were free of heart disease. Eight years later the study recorded whether these men now suffered from heart disease (chd), along with many other variables that might be related. The data is available from faraway package:

\begin{itemize}
\tightlist
\item
  using logistic regression, can you discover anything interesting about the probability of developing heart disease
\item
  using Poisson regression, can you comment about number of cigarettes smoked?
\end{itemize}
\end{exercise}

\begin{Shaded}
\begin{Highlighting}[]

\KeywordTok{library}\NormalTok{(faraway)}
\KeywordTok{data}\NormalTok{(wcgs, }\DataTypeTok{package=}\StringTok{"faraway"}\NormalTok{)}

\KeywordTok{head}\NormalTok{(wcgs)}
\CommentTok{\#\#      age height weight sdp dbp chol behave cigs dibep chd  typechd timechd}
\CommentTok{\#\# 2001  49     73    150 110  76  225     A2   25     B  no     none    1664}
\CommentTok{\#\# 2002  42     70    160 154  84  177     A2   20     B  no     none    3071}
\CommentTok{\#\# 2003  42     69    160 110  78  181     B3    0     A  no     none    3071}
\CommentTok{\#\# 2004  41     68    152 124  78  132     B4   20     A  no     none    3064}
\CommentTok{\#\# 2005  59     70    150 144  86  255     B3   20     A yes infdeath    1885}
\CommentTok{\#\# 2006  44     72    204 150  90  182     B4    0     A  no     none    3102}
\CommentTok{\#\#        arcus}
\CommentTok{\#\# 2001  absent}
\CommentTok{\#\# 2002 present}
\CommentTok{\#\# 2003  absent}
\CommentTok{\#\# 2004  absent}
\CommentTok{\#\# 2005 present}
\CommentTok{\#\# 2006  absent}
\end{Highlighting}
\end{Shaded}

\hypertarget{part-misc}{%
\part{Misc}\label{part-misc}}

\hypertarget{classification-with-knn-and-decision-trees}{%
\chapter{Classification with knn and decision trees}\label{classification-with-knn-and-decision-trees}}

\textbf{Aims}

\begin{itemize}
\tightlist
\item
  to introduce classification with knn and decision trees
\end{itemize}

\textbf{Learning outcomes}

\begin{itemize}
\tightlist
\item
  to understand the concepts of splitting data into training, validation and test set
\item
  to be able to calculate overall and class specific classification rates
\item
  to use knn() function to select run the optimal value of k and build knn classifier
\item
  to use rpart() function to fit and optimize a decision tree
\item
  to use knn and a decision tree for prediction
\end{itemize}

\hypertarget{classification}{%
\section{Classification}\label{classification}}

\begin{itemize}
\tightlist
\item
  Classification methods are prediction models and algorithms use to classify or categorize objects based on their measurements
\item
  They belong under \textbf{supervised learning} as we usually start off with \textbf{labeled} data, i.e.~observations with measurements for which we know the label (class) of
\item
  If we have a pair \(\{\mathbf{x_i}, g_i\}\) for each observation \(i\), with \(g_i \in \{1, \dots, G\}\) being the class label, where \(G\) is the number of different classes and \(\mathbf{x_i}\) a set of exploratory variables, that can be continuous, categorical or a mix of both, then we want to find a \textbf{classification rule} \(f(.)\) (model) such that \[f(\mathbf{x_i})=g_i\]
\end{itemize}

\hypertarget{evaluating-classification-model-performance}{%
\section{Evaluating Classification Model Performance}\label{evaluating-classification-model-performance}}

\begin{itemize}
\tightlist
\item
  Once we have a classification model we need some way of evaluating how well it works and how it compares to other models
\item
  There are few measures being used that involve looking at the truth (labels) and comparing it to what was predicted by the model
\item
  Common measures include: correct (overall) classification rate, Missclassification rate, class specific rates, cross classification tables, sensitivity and specificity and ROC curves
\end{itemize}

\textbf{Correct (miss)classification rate}

\begin{itemize}
\tightlist
\item
  the simplest way to evaluate in which we count for all the \(n\) predictions how many times we got the classification right
  \[Correct\; Classifcation \; Rate = \frac{\sum_{i=1}^{n}1[f(x_i)=g_i]}{n}\] where
  \(1[]\) is an indicator function equal to 1 if the statement in the bracket is true and 0 otherwise
\item
  Missclassification Rate = 1 - Correct Classification Rate
\end{itemize}

\textbf{Class specific rates and cross classification table}
\[CCR \; for \; class\; j =  \frac{number \; of \; observations \; in \; class \; j \; that \; were \; correctly \; classified}{number \; of \; observations \; in \; class \; j} = \\ \sum_{i:g_i=j}{\frac{1[f(\mathbf{x_i})\neq j]}{n_j} = \frac{n_j-k_j}{n_j}}\]

\textbf{Example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example data}
\NormalTok{true.clas \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{pred.class \textless{}{-}}\StringTok{  }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{)}

\CommentTok{\# correct classification rate}
\NormalTok{n \textless{}{-}}\StringTok{ }\KeywordTok{length}\NormalTok{(true.clas)}
\NormalTok{ccr \textless{}{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{(true.clas }\OperatorTok{==}\StringTok{ }\NormalTok{pred.class)}\OperatorTok{/}\NormalTok{n}
\KeywordTok{print}\NormalTok{(ccr)}
\CommentTok{\#\# [1] 0.6}

\CommentTok{\# cross classification table}
\NormalTok{tab.pred \textless{}{-}}\StringTok{ }\KeywordTok{table}\NormalTok{(true.clas, pred.class)}
\KeywordTok{print}\NormalTok{(tab.pred)}
\CommentTok{\#\#          pred.class}
\CommentTok{\#\# true.clas 1 2}
\CommentTok{\#\#         1 4 2}
\CommentTok{\#\#         2 2 2}

\CommentTok{\# cross classification rate}
\CommentTok{\# we divide each row by its sum (using sweep function)}
\NormalTok{tab.rate \textless{}{-}}\StringTok{ }\KeywordTok{sweep}\NormalTok{(tab.pred, }\DecValTok{1}\NormalTok{, }\KeywordTok{apply}\NormalTok{(tab.pred, }\DecValTok{1}\NormalTok{, sum), }\StringTok{"/"}\NormalTok{)}
\NormalTok{tab.rate \textless{}{-}}\StringTok{ }\KeywordTok{round}\NormalTok{(tab.rate, }\DecValTok{2}\NormalTok{)}
\KeywordTok{print}\NormalTok{(tab.rate)}
\CommentTok{\#\#          pred.class}
\CommentTok{\#\# true.clas    1    2}
\CommentTok{\#\#         1 0.67 0.33}
\CommentTok{\#\#         2 0.50 0.50}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-splitting}{%
\section{Data splitting}\label{data-splitting}}

\begin{itemize}
\tightlist
\item
  part of the issue of fitting complex models to data is that the model can be continually tweaked to adapt as well as possible
\item
  but the results may not be generalizable to future data due to the added complexity modeling noise that is unique to a particular dataset (overfitting)
\item
  to deal with overconfident estimation of future performance we randomly split data into training data, validation data and test data
\item
  common split strategy are 50\%/25\%/25\% and 33\%/33\%/33\% for training/validation/test
\item
  \textbf{training data}: this is data to give fit (train) the classification model, i.e.~derive the classification rule
\item
  \textbf{validation data}: this is data used to select which parameters or types of model perform best, i.e.~to validate the performance of model parameters
\item
  \textbf{test data}: this data is used to give an estimate of future prediction performance for the model and parameters chosen
\end{itemize}

\hypertarget{cross-validation}{%
\section{Cross validation}\label{cross-validation}}

\begin{itemize}
\tightlist
\item
  the could happen that despite random splitting in train/validation/test dataset one of the subsets does not represent data (i.e.~gets all the difficult observation to classify)
\item
  or that we do not have enough data in each subset after performing the split
\item
  In \textbf{K-fold cross-validation} we split data into \(K\) roughly equal-sized parts
\item
  We start by setting the validation data to be the first set of data and the training data to be all other sets
\item
  We estimate the validation error rate / correct classification rate for the split
\item
  We then repeat the process \(K-1\) times, each time with a different part of the data set to be the validation data and the remainder being the training data
\item
  We finish with \(K\) different error of correct classification rates
\item
  In this way, every data point has its class membership predicted once
\item
  The final reporter error rate is usually the average of \(K\) error rates
\end{itemize}

Now we know how to assess our classification models. Let's try it out on two methods, k-nearest neighbors and decision tree

\hypertarget{k-nearest-neighbours}{%
\section{k-nearest neighbours}\label{k-nearest-neighbours}}

\begin{itemize}
\tightlist
\item
  k-nearest neighbours (knn) is a non-parametric classification method, i.e.~we do not have to assume a parametric model for the data of the classes
\item
  there is no need to worry about the diagnostic tests for
\end{itemize}

\textbf{Algorithm}

\begin{itemize}
\tightlist
\item
  Decide on the value of \(k\)
\item
  Calculate the distance between the query-instance (new observation) and all the training samples
\item
  Sort the distances and determine the nearest neighbours based on the k-th minimum distance
\item
  Gather the categories of the nearest neighbours
\item
  Use simple majority of the categories of nearest neighbours as the prediction value of the new observation
\end{itemize}

\emph{Euclidean distance is a classic distance used with knn; other distance measures are also used incl.~weighted Euclidean distance, Mahalanobis distance, Manhatan distance, maximum distance etc.}

\begin{figure}

{\centering \includegraphics{401-classification-knn-dtrees_files/figure-latex/unnamed-chunk-2-1} 

}

\caption{An example of k-nearest neighbours algorithm with k=3; in the top new observation (blue) is closest to three red triangales and thus classified as a red triangle; in the bottom, a new observation (blue) is closest to 2 black dots and 1 red triangle thus classified as a black dot (majority vote)}\label{fig:unnamed-chunk-2}
\end{figure}

\textbf{choosing k}

\begin{itemize}
\tightlist
\item
  for problems with 2 classes, choose an odd number of k to avoid ties
\item
  use validation data to fit the model for a series of \(k\) values
\item
  pick the value of \(k\) which results in the best model (as assessed by the method of choice, e.g.~overall classification rate)
\end{itemize}

Let's see how it works in practice on a classical iris dataset containing measurements on petals and sepals as well as species information (setosa, versicolor, virginica)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# library with knn() function}
\KeywordTok{library}\NormalTok{(class)}

\CommentTok{\# preview iris dataset}
\KeywordTok{head}\NormalTok{(iris)}
\CommentTok{\#\#   Sepal.Length Sepal.Width Petal.Length Petal.Width Species}
\CommentTok{\#\# 1          5.1         3.5          1.4         0.2  setosa}
\CommentTok{\#\# 2          4.9         3.0          1.4         0.2  setosa}
\CommentTok{\#\# 3          4.7         3.2          1.3         0.2  setosa}
\CommentTok{\#\# 4          4.6         3.1          1.5         0.2  setosa}
\CommentTok{\#\# 5          5.0         3.6          1.4         0.2  setosa}
\CommentTok{\#\# 6          5.4         3.9          1.7         0.4  setosa}

\CommentTok{\# summary statistics}
\KeywordTok{summary}\NormalTok{(iris)}
\CommentTok{\#\#   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   }
\CommentTok{\#\#  Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  }
\CommentTok{\#\#  1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  }
\CommentTok{\#\#  Median :5.800   Median :3.000   Median :4.350   Median :1.300  }
\CommentTok{\#\#  Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  }
\CommentTok{\#\#  3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  }
\CommentTok{\#\#  Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  }
\CommentTok{\#\#        Species  }
\CommentTok{\#\#  setosa    :50  }
\CommentTok{\#\#  versicolor:50  }
\CommentTok{\#\#  virginica :50  }
\CommentTok{\#\#                 }
\CommentTok{\#\#                 }
\CommentTok{\#\# }

\CommentTok{\# split data into train 50\%, validation 25\% and test dataset 25\%}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\NormalTok{n \textless{}{-}}\StringTok{ }\KeywordTok{nrow}\NormalTok{(iris) }\CommentTok{\# no. of observations}
\NormalTok{idx.train \textless{}{-}}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n), }\KeywordTok{round}\NormalTok{(n}\OperatorTok{/}\DecValTok{2}\NormalTok{))}
\NormalTok{idx.valid \textless{}{-}}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n)[}\OperatorTok{{-}}\NormalTok{idx.train], }\KeywordTok{round}\NormalTok{(n}\OperatorTok{/}\DecValTok{4}\NormalTok{))}
\NormalTok{idx.test \textless{}{-}}\StringTok{ }\KeywordTok{setdiff}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n), }\KeywordTok{c}\NormalTok{(idx.train, idx.valid))}

\NormalTok{data.train \textless{}{-}}\StringTok{ }\NormalTok{iris[idx.train,]}
\NormalTok{data.valid \textless{}{-}}\StringTok{ }\NormalTok{iris[idx.valid,]}
\NormalTok{data.test \textless{}{-}}\StringTok{ }\NormalTok{iris[idx.test,]}

\KeywordTok{dim}\NormalTok{(data.train)}
\CommentTok{\#\# [1] 75  5}
\KeywordTok{dim}\NormalTok{(data.valid)}
\CommentTok{\#\# [1] 38  5}
\KeywordTok{dim}\NormalTok{(data.test)}
\CommentTok{\#\# [1] 37  5}

\CommentTok{\# run knn with different values of k from 1 : 30}
\NormalTok{k.values \textless{}{-}}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{30}
\NormalTok{class.rate \textless{}{-}}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{length}\NormalTok{(k.values)) }\CommentTok{\# allocate empty vector to collect correct classification rates}
\ControlFlowTok{for}\NormalTok{ (k }\ControlFlowTok{in} \KeywordTok{seq\_along}\NormalTok{(k.values))}
\NormalTok{\{}
\NormalTok{  pred.class \textless{}{-}}\StringTok{ }\KeywordTok{knn}\NormalTok{(}\DataTypeTok{train =}\NormalTok{ data.train[, }\DecValTok{{-}5}\NormalTok{], }\DataTypeTok{test=}\NormalTok{data.valid[, }\DecValTok{{-}5}\NormalTok{], }\DataTypeTok{cl =}\NormalTok{ data.train[,}\DecValTok{5}\NormalTok{], k)}
\NormalTok{  class.rate[k] \textless{}{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{((pred.class}\OperatorTok{==}\NormalTok{data.valid[,}\DecValTok{5}\NormalTok{]))}\OperatorTok{/}\KeywordTok{length}\NormalTok{(pred.class)}
\NormalTok{\}}

\CommentTok{\# for which value of k we reach the highest classification rate}
\KeywordTok{which.max}\NormalTok{(class.rate)}
\CommentTok{\#\# [1] 4}

\CommentTok{\# plot classification rate as a function of k}
\KeywordTok{plot}\NormalTok{(class.rate, }\DataTypeTok{type=}\StringTok{"l"}\NormalTok{, }\DataTypeTok{xlab=}\StringTok{"k"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"class. rate"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{401-classification-knn-dtrees_files/figure-latex/unnamed-chunk-3-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# how would our model perform on the future data using the optimal k?}
\NormalTok{pred.class \textless{}{-}}\StringTok{ }\KeywordTok{knn}\NormalTok{(}\DataTypeTok{train =}\NormalTok{ data.train[, }\DecValTok{{-}5}\NormalTok{], data.test[, }\DecValTok{{-}5}\NormalTok{], data.train[,}\DecValTok{5}\NormalTok{], }\DataTypeTok{k=}\KeywordTok{which.max}\NormalTok{(class.rate))}
\NormalTok{class.rate \textless{}{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{((pred.class}\OperatorTok{==}\NormalTok{data.test[,}\DecValTok{5}\NormalTok{]))}\OperatorTok{/}\KeywordTok{length}\NormalTok{(pred.class)}
\KeywordTok{print}\NormalTok{(class.rate)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

\hypertarget{classification-trees}{%
\section{Classification trees}\label{classification-trees}}

\begin{itemize}
\tightlist
\item
  they are often used to represent knowledge and aid decision-making
\item
  they can be easily interpretable by anyone
\item
  similar to knn they are assumption free and can handle various data input
\item
  they can be presented as diagrams or pseudo-code via text
\item
  they can be used for both classification and regression
\item
  here we will focus on classification
\end{itemize}

\textbf{Terminology}

\begin{itemize}
\tightlist
\item
  \textbf{Root node}: represents the entire population of the data set
\item
  \textbf{Splitting}: the process of dividing a node into two or more nodes
\item
  \textbf{Decision / internal node}: when a new node is split into further nodes
\item
  \textbf{Leaf / terminal noel}: nodes that do not split into further nodes
\item
  \textbf{Subtree}: a subsection of a tree
\item
  \textbf{Branch}: a subtree that is only one side of a split from a node
\end{itemize}

To make predictions we simply travel down the tree starting from the top

\begin{figure}

{\centering \includegraphics{401-classification-knn-dtrees_files/figure-latex/unnamed-chunk-5-1} 

}

\caption{Example of the decision tree classifying tumour into bening and malignant type}\label{fig:unnamed-chunk-5}
\end{figure}

\textbf{Fitting trees}
1. pick the variable that gives the best split (often based on the lowest Gini index)
2. partition the data based on the value of this variable
3. repeat step 1. and step 2.
4. stop splitting when no further gain can be made or some pre-set stopping rule is met
Alternatively, the data is split as much as possible and the tree is \textbf{pruned}

\textbf{Gini index}

\begin{itemize}
\tightlist
\item
  measures impurity in node, an alternative way of assessing model's performance to classification rates that have been shown to result in local overfitting in decision trees
\item
  Gini index varies between 0 and (1-1/n) where \(n\) is the number of categories in a dependent variable
  \[Gini = \displaystyle \sum_{i=1}^{c}(p_i)^2\] where
  \(c\) is the number of categories
\end{itemize}

\begin{verbatim}
## [1] 699  11
## [1] "benign"    "malignant"
##        Id Cl.thickness Cell.size Cell.shape Marg.adhesion Epith.c.size
## 1 1000025            5         1          1             1            2
## 2 1002945            5         4          4             5            7
## 3 1015425            3         1          1             1            2
## 4 1016277            6         8          8             1            3
## 5 1017023            4         1          1             3            2
## 6 1017122            8        10         10             8            7
##   Bare.nuclei Bl.cromatin Normal.nucleoli Mitoses     Class
## 1           1           3               1       1    benign
## 2          10           3               2       1    benign
## 3           2           3               1       1    benign
## 4           4           3               7       1    benign
## 5           1           3               1       1    benign
## 6          10           9               7       1 malignant
## 
## Classification tree:
## rpart(formula = Class ~ Cl.thickness + Cell.size + Cell.shape + 
##     Marg.adhesion + Epith.c.size + Bare.nuclei + Bl.cromatin + 
##     Normal.nucleoli + Mitoses, data = BreastCancer)
## 
## Variables actually used in tree construction:
## [1] Bare.nuclei     Cell.shape      Cell.size       Normal.nucleoli
## 
## Root node error: 241/699 = 0.34478
## 
## n= 699 
## 
##         CP nsplit rel error  xerror     xstd
## 1 0.780083      0   1.00000 1.00000 0.052142
## 2 0.053942      1   0.21992 0.26141 0.031415
## 3 0.024896      2   0.16598 0.18257 0.026644
## 4 0.012448      3   0.14108 0.16598 0.025481
## 5 0.010000      6   0.10373 0.16183 0.025180
\end{verbatim}

\begin{figure}

{\centering \includegraphics{401-classification-knn-dtrees_files/figure-latex/unnamed-chunk-6-1} 

}

\caption{Example of the decision tree classifying tumour into bening and malignant type with rpart() default parameteres}\label{fig:unnamed-chunk-6}
\end{figure}

\textbf{Importance of the variable}

\begin{itemize}
\tightlist
\item
  defined as the sum of goodness of split measures for each split for which it as the primary variable
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# show variable.importance attribute}
\NormalTok{tree}\FloatTok{.1}\OperatorTok{$}\NormalTok{variable.importance}
\CommentTok{\#\#       Cell.size      Cell.shape Normal.nucleoli    Epith.c.size     Bl.cromatin }
\CommentTok{\#\#      228.196290      195.580593      167.558093      164.615713      160.203228 }
\CommentTok{\#\#     Bare.nuclei         Mitoses    Cl.thickness   Marg.adhesion }
\CommentTok{\#\#      154.590550        5.763756        4.301576        2.655170}
\end{Highlighting}
\end{Shaded}

\textbf{Complexity measure of a tree}

\begin{itemize}
\tightlist
\item
  in rpart() the complexity measure is calculated based on the size of a tree and the ability of the tree to separate the classes of the target variable
\item
  if the next best split in growing a tree does not reduce the tree's overall complexity by a certain amount, rpart() terminates the growing process
\item
  \texttt{cp} is the complexity parameter, set to negative amount results in a fully grown tree (maximum splits)
\end{itemize}

\begin{verbatim}
## 
## Classification tree:
## rpart(formula = Class ~ Cl.thickness + Cell.size + Cell.shape + 
##     Marg.adhesion + Epith.c.size + Bare.nuclei + Bl.cromatin + 
##     Normal.nucleoli + Mitoses, data = BreastCancer, cp = -1)
## 
## Variables actually used in tree construction:
## [1] Bare.nuclei     Bl.cromatin     Cell.shape      Cell.size      
## [5] Cl.thickness    Normal.nucleoli
## 
## Root node error: 241/699 = 0.34478
## 
## n= 699 
## 
##          CP nsplit rel error  xerror     xstd
## 1  0.780083      0   1.00000 1.00000 0.052142
## 2  0.053942      1   0.21992 0.24481 0.030497
## 3  0.024896      2   0.16598 0.17842 0.026359
## 4  0.012448      3   0.14108 0.16183 0.025180
## 5  0.000000      6   0.10373 0.17012 0.025778
## 6 -1.000000     15   0.10373 0.17012 0.025778
\end{verbatim}

\begin{figure}

{\centering \includegraphics{401-classification-knn-dtrees_files/figure-latex/unnamed-chunk-8-1} 

}

\caption{Example of the decision tree classifying tumour into bening and malignant type with rpart(), fully grown tree}\label{fig:unnamed-chunk-8}
\end{figure}

\textbf{Pruning a tree}

\begin{itemize}
\tightlist
\item
  fully grown trees do not usually perform well against data not in the training set (overfitting)
\item
  a solution to this is to reduce (prune) the tree
\item
  typically, this is done by choosing the complexity parameter associated with the minimum possible cross-validated error
\item
  \texttt{xerror}, in the tree view output, in our \(cp = 0.14108\) in the above case
\end{itemize}

\begin{verbatim}
## 
## Classification tree:
## rpart(formula = Class ~ Cl.thickness + Cell.size + Cell.shape + 
##     Marg.adhesion + Epith.c.size + Bare.nuclei + Bl.cromatin + 
##     Normal.nucleoli + Mitoses, data = BreastCancer, cp = -1)
## 
## Variables actually used in tree construction:
## [1] Cell.size
## 
## Root node error: 241/699 = 0.34478
## 
## n= 699 
## 
##        CP nsplit rel error  xerror     xstd
## 1 0.78008      0   1.00000 1.00000 0.052142
## 2 0.14108      1   0.21992 0.24481 0.030497
##       Cell.size      Cell.shape    Epith.c.size Normal.nucleoli     Bl.cromatin 
##        222.9401        174.2235        163.4894        153.5809        151.9295 
##     Bare.nuclei 
##        142.0211
\end{verbatim}

\begin{figure}

{\centering \includegraphics{401-classification-knn-dtrees_files/figure-latex/unnamed-chunk-9-1} 

}

\caption{Example of the decision tree classifying tumour into bening and malignant type with rpart() pruned tree to minimize cross-validation error}\label{fig:unnamed-chunk-9}
\end{figure}

\textbf{Predictions of future observations}

\begin{itemize}
\tightlist
\item
  having our best tree model we can predict the outcome of applications on a test data set and assess model performance on ``unseen'' data
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# predict cancer type given tree model}
\NormalTok{cancertype \textless{}{-}}\StringTok{ }\KeywordTok{predict}\NormalTok{(tree}\FloatTok{.2}\NormalTok{pruned, }\DataTypeTok{newdata =}\NormalTok{ data.test, }\DataTypeTok{type=}\StringTok{"class"}\NormalTok{)}

\CommentTok{\# cross classification table}
\KeywordTok{table}\NormalTok{(cancertype, data.test}\OperatorTok{$}\NormalTok{Class)}
\CommentTok{\#\#            }
\CommentTok{\#\# cancertype  benign malignant}
\CommentTok{\#\#   benign       208         6}
\CommentTok{\#\#   malignant     22       113}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{exercises-classification}{%
\section{Exercises: classification}\label{exercises-classification}}

\begin{exercise}
\protect\hypertarget{exr:knn-rpart-repeat}{}{\label{exr:knn-rpart-repeat} }knn and rpart practice

Make sure you can run and understand the above knn and rpart examples
\end{exercise}

\begin{exercise}
\protect\hypertarget{exr:knn}{}{\label{exr:knn} }Comparing knn() and rpart()

Given BreastCancer data

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  build a best knn() classification model that you can to predict the cancer in BreatCancer data set
\item
  try improving the rpart() model, look at the documentation ?rpart.control() and try to figure out and test changing other parameters, especially \texttt{minsplit} and \texttt{minbucket}
\item
  compare the performance of your best knn() models with your best rpart() model on the test data
\item
  share which method knn or rpart performs better together with the overall classification rate on Zulip (under Day-04)
\end{enumerate}
\end{exercise}

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{\# Install "mlbench" package}
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"mlbench"}\NormalTok{)}
\CommentTok{\#\# Installing package into \textquotesingle{}/Users/olga.hrydziuszko/Desktop/bookdown{-}mlbiostatistics/packrat/lib/x86\_64{-}apple{-}darwin17.0/4.0.2\textquotesingle{}}
\CommentTok{\#\# (as \textquotesingle{}lib\textquotesingle{} is unspecified)}
\CommentTok{\#\# }
\CommentTok{\#\# The downloaded binary packages are in}
\CommentTok{\#\# 	/var/folders/hw/jx67\_4vj6ljfd13xsg7xzvt83k7mrx/T//RtmpgOZg6U/downloaded\_packages}
\KeywordTok{library}\NormalTok{(mlbench)}

\CommentTok{\# Look at the Breast Cancer data}
\CommentTok{\# more about data is here: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)}
\KeywordTok{data}\NormalTok{(BreastCancer)}
\KeywordTok{dim}\NormalTok{(BreastCancer)}
\CommentTok{\#\# [1] 699  11}
\KeywordTok{levels}\NormalTok{(BreastCancer}\OperatorTok{$}\NormalTok{Class)}
\CommentTok{\#\# [1] "benign"    "malignant"}
\KeywordTok{head}\NormalTok{(BreastCancer)}
\CommentTok{\#\#        Id Cl.thickness Cell.size Cell.shape Marg.adhesion Epith.c.size}
\CommentTok{\#\# 1 1000025            5         1          1             1            2}
\CommentTok{\#\# 2 1002945            5         4          4             5            7}
\CommentTok{\#\# 3 1015425            3         1          1             1            2}
\CommentTok{\#\# 4 1016277            6         8          8             1            3}
\CommentTok{\#\# 5 1017023            4         1          1             3            2}
\CommentTok{\#\# 6 1017122            8        10         10             8            7}
\CommentTok{\#\#   Bare.nuclei Bl.cromatin Normal.nucleoli Mitoses     Class}
\CommentTok{\#\# 1           1           3               1       1    benign}
\CommentTok{\#\# 2          10           3               2       1    benign}
\CommentTok{\#\# 3           2           3               1       1    benign}
\CommentTok{\#\# 4           4           3               7       1    benign}
\CommentTok{\#\# 5           1           3               1       1    benign}
\CommentTok{\#\# 6          10           9               7       1 malignant}
\end{Highlighting}
\end{Shaded}

\hypertarget{ann-regression-and-classification}{%
\chapter{ANN regression and classification}\label{ann-regression-and-classification}}

\textbf{Aims}

\begin{itemize}
\tightlist
\item
  to introduce regression and classification with ANN via examples
\end{itemize}

\textbf{Learning outcomes}

\begin{itemize}
\tightlist
\item
  to be able to use neuralnet() package for classification and regression
\end{itemize}

\hypertarget{exercise-1.1}{%
\section{Exercise 1.1}\label{exercise-1.1}}

\hypertarget{set-up}{%
\subsection{Set-up}\label{set-up}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Clean all variables and load libraries}
\KeywordTok{rm}\NormalTok{(}\DataTypeTok{list=}\KeywordTok{ls}\NormalTok{())}
\KeywordTok{library}\NormalTok{(mlbench) }\CommentTok{\# CancerBreast dataset}
\KeywordTok{library}\NormalTok{(class) }\CommentTok{\# knn}
\KeywordTok{library}\NormalTok{(rpart) }\CommentTok{\# decision tree}
\KeywordTok{library}\NormalTok{(rpart.plot) }\CommentTok{\# decision tree plots}
\KeywordTok{library}\NormalTok{(neuralnet) }\CommentTok{\# ann}
\KeywordTok{library}\NormalTok{(NeuralNetTools) }\CommentTok{\# ann tools}
\KeywordTok{library}\NormalTok{(ggplot2) }\CommentTok{\# plotting}
\KeywordTok{library}\NormalTok{(ggiraphExtra)}
\end{Highlighting}
\end{Shaded}

\hypertarget{load-and-process-the-data}{%
\subsection{Load and process the data}\label{load-and-process-the-data}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Data input }
\KeywordTok{data}\NormalTok{(}\StringTok{"BreastCancer"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(BreastCancer) }\CommentTok{\# preview data}
\CommentTok{\#\#        Id Cl.thickness Cell.size Cell.shape Marg.adhesion Epith.c.size}
\CommentTok{\#\# 1 1000025            5         1          1             1            2}
\CommentTok{\#\# 2 1002945            5         4          4             5            7}
\CommentTok{\#\# 3 1015425            3         1          1             1            2}
\CommentTok{\#\# 4 1016277            6         8          8             1            3}
\CommentTok{\#\# 5 1017023            4         1          1             3            2}
\CommentTok{\#\# 6 1017122            8        10         10             8            7}
\CommentTok{\#\#   Bare.nuclei Bl.cromatin Normal.nucleoli Mitoses     Class}
\CommentTok{\#\# 1           1           3               1       1    benign}
\CommentTok{\#\# 2          10           3               2       1    benign}
\CommentTok{\#\# 3           2           3               1       1    benign}
\CommentTok{\#\# 4           4           3               7       1    benign}
\CommentTok{\#\# 5           1           3               1       1    benign}
\CommentTok{\#\# 6          10           9               7       1 malignant}
\KeywordTok{str}\NormalTok{(BreastCancer) }\CommentTok{\# show data types}
\CommentTok{\#\# \textquotesingle{}data.frame\textquotesingle{}:	699 obs. of  11 variables:}
\CommentTok{\#\#  $ Id             : chr  "1000025" "1002945" "1015425" "1016277" ...}
\CommentTok{\#\#  $ Cl.thickness   : Ord.factor w/ 10 levels "1"\textless{}"2"\textless{}"3"\textless{}"4"\textless{}..: 5 5 3 6 4 8 1 2 2 4 ...}
\CommentTok{\#\#  $ Cell.size      : Ord.factor w/ 10 levels "1"\textless{}"2"\textless{}"3"\textless{}"4"\textless{}..: 1 4 1 8 1 10 1 1 1 2 ...}
\CommentTok{\#\#  $ Cell.shape     : Ord.factor w/ 10 levels "1"\textless{}"2"\textless{}"3"\textless{}"4"\textless{}..: 1 4 1 8 1 10 1 2 1 1 ...}
\CommentTok{\#\#  $ Marg.adhesion  : Ord.factor w/ 10 levels "1"\textless{}"2"\textless{}"3"\textless{}"4"\textless{}..: 1 5 1 1 3 8 1 1 1 1 ...}
\CommentTok{\#\#  $ Epith.c.size   : Ord.factor w/ 10 levels "1"\textless{}"2"\textless{}"3"\textless{}"4"\textless{}..: 2 7 2 3 2 7 2 2 2 2 ...}
\CommentTok{\#\#  $ Bare.nuclei    : Factor w/ 10 levels "1","2","3","4",..: 1 10 2 4 1 10 10 1 1 1 ...}
\CommentTok{\#\#  $ Bl.cromatin    : Factor w/ 10 levels "1","2","3","4",..: 3 3 3 3 3 9 3 3 1 2 ...}
\CommentTok{\#\#  $ Normal.nucleoli: Factor w/ 10 levels "1","2","3","4",..: 1 2 1 7 1 7 1 1 1 1 ...}
\CommentTok{\#\#  $ Mitoses        : Factor w/ 9 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 5 1 ...}
\CommentTok{\#\#  $ Class          : Factor w/ 2 levels "benign","malignant": 1 1 1 1 1 2 1 1 1 1 ...}

\CommentTok{\# data summary}
\KeywordTok{summary}\NormalTok{(BreastCancer)}
\CommentTok{\#\#       Id             Cl.thickness   Cell.size     Cell.shape  Marg.adhesion}
\CommentTok{\#\#  Length:699         1      :145   1      :384   1      :353   1      :407  }
\CommentTok{\#\#  Class :character   5      :130   10     : 67   2      : 59   2      : 58  }
\CommentTok{\#\#  Mode  :character   3      :108   3      : 52   10     : 58   3      : 58  }
\CommentTok{\#\#                     4      : 80   2      : 45   3      : 56   10     : 55  }
\CommentTok{\#\#                     10     : 69   4      : 40   4      : 44   4      : 33  }
\CommentTok{\#\#                     2      : 50   5      : 30   5      : 34   8      : 25  }
\CommentTok{\#\#                     (Other):117   (Other): 81   (Other): 95   (Other): 63  }
\CommentTok{\#\#   Epith.c.size  Bare.nuclei   Bl.cromatin  Normal.nucleoli    Mitoses   }
\CommentTok{\#\#  2      :386   1      :402   2      :166   1      :443     1      :579  }
\CommentTok{\#\#  3      : 72   10     :132   3      :165   10     : 61     2      : 35  }
\CommentTok{\#\#  4      : 48   2      : 30   1      :152   3      : 44     3      : 33  }
\CommentTok{\#\#  1      : 47   5      : 30   7      : 73   2      : 36     10     : 14  }
\CommentTok{\#\#  6      : 41   3      : 28   4      : 40   8      : 24     4      : 12  }
\CommentTok{\#\#  5      : 39   (Other): 61   5      : 34   6      : 22     7      :  9  }
\CommentTok{\#\#  (Other): 66   NA\textquotesingle{}s   : 16   (Other): 69   (Other): 69     (Other): 17  }
\CommentTok{\#\#        Class    }
\CommentTok{\#\#  benign   :458  }
\CommentTok{\#\#  malignant:241  }
\CommentTok{\#\#                 }
\CommentTok{\#\#                 }
\CommentTok{\#\#                 }
\CommentTok{\#\#                 }
\CommentTok{\#\# }

\CommentTok{\# convert variables to numerical values}
\NormalTok{data.breast \textless{}{-}}\StringTok{ }\NormalTok{BreastCancer}
\NormalTok{data.breast \textless{}{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{Class =}\NormalTok{ BreastCancer}\OperatorTok{$}\NormalTok{Class,}
                          \DataTypeTok{Cell.size =} \KeywordTok{as.numeric}\NormalTok{(BreastCancer}\OperatorTok{$}\NormalTok{Cell.size),}
                          \DataTypeTok{Cell.shape =} \KeywordTok{as.numeric}\NormalTok{(BreastCancer}\OperatorTok{$}\NormalTok{Cell.shape), }
                          \DataTypeTok{Cl.thickness =} \KeywordTok{as.numeric}\NormalTok{(BreastCancer}\OperatorTok{$}\NormalTok{Cl.thickness),}
                          \DataTypeTok{Marg.adhesion =} \KeywordTok{as.numeric}\NormalTok{(BreastCancer}\OperatorTok{$}\NormalTok{Marg.adhesion),}
                          \DataTypeTok{Epith.c.size =} \KeywordTok{as.numeric}\NormalTok{(BreastCancer}\OperatorTok{$}\NormalTok{Epith.c.size), }
                          \DataTypeTok{Bare.nuclei =} \KeywordTok{as.numeric}\NormalTok{(BreastCancer}\OperatorTok{$}\NormalTok{Bare.nuclei),}
                          \DataTypeTok{Bl.cromatin =} \KeywordTok{as.numeric}\NormalTok{(BreastCancer}\OperatorTok{$}\NormalTok{Bare.nuclei),}
                          \DataTypeTok{Normal.nucleoli =} \KeywordTok{as.numeric}\NormalTok{(BreastCancer}\OperatorTok{$}\NormalTok{Normal.nucleoli), }
                          \DataTypeTok{Mitoses =} \KeywordTok{as.numeric}\NormalTok{(BreastCancer}\OperatorTok{$}\NormalTok{Mitoses)}
\NormalTok{                          )}

\KeywordTok{str}\NormalTok{(data.breast)}
\CommentTok{\#\# \textquotesingle{}data.frame\textquotesingle{}:	699 obs. of  10 variables:}
\CommentTok{\#\#  $ Class          : Factor w/ 2 levels "benign","malignant": 1 1 1 1 1 2 1 1 1 1 ...}
\CommentTok{\#\#  $ Cell.size      : num  1 4 1 8 1 10 1 1 1 2 ...}
\CommentTok{\#\#  $ Cell.shape     : num  1 4 1 8 1 10 1 2 1 1 ...}
\CommentTok{\#\#  $ Cl.thickness   : num  5 5 3 6 4 8 1 2 2 4 ...}
\CommentTok{\#\#  $ Marg.adhesion  : num  1 5 1 1 3 8 1 1 1 1 ...}
\CommentTok{\#\#  $ Epith.c.size   : num  2 7 2 3 2 7 2 2 2 2 ...}
\CommentTok{\#\#  $ Bare.nuclei    : num  1 10 2 4 1 10 10 1 1 1 ...}
\CommentTok{\#\#  $ Bl.cromatin    : num  1 10 2 4 1 10 10 1 1 1 ...}
\CommentTok{\#\#  $ Normal.nucleoli: num  1 2 1 7 1 7 1 1 1 1 ...}
\CommentTok{\#\#  $ Mitoses        : num  1 1 1 1 1 1 1 1 5 1 ...}

\CommentTok{\# Remove missing data}
\NormalTok{data.breast \textless{}{-}}\StringTok{ }\KeywordTok{na.omit}\NormalTok{(data.breast)}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-split}{%
\subsection{Data split}\label{data-split}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Split into train, validation, test}
\CommentTok{\# split data into train 50\%, validation 25\% and test dataset 25\%}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{n \textless{}{-}}\StringTok{ }\KeywordTok{nrow}\NormalTok{(data.breast) }\CommentTok{\# no. of observations}
\NormalTok{idx.train \textless{}{-}}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n), }\KeywordTok{round}\NormalTok{(n}\OperatorTok{/}\DecValTok{2}\NormalTok{))}
\NormalTok{idx.valid \textless{}{-}}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n)[}\OperatorTok{{-}}\NormalTok{idx.train], }\KeywordTok{round}\NormalTok{(n}\OperatorTok{/}\DecValTok{4}\NormalTok{))}
\NormalTok{idx.test \textless{}{-}}\StringTok{ }\KeywordTok{setdiff}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n), }\KeywordTok{c}\NormalTok{(idx.train, idx.valid))}

\NormalTok{data.train \textless{}{-}}\StringTok{ }\NormalTok{data.breast[idx.train,]}
\NormalTok{data.valid \textless{}{-}}\StringTok{ }\NormalTok{data.breast[idx.valid,]}
\NormalTok{data.test \textless{}{-}}\StringTok{ }\NormalTok{data.breast[idx.test,]}

\KeywordTok{dim}\NormalTok{(data.train)}
\CommentTok{\#\# [1] 342  10}
\KeywordTok{dim}\NormalTok{(data.valid)}
\CommentTok{\#\# [1] 171  10}
\KeywordTok{dim}\NormalTok{(data.test)}
\CommentTok{\#\# [1] 170  10}
\end{Highlighting}
\end{Shaded}

\hypertarget{default-knn-decision-tree-and-logistic-regression-classification}{%
\subsection{Default knn, decision tree and logistic regression classification}\label{default-knn-decision-tree-and-logistic-regression-classification}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# KNN (k=3)}
\NormalTok{knn.pred \textless{}{-}}\StringTok{ }\KeywordTok{knn}\NormalTok{(}\DataTypeTok{train =}\NormalTok{ data.train[, }\DecValTok{{-}1}\NormalTok{], data.test[, }\DecValTok{{-}1}\NormalTok{], data.train[,}\DecValTok{1}\NormalTok{], }\DataTypeTok{k=}\DecValTok{3}\NormalTok{)}
\NormalTok{knn.cr \textless{}{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{((knn.pred}\OperatorTok{==}\NormalTok{data.test[,}\DecValTok{1}\NormalTok{]))}\OperatorTok{/}\KeywordTok{length}\NormalTok{(knn.pred) }\CommentTok{\# classification rate}
\KeywordTok{print}\NormalTok{(knn.cr)}
\CommentTok{\#\# [1] 0.9588235}

\CommentTok{\# Decision tree}
\NormalTok{cart}\FloatTok{.1}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{rpart}\NormalTok{(data.train}\OperatorTok{$}\NormalTok{Class }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Cl.thickness }\OperatorTok{+}\StringTok{ }\NormalTok{Cell.size }\OperatorTok{+}\StringTok{  }\NormalTok{Cell.shape }\OperatorTok{+}\StringTok{ }\NormalTok{Marg.adhesion }\OperatorTok{+}\StringTok{ }\NormalTok{Epith.c.size }\OperatorTok{+}\StringTok{ }\NormalTok{Bare.nuclei }\OperatorTok{+}\StringTok{ }\NormalTok{Bl.cromatin }\OperatorTok{+}\StringTok{ }\NormalTok{Normal.nucleoli }\OperatorTok{+}\StringTok{ }\NormalTok{Mitoses, }\DataTypeTok{data=}\NormalTok{data.train)}
\KeywordTok{rpart.plot}\NormalTok{(cart}\FloatTok{.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{402-ann-intro_files/figure-latex/unnamed-chunk-2-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cart.pred \textless{}{-}}\StringTok{ }\KeywordTok{predict}\NormalTok{(cart}\FloatTok{.1}\NormalTok{, }\DataTypeTok{newdata =}\NormalTok{ data.test, }\DataTypeTok{type=}\StringTok{"class"}\NormalTok{)}
\NormalTok{cart.cr \textless{}{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{((cart.pred}\OperatorTok{==}\NormalTok{data.test[,}\DecValTok{1}\NormalTok{]))}\OperatorTok{/}\KeywordTok{length}\NormalTok{(cart.pred)}
\KeywordTok{print}\NormalTok{(cart.cr)}
\CommentTok{\#\# [1] 0.9352941}

\CommentTok{\# Logisitc regression}
\NormalTok{logreg \textless{}{-}}\StringTok{ }\KeywordTok{glm}\NormalTok{(data.train}\OperatorTok{$}\NormalTok{Class }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Cl.thickness }\OperatorTok{+}\StringTok{ }\NormalTok{Cell.size }\OperatorTok{+}\StringTok{  }\NormalTok{Cell.shape }\OperatorTok{+}\StringTok{ }\NormalTok{Marg.adhesion }\OperatorTok{+}\StringTok{ }\NormalTok{Epith.c.size }\OperatorTok{+}\StringTok{ }\NormalTok{Bare.nuclei }\OperatorTok{+}\StringTok{ }\NormalTok{Bl.cromatin }\OperatorTok{+}\StringTok{ }\NormalTok{Normal.nucleoli }\OperatorTok{+}\StringTok{ }\NormalTok{Mitoses, }\DataTypeTok{data=}\NormalTok{data.train, }\DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link=}\StringTok{"logit"}\NormalTok{))}
\CommentTok{\#\# Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred}
\KeywordTok{print}\NormalTok{(}\KeywordTok{summary}\NormalTok{(logreg))}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# glm(formula = data.train$Class \textasciitilde{} Cl.thickness + Cell.size + Cell.shape + }
\CommentTok{\#\#     Marg.adhesion + Epith.c.size + Bare.nuclei + Bl.cromatin + }
\CommentTok{\#\#     Normal.nucleoli + Mitoses, family = binomial(link = "logit"), }
\CommentTok{\#\#     data = data.train)}
\CommentTok{\#\# }
\CommentTok{\#\# Deviance Residuals: }
\CommentTok{\#\#      Min        1Q    Median        3Q       Max  }
\CommentTok{\#\# {-}2.78015  {-}0.09873  {-}0.04989   0.00842   2.29108  }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients: (1 not defined because of singularities)}
\CommentTok{\#\#                 Estimate Std. Error z value Pr(\textgreater{}|z|)    }
\CommentTok{\#\# (Intercept)     {-}10.8815     2.1472  {-}5.068 4.02e{-}07 ***}
\CommentTok{\#\# Cl.thickness      0.4050     0.2242   1.807 0.070827 .  }
\CommentTok{\#\# Cell.size         0.1039     0.2724   0.381 0.702933    }
\CommentTok{\#\# Cell.shape        0.6366     0.3678   1.731 0.083481 .  }
\CommentTok{\#\# Marg.adhesion     0.3343     0.1951   1.714 0.086534 .  }
\CommentTok{\#\# Epith.c.size     {-}0.4608     0.2947  {-}1.564 0.117860    }
\CommentTok{\#\# Bare.nuclei       0.5100     0.1525   3.343 0.000828 ***}
\CommentTok{\#\# Bl.cromatin           NA         NA      NA       NA    }
\CommentTok{\#\# Normal.nucleoli   0.5765     0.1944   2.966 0.003015 ** }
\CommentTok{\#\# Mitoses           2.3031     1.2862   1.791 0.073361 .  }
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# (Dispersion parameter for binomial family taken to be 1)}
\CommentTok{\#\# }
\CommentTok{\#\#     Null deviance: 457.974  on 341  degrees of freedom}
\CommentTok{\#\# Residual deviance:  40.942  on 333  degrees of freedom}
\CommentTok{\#\# AIC: 58.942}
\CommentTok{\#\# }
\CommentTok{\#\# Number of Fisher Scoring iterations: 9}
\NormalTok{logreg.prob \textless{}{-}}\StringTok{ }\KeywordTok{predict}\NormalTok{(logreg, }\DataTypeTok{newdata=}\NormalTok{data.test, }\DataTypeTok{type=}\StringTok{"response"}\NormalTok{)}
\CommentTok{\#\# Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :}
\CommentTok{\#\# prediction from a rank{-}deficient fit may be misleading}

\NormalTok{logreg.pred \textless{}{-}}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\StringTok{"malignant"}\NormalTok{, }\KeywordTok{nrow}\NormalTok{(data.test))}
\NormalTok{logreg.pred[logreg.prob }\OperatorTok{\textless{}=}\StringTok{ }\FloatTok{0.5}\NormalTok{] \textless{}{-}}\StringTok{ "benign"}
\NormalTok{logreg.cr \textless{}{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{((logreg.pred}\OperatorTok{==}\NormalTok{data.test[,}\DecValTok{1}\NormalTok{]))}\OperatorTok{/}\KeywordTok{length}\NormalTok{(logreg.pred)}
\KeywordTok{print}\NormalTok{(logreg.cr)}
\CommentTok{\#\# [1] 0.9411765}

\KeywordTok{print}\NormalTok{(}\KeywordTok{c}\NormalTok{(knn.cr, cart.cr, logreg.cr))}
\CommentTok{\#\# [1] 0.9588235 0.9352941 0.9411765}
\end{Highlighting}
\end{Shaded}

\hypertarget{ann-classification-fitting-model}{%
\subsection{ANN classification: fitting model}\label{ann-classification-fitting-model}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fit ANN classification model (default parameters and logistic activation function)}
\CommentTok{\# notice linear.output set to FALSE}
\NormalTok{ann.c1 \textless{}{-}}\StringTok{ }\KeywordTok{neuralnet}\NormalTok{(Class }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Cl.thickness }\OperatorTok{+}\StringTok{ }\NormalTok{Cell.size }\OperatorTok{+}\StringTok{  }\NormalTok{Cell.shape }\OperatorTok{+}\StringTok{ }
\StringTok{                        }\NormalTok{Marg.adhesion }\OperatorTok{+}\StringTok{ }\NormalTok{Epith.c.size }\OperatorTok{+}\StringTok{ }\NormalTok{Bare.nuclei }\OperatorTok{+}\StringTok{ }
\StringTok{                        }\NormalTok{Bl.cromatin }\OperatorTok{+}\StringTok{ }\NormalTok{Normal.nucleoli }\OperatorTok{+}\StringTok{ }\NormalTok{Mitoses, }
                        \DataTypeTok{data=}\NormalTok{data.train, }
                        \DataTypeTok{linear.output =} \OtherTok{FALSE}\NormalTok{, }
                        \DataTypeTok{act.fct =} \StringTok{"logistic"}\NormalTok{)}

\KeywordTok{plotnet}\NormalTok{(ann.c1, }\DataTypeTok{cex\_val =} \FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{402-ann-intro_files/figure-latex/ann-classification-fit-1} 

}

\caption{ANN model representation. The black lines show the connections between each layer and the weights on each connection; B nodes represent bias terms added in each step (bias nodes), and the hidden nodes are the ones between the input and output, here only one node}\label{fig:ann-classification-fit}
\end{figure}

\hypertarget{ann-classification-comparing-to-logistic-regression}{%
\subsection{ANN classification: comparing to logistic regression}\label{ann-classification-comparing-to-logistic-regression}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# we run prediction using compute function()}
\NormalTok{ann.c1\_predictions \textless{}{-}}\StringTok{ }\NormalTok{neuralnet}\OperatorTok{::}\KeywordTok{compute}\NormalTok{(ann.c1, }
\NormalTok{                                  data.test)}
\NormalTok{ann.c1\_predictions \textless{}{-}}\StringTok{ }\NormalTok{ann.c1\_predictions}\OperatorTok{$}\NormalTok{net.result}

\CommentTok{\# The prediction result shows the probability of each class}
\CommentTok{\# with first column corresponding to benign and second to malignant}
\CommentTok{\# we know as by typing str(data.breast) we can see that our Class is ordered benign and malignant}
\KeywordTok{head}\NormalTok{(ann.c1\_predictions)}
\CommentTok{\#\#           [,1]         [,2]}
\CommentTok{\#\# 13 0.003303861 9.965274e{-}01}
\CommentTok{\#\# 17 1.000000000 1.278634e{-}10}
\CommentTok{\#\# 20 1.000000000 3.511953e{-}10}
\CommentTok{\#\# 23 1.000000000 9.554493e{-}11}
\CommentTok{\#\# 27 0.999999999 4.639298e{-}10}
\CommentTok{\#\# 31 1.000000000 2.895116e{-}10}

\CommentTok{\# So we need the extract the class with the highest prediction values as the predicted result}
\CommentTok{\# e.g by using ifelse}
\NormalTok{ann.c1\_pred \textless{}{-}}\StringTok{ }\KeywordTok{max.col}\NormalTok{(ann.c1\_predictions) }\CommentTok{\# find out which column has the maximum value}
\NormalTok{ann.c1\_pred \textless{}{-}}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(ann.c1\_pred}\OperatorTok{==}\DecValTok{1}\NormalTok{, }\StringTok{"benign"}\NormalTok{, }\StringTok{"malignant"}\NormalTok{) }\CommentTok{\# if the first column was max, set it to beign, malignant otherwise}
\NormalTok{ann1.cr \textless{}{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{((ann.c1\_pred}\OperatorTok{==}\NormalTok{data.test[,}\DecValTok{1}\NormalTok{]))}\OperatorTok{/}\KeywordTok{length}\NormalTok{(ann.c1\_pred)}
\KeywordTok{print}\NormalTok{(ann1.cr)}
\CommentTok{\#\# [1] 0.9470588}

\CommentTok{\# Compare with our previous models}
\KeywordTok{print}\NormalTok{(}\KeywordTok{c}\NormalTok{(knn.cr, cart.cr, logreg.cr, ann1.cr))}
\CommentTok{\#\# [1] 0.9588235 0.9352941 0.9411765 0.9470588}

\CommentTok{\# Note: we see we are not doing quite similar to logistic regression}
\CommentTok{\# It is not surprising as we only have one hidden layer with only one node with logistic activation function}
\CommentTok{\# and the linear regression can be viewed as a simple special case of neural network with no hidden layer}
\end{Highlighting}
\end{Shaded}

\hypertarget{ann-classification-adding-hidden-layers}{%
\subsection{ANN classification: adding hidden layers}\label{ann-classification-adding-hidden-layers}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Lets add some more 2 more hidden layers, with 2 and 5 nodes, via hidden parameter}
\CommentTok{\# and see if our predictions improve}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{ann.c2 \textless{}{-}}\StringTok{ }\KeywordTok{neuralnet}\NormalTok{(Class }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Cl.thickness }\OperatorTok{+}\StringTok{ }\NormalTok{Cell.size }\OperatorTok{+}\StringTok{  }\NormalTok{Cell.shape }\OperatorTok{+}\StringTok{ }
\StringTok{                        }\NormalTok{Marg.adhesion }\OperatorTok{+}\StringTok{ }\NormalTok{Epith.c.size }\OperatorTok{+}\StringTok{ }\NormalTok{Bare.nuclei }\OperatorTok{+}\StringTok{ }
\StringTok{                        }\NormalTok{Bl.cromatin }\OperatorTok{+}\StringTok{ }\NormalTok{Normal.nucleoli }\OperatorTok{+}\StringTok{ }\NormalTok{Mitoses, }
                        \DataTypeTok{data=}\NormalTok{data.train, }
                        \DataTypeTok{hidden =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{),}
                        \DataTypeTok{linear.output =} \OtherTok{FALSE}\NormalTok{, }
                        \DataTypeTok{act.fct =} \StringTok{"logistic"}\NormalTok{)}

\KeywordTok{plotnet}\NormalTok{(ann.c2, }\DataTypeTok{cex\_val =} \FloatTok{0.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{402-ann-intro_files/figure-latex/unnamed-chunk-3-1} 

}

\caption{ANN model representation for classification, two hidden layers, with two and five nodes respectively}\label{fig:unnamed-chunk-3}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]


\NormalTok{ann.c2\_predictions \textless{}{-}}\StringTok{ }\NormalTok{neuralnet}\OperatorTok{::}\KeywordTok{compute}\NormalTok{(ann.c2, data.test)}\OperatorTok{$}\NormalTok{net.result}
\NormalTok{ann.c2\_pred \textless{}{-}}\StringTok{ }\KeywordTok{max.col}\NormalTok{(ann.c2\_predictions) }\CommentTok{\# find out which column has the maximum value}
\NormalTok{ann.c2\_pred \textless{}{-}}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(ann.c2\_pred}\OperatorTok{==}\DecValTok{1}\NormalTok{, }\StringTok{"benign"}\NormalTok{, }\StringTok{"malignant"}\NormalTok{) }\CommentTok{\# if the first column was max, set it to beign, malignant otherwise}
\NormalTok{ann2.cr \textless{}{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{((ann.c2\_pred}\OperatorTok{==}\NormalTok{data.test[,}\DecValTok{1}\NormalTok{]))}\OperatorTok{/}\KeywordTok{length}\NormalTok{(ann.c2\_pred)}

\CommentTok{\# Compare with our previous models}
\KeywordTok{print}\NormalTok{(}\KeywordTok{c}\NormalTok{(knn.cr, cart.cr, logreg.cr, ann1.cr, ann2.cr))}
\CommentTok{\#\# [1] 0.9588235 0.9352941 0.9411765 0.9470588 0.9529412}

\CommentTok{\# Feel free to experiment with more layers and more nodes}
\end{Highlighting}
\end{Shaded}

\hypertarget{ann-classification-changing-activation-function}{%
\subsection{ANN classification: changing activation function}\label{ann-classification-changing-activation-function}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# We can change activation function via act.fct parameter and include custom functions}
\CommentTok{\# e.g. softplus \textless{}{-} function(x) log(1 + exp(x)) }
\CommentTok{\# or relu \textless{}{-} function(x) sapply(x, function(z) max(0,z))}
\CommentTok{\# here we switch to "tanh" from a default "logistic"}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{101}\NormalTok{)}
\NormalTok{ann.c3 \textless{}{-}}\StringTok{ }\KeywordTok{neuralnet}\NormalTok{(Class }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{Cl.thickness }\OperatorTok{+}\StringTok{ }\NormalTok{Cell.size }\OperatorTok{+}\StringTok{  }\NormalTok{Cell.shape }\OperatorTok{+}\StringTok{ }
\StringTok{                        }\NormalTok{Marg.adhesion }\OperatorTok{+}\StringTok{ }\NormalTok{Epith.c.size }\OperatorTok{+}\StringTok{ }\NormalTok{Bare.nuclei }\OperatorTok{+}\StringTok{ }
\StringTok{                        }\NormalTok{Bl.cromatin }\OperatorTok{+}\StringTok{ }\NormalTok{Normal.nucleoli }\OperatorTok{+}\StringTok{ }\NormalTok{Mitoses, }
                        \DataTypeTok{data=}\NormalTok{data.train, }
                        \DataTypeTok{hidden =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{),}
                        \DataTypeTok{linear.output =} \OtherTok{FALSE}\NormalTok{, }
                        \DataTypeTok{act.fct =} \StringTok{"tanh"}\NormalTok{)}

\NormalTok{ann.c3\_predictions \textless{}{-}}\StringTok{ }\NormalTok{neuralnet}\OperatorTok{::}\KeywordTok{compute}\NormalTok{(ann.c3, data.test)}\OperatorTok{$}\NormalTok{net.result}
\NormalTok{ann.c3\_pred \textless{}{-}}\StringTok{ }\KeywordTok{max.col}\NormalTok{(ann.c3\_predictions) }\CommentTok{\# find out which column has the maximum value}
\NormalTok{ann.c3\_pred \textless{}{-}}\StringTok{ }\KeywordTok{ifelse}\NormalTok{(ann.c3\_pred}\OperatorTok{==}\DecValTok{1}\NormalTok{, }\StringTok{"benign"}\NormalTok{, }\StringTok{"malignant"}\NormalTok{) }\CommentTok{\# if the first column was max, set it to benign, malignant otherwise}
\NormalTok{ann3.cr \textless{}{-}}\StringTok{ }\KeywordTok{sum}\NormalTok{((ann.c3\_pred}\OperatorTok{==}\NormalTok{data.test[,}\DecValTok{1}\NormalTok{]))}\OperatorTok{/}\KeywordTok{length}\NormalTok{(ann.c3\_pred)}

\CommentTok{\# Compare with our previous models}
\KeywordTok{print}\NormalTok{(}\KeywordTok{c}\NormalTok{(knn.cr, cart.cr, logreg.cr, ann1.cr, ann2.cr, ann3.cr))}
\CommentTok{\#\# [1] 0.9588235 0.9352941 0.9411765 0.9470588 0.9529412 0.7000000}
\end{Highlighting}
\end{Shaded}

\hypertarget{ann-regression}{%
\subsection{ANN regression}\label{ann-regression}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}

\CommentTok{\# read in data on Pima Indians Diabeses Database}
\KeywordTok{data}\NormalTok{(PimaIndiansDiabetes)}
\KeywordTok{head}\NormalTok{(PimaIndiansDiabetes)}
\CommentTok{\#\#   pregnant glucose pressure triceps insulin mass pedigree age diabetes}
\CommentTok{\#\# 1        6     148       72      35       0 33.6    0.627  50      pos}
\CommentTok{\#\# 2        1      85       66      29       0 26.6    0.351  31      neg}
\CommentTok{\#\# 3        8     183       64       0       0 23.3    0.672  32      pos}
\CommentTok{\#\# 4        1      89       66      23      94 28.1    0.167  21      neg}
\CommentTok{\#\# 5        0     137       40      35     168 43.1    2.288  33      pos}
\CommentTok{\#\# 6        5     116       74       0       0 25.6    0.201  30      neg}
\KeywordTok{summary}\NormalTok{(PimaIndiansDiabetes)}
\CommentTok{\#\#     pregnant         glucose         pressure         triceps     }
\CommentTok{\#\#  Min.   : 0.000   Min.   :  0.0   Min.   :  0.00   Min.   : 0.00  }
\CommentTok{\#\#  1st Qu.: 1.000   1st Qu.: 99.0   1st Qu.: 62.00   1st Qu.: 0.00  }
\CommentTok{\#\#  Median : 3.000   Median :117.0   Median : 72.00   Median :23.00  }
\CommentTok{\#\#  Mean   : 3.845   Mean   :120.9   Mean   : 69.11   Mean   :20.54  }
\CommentTok{\#\#  3rd Qu.: 6.000   3rd Qu.:140.2   3rd Qu.: 80.00   3rd Qu.:32.00  }
\CommentTok{\#\#  Max.   :17.000   Max.   :199.0   Max.   :122.00   Max.   :99.00  }
\CommentTok{\#\#     insulin           mass          pedigree           age        diabetes }
\CommentTok{\#\#  Min.   :  0.0   Min.   : 0.00   Min.   :0.0780   Min.   :21.00   neg:500  }
\CommentTok{\#\#  1st Qu.:  0.0   1st Qu.:27.30   1st Qu.:0.2437   1st Qu.:24.00   pos:268  }
\CommentTok{\#\#  Median : 30.5   Median :32.00   Median :0.3725   Median :29.00            }
\CommentTok{\#\#  Mean   : 79.8   Mean   :31.99   Mean   :0.4719   Mean   :33.24            }
\CommentTok{\#\#  3rd Qu.:127.2   3rd Qu.:36.60   3rd Qu.:0.6262   3rd Qu.:41.00            }
\CommentTok{\#\#  Max.   :846.0   Max.   :67.10   Max.   :2.4200   Max.   :81.00}
\KeywordTok{str}\NormalTok{(PimaIndiansDiabetes)}
\CommentTok{\#\# \textquotesingle{}data.frame\textquotesingle{}:	768 obs. of  9 variables:}
\CommentTok{\#\#  $ pregnant: num  6 1 8 1 0 5 3 10 2 8 ...}
\CommentTok{\#\#  $ glucose : num  148 85 183 89 137 116 78 115 197 125 ...}
\CommentTok{\#\#  $ pressure: num  72 66 64 66 40 74 50 0 70 96 ...}
\CommentTok{\#\#  $ triceps : num  35 29 0 23 35 0 32 0 45 0 ...}
\CommentTok{\#\#  $ insulin : num  0 0 0 94 168 0 88 0 543 0 ...}
\CommentTok{\#\#  $ mass    : num  33.6 26.6 23.3 28.1 43.1 25.6 31 35.3 30.5 0 ...}
\CommentTok{\#\#  $ pedigree: num  0.627 0.351 0.672 0.167 2.288 ...}
\CommentTok{\#\#  $ age     : num  50 31 32 21 33 30 26 29 53 54 ...}
\CommentTok{\#\#  $ diabetes: Factor w/ 2 levels "neg","pos": 2 1 2 1 2 1 2 1 2 2 ...}
\CommentTok{\# pregnant: Number of times pregnant}
\CommentTok{\# glucose: Plasma glucose concentration (glucose tolerance test) }
\CommentTok{\# pressure: Diastolic blood pressure (mm Hg)}
\CommentTok{\# triceps: Triceps skin fold thickness (mm)}
\CommentTok{\# insulin: 2{-}Hour serum insulin (mu U/ml)}
\CommentTok{\# mass: Body mass index (weight in kg/(height in m)\textbackslash{}\^{}2) Diabetes pedigree function}
\CommentTok{\# age: Age (years)}
\CommentTok{\# diabetes: Class variable (test for diabetes)}

\CommentTok{\# remove missing values i.e. some mass measurements are 0}
\NormalTok{idx}\FloatTok{.0}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{which}\NormalTok{(PimaIndiansDiabetes}\OperatorTok{$}\NormalTok{mass }\OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{)}
\NormalTok{data.pima \textless{}{-}}\StringTok{ }\NormalTok{PimaIndiansDiabetes[}\OperatorTok{{-}}\NormalTok{idx}\FloatTok{.0}\NormalTok{,]}

\CommentTok{\# re{-}scale data}
\NormalTok{data.pima}\OperatorTok{$}\NormalTok{diabetes \textless{}{-}}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(data.pima}\OperatorTok{$}\NormalTok{diabetes)}\OperatorTok{{-}}\DecValTok{1}
\NormalTok{maxs \textless{}{-}}\StringTok{ }\KeywordTok{apply}\NormalTok{(data.pima, }\DecValTok{2}\NormalTok{, max)}
\NormalTok{mins \textless{}{-}}\StringTok{ }\KeywordTok{apply}\NormalTok{(data.pima, }\DecValTok{2}\NormalTok{, min)}
\NormalTok{data.pima \textless{}{-}}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(}\KeywordTok{scale}\NormalTok{(data.pima, }\DataTypeTok{center=}\NormalTok{mins, }\DataTypeTok{scale=}\NormalTok{maxs }\OperatorTok{{-}}\StringTok{ }\NormalTok{mins))}
\KeywordTok{head}\NormalTok{(data.pima)}
\CommentTok{\#\#     pregnant   glucose  pressure   triceps   insulin      mass   pedigree}
\CommentTok{\#\# 1 0.35294118 0.7437186 0.5901639 0.3535354 0.0000000 0.3149284 0.23441503}
\CommentTok{\#\# 2 0.05882353 0.4271357 0.5409836 0.2929293 0.0000000 0.1717791 0.11656704}
\CommentTok{\#\# 3 0.47058824 0.9195980 0.5245902 0.0000000 0.0000000 0.1042945 0.25362938}
\CommentTok{\#\# 4 0.05882353 0.4472362 0.5409836 0.2323232 0.1111111 0.2024540 0.03800171}
\CommentTok{\#\# 5 0.00000000 0.6884422 0.3278689 0.3535354 0.1985816 0.5092025 0.94363792}
\CommentTok{\#\# 6 0.29411765 0.5829146 0.6065574 0.0000000 0.0000000 0.1513292 0.05251921}
\CommentTok{\#\#         age diabetes}
\CommentTok{\#\# 1 0.4833333        1}
\CommentTok{\#\# 2 0.1666667        0}
\CommentTok{\#\# 3 0.1833333        1}
\CommentTok{\#\# 4 0.0000000        0}
\CommentTok{\#\# 5 0.2000000        1}
\CommentTok{\#\# 6 0.1500000        0}

\CommentTok{\# split into train and test}
\NormalTok{n \textless{}{-}}\StringTok{ }\KeywordTok{nrow}\NormalTok{(data.pima)}
\NormalTok{idx.train \textless{}{-}}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n), }\KeywordTok{round}\NormalTok{(n}\OperatorTok{/}\DecValTok{2}\NormalTok{))}
\NormalTok{idx.test \textless{}{-}}\StringTok{ }\KeywordTok{setdiff}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n), idx.train)}
\NormalTok{data.train \textless{}{-}}\StringTok{ }\NormalTok{data.pima[idx.train, ]}
\NormalTok{data.test \textless{}{-}}\StringTok{ }\NormalTok{data.pima[idx.test,]}

\CommentTok{\# fit multiple regression model to predict mass (BMI) based on other measurements}
\NormalTok{reg \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(mass }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{triceps }\OperatorTok{+}\StringTok{ }\KeywordTok{factor}\NormalTok{(diabetes) }\OperatorTok{+}\StringTok{ }\NormalTok{insulin }\OperatorTok{+}\StringTok{ }\NormalTok{glucose }\OperatorTok{+}\StringTok{ }\NormalTok{pregnant }\OperatorTok{+}\StringTok{ }\NormalTok{pressure, }\DataTypeTok{data =}\NormalTok{ data.train)}
\KeywordTok{summary}\NormalTok{(reg)}
\CommentTok{\#\# }
\CommentTok{\#\# Call:}
\CommentTok{\#\# lm(formula = mass \textasciitilde{} age + triceps + factor(diabetes) + insulin + }
\CommentTok{\#\#     glucose + pregnant + pressure, data = data.train)}
\CommentTok{\#\# }
\CommentTok{\#\# Residuals:}
\CommentTok{\#\#      Min       1Q   Median       3Q      Max }
\CommentTok{\#\# {-}0.27091 {-}0.09095 {-}0.01383  0.07434  0.49669 }
\CommentTok{\#\# }
\CommentTok{\#\# Coefficients:}
\CommentTok{\#\#                   Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\# (Intercept)        0.10099    0.03375   2.992  0.00296 ** }
\CommentTok{\#\# age               {-}0.02083    0.04168  {-}0.500  0.61746    }
\CommentTok{\#\# triceps            0.30591    0.04332   7.062 8.20e{-}12 ***}
\CommentTok{\#\# factor(diabetes)1  0.09178    0.01520   6.037 3.82e{-}09 ***}
\CommentTok{\#\# insulin           {-}0.09777    0.06031  {-}1.621  0.10585    }
\CommentTok{\#\# glucose            0.02333    0.04736   0.493  0.62264    }
\CommentTok{\#\# pregnant          {-}0.06298    0.03806  {-}1.655  0.09883 .  }
\CommentTok{\#\# pressure           0.18860    0.04577   4.120 4.67e{-}05 ***}
\CommentTok{\#\# {-}{-}{-}}
\CommentTok{\#\# Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\# }
\CommentTok{\#\# Residual standard error: 0.1219 on 370 degrees of freedom}
\CommentTok{\#\# Multiple R{-}squared:  0.2906,	Adjusted R{-}squared:  0.2772 }
\CommentTok{\#\# F{-}statistic: 21.65 on 7 and 370 DF,  p{-}value: \textless{} 2.2e{-}16}

\CommentTok{\# calculate sum of squared errors (SSE) }
\NormalTok{yhat.reg1 \textless{}{-}}\StringTok{ }\KeywordTok{predict}\NormalTok{(reg, }\DataTypeTok{newdata =}\NormalTok{ data.test)}
\NormalTok{reg.sse \textless{}{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{sse.train =} \KeywordTok{sum}\NormalTok{((reg}\OperatorTok{$}\NormalTok{fitted.values }\OperatorTok{{-}}\StringTok{ }\NormalTok{data.train}\OperatorTok{$}\NormalTok{mass)}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{)}\OperatorTok{/}\DecValTok{2}\NormalTok{, }
                      \DataTypeTok{sse.test =} \KeywordTok{sum}\NormalTok{((yhat.reg1 }\OperatorTok{{-}}\StringTok{ }\NormalTok{data.test}\OperatorTok{$}\NormalTok{mass)}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{)}\OperatorTok{/}\DecValTok{2}\NormalTok{)}

\CommentTok{\# fit ANN regression model}
\CommentTok{\# notice linear.output set to TRUE this time}
\NormalTok{ann.r1 \textless{}{-}}\StringTok{ }\KeywordTok{neuralnet}\NormalTok{(mass }\OperatorTok{\textasciitilde{}}\StringTok{  }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{triceps  }\OperatorTok{+}\StringTok{ }\NormalTok{insulin }\OperatorTok{+}\StringTok{ }\NormalTok{glucose }\OperatorTok{+}\StringTok{ }\NormalTok{pregnant }\OperatorTok{+}\StringTok{ }\NormalTok{pressure, }
                        \DataTypeTok{data =}\NormalTok{ data.train,}
                        \DataTypeTok{hidden =} \KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{),}
                        \DataTypeTok{linear.output =} \OtherTok{TRUE}\NormalTok{)}

\KeywordTok{plotnet}\NormalTok{(ann.r1)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{402-ann-intro_files/figure-latex/unnamed-chunk-5-1} 

}

\caption{ANN network visualisation for regression}\label{fig:unnamed-chunk-5-1}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{\# SSE and RMSE errors}
\NormalTok{yhat.annr1 \textless{}{-}}\StringTok{ }\NormalTok{neuralnet}\OperatorTok{::}\KeywordTok{compute}\NormalTok{(ann.r1, data.test)}\OperatorTok{$}\NormalTok{net.result}
\NormalTok{annr1.sse \textless{}{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{sse.train =} \KeywordTok{sum}\NormalTok{((ann.r1}\OperatorTok{$}\NormalTok{net.result[[}\DecValTok{1}\NormalTok{]] }\OperatorTok{{-}}\StringTok{ }\NormalTok{data.train}\OperatorTok{$}\NormalTok{mass)}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{)}\OperatorTok{/}\DecValTok{2}\NormalTok{, }
                      \DataTypeTok{sse.test =} \KeywordTok{sum}\NormalTok{((yhat.annr1 }\OperatorTok{{-}}\StringTok{ }\NormalTok{data.train}\OperatorTok{$}\NormalTok{mass)}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{)}\OperatorTok{/}\DecValTok{2}\NormalTok{)}
\CommentTok{\#\# Warning in yhat.annr1 {-} data.train$mass: longer object length is not a multiple}
\CommentTok{\#\# of shorter object length}

\CommentTok{\# compare SSE errors for train and test between multiple regression and ANN}
\KeywordTok{print}\NormalTok{(reg.sse)}
\CommentTok{\#\#   sse.train sse.test}
\CommentTok{\#\# 1  2.751006  3.04521}
\KeywordTok{print}\NormalTok{(annr1.sse)}
\CommentTok{\#\#   sse.train sse.test}
\CommentTok{\#\# 1  2.109606 137.7486}

\CommentTok{\# plot predicted values vs. mass values for the train and test data separately}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(data.train}\OperatorTok{$}\NormalTok{mass, reg}\OperatorTok{$}\NormalTok{fitted.values, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{col=}\StringTok{"lightblue"}\NormalTok{, }\DataTypeTok{xlab=}\StringTok{"mass (true value)"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Prediction"}\NormalTok{)}
\KeywordTok{points}\NormalTok{(data.train}\OperatorTok{$}\NormalTok{mass, ann.r1}\OperatorTok{$}\NormalTok{net.result[[}\DecValTok{1}\NormalTok{]], }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{col=}\StringTok{"coral2"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(}\DataTypeTok{x=}\KeywordTok{c}\NormalTok{(}\OperatorTok{{-}}\DecValTok{100}\OperatorTok{:}\DecValTok{100}\NormalTok{), }\DataTypeTok{y=}\KeywordTok{c}\NormalTok{(}\OperatorTok{{-}}\DecValTok{100}\OperatorTok{:}\DecValTok{100}\NormalTok{))}

\KeywordTok{plot}\NormalTok{(data.test}\OperatorTok{$}\NormalTok{mass, yhat.reg1, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{col=}\StringTok{"lightblue"}\NormalTok{, }\DataTypeTok{xlab=}\StringTok{"mass (true value)"}\NormalTok{, }\DataTypeTok{ylab=}\StringTok{"Prediction"}\NormalTok{)}
\KeywordTok{points}\NormalTok{(data.test}\OperatorTok{$}\NormalTok{mass, yhat.annr1, }\DataTypeTok{pch=}\DecValTok{19}\NormalTok{, }\DataTypeTok{col=}\StringTok{"coral2"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(}\DataTypeTok{x=}\KeywordTok{c}\NormalTok{(}\OperatorTok{{-}}\DecValTok{100}\OperatorTok{:}\DecValTok{100}\NormalTok{), }\DataTypeTok{y=}\KeywordTok{c}\NormalTok{(}\OperatorTok{{-}}\DecValTok{100}\OperatorTok{:}\DecValTok{100}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{402-ann-intro_files/figure-latex/unnamed-chunk-5-2} 

}

\caption{Comparison of predicted values vs. known values with linear regression (blue) and ANN (red) on the training data set (left) and on the test data set (right)}\label{fig:unnamed-chunk-5-2}
\end{figure}

\hypertarget{ann-rep-value}{%
\subsection{ANN rep value}\label{ann-rep-value}}

Have we said at the lecture that the weights are randomly assigned at the start? How do we know that we have a best network? Above we have looked at one network and used a random seed to ensure reproducibility of the results. We could have been just unlucky with our comparisons to logigits or linear regression. In practice, one would fit many networks and choose a best one

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Here we will set rep to 5, it is getting computationally heavy}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{ann.r2 \textless{}{-}}\StringTok{ }\KeywordTok{neuralnet}\NormalTok{(mass }\OperatorTok{\textasciitilde{}}\StringTok{  }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{triceps  }\OperatorTok{+}\StringTok{ }\NormalTok{insulin }\OperatorTok{+}\StringTok{ }\NormalTok{glucose }\OperatorTok{+}\StringTok{ }\NormalTok{pregnant }\OperatorTok{+}\StringTok{ }\NormalTok{pressure, }
                        \DataTypeTok{data =}\NormalTok{ data.train,}
                        \DataTypeTok{hidden =} \KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{),}
                        \DataTypeTok{linear.output =} \OtherTok{TRUE}\NormalTok{, }
                        \DataTypeTok{rep =} \DecValTok{5}\NormalTok{)}

\CommentTok{\#plot(ann.r2, rep = "best")}
\end{Highlighting}
\end{Shaded}

\hypertarget{ann-relative-importance-of-variables}{%
\subsection{ANN relative importance of variables}\label{ann-relative-importance-of-variables}}

\begin{itemize}
\tightlist
\item
  Weights that connect nodes in a neural network cannot be interpreted as the parameters coefficients of a standard linear regression model
\item
  They can be thought of as analogous to them and can be used to describe relationships between variables
\item
  i.e.~weights dictate the relative influence of information that is processed in the network such that input variables that are not relevant in terms of their correlation with the response are suppressed by the weights
\item
  A difference between neural network and a regression model is that the number of weights is excessive in the former case
\item
  This makes neural network powerful and flexible, the price for that is easiness of integration of the model, it is not so straightforward anymore
\item
  One method to identify the relative importance of the covariates is by Garson (1991) and is based by deconstructing the model weights (implented in NerualNetTools)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{garson}\NormalTok{(ann.r1)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{402-ann-intro_files/figure-latex/unnamed-chunk-7-1} 

}

\caption{Output of the variable important call for one of the ANN regression models}\label{fig:unnamed-chunk-7}
\end{figure}

Feel free to experiment with different options of the neuralnet() and different datasets that we have used so far. Do note however, that neurlanet() package is great fpr getting some ideas about running ANN, the heavy duty work is done on GPUs typically via \href{https://tensorflow.rstudio.com/guide/keras/}{Keras}, often in Python, although now \href{https://tensorflow.rstudio.com}{Tensforlow} is available for R as well.

\end{document}
